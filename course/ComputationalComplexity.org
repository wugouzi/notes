#+TITLE: Computational Complexity
#+AUTHOR: Ryan O'Donnell

#+EXPORT_FILE_NAME: ../latex/ComputationalComplexity/ComputationalComplexity.tex
#+LATEX_HEADER: \input{preamble.tex}
#+LATEX_HEADER: \graphicspath{{../../books/}}
* Definition of macros                                               :ignore:
#+LATEX_HEADER: \def \TIME {\text{TIME}}
#+LATEX_HEADER: \def \EXP {\textbf{EXP}}
#+LATEX_HEADER: \def \SPACE {\textbf{SPACE}}
#+LATEX_HEADER: \def \PSPACE {\textbf{PSPACE}}
#+LATEX_HEADER: \def \NPSPACE {\textbf{NPSPACE}}
#+LATEX_HEADER: \def \NSPACE {\textbf{NSPACE}}
#+LATEX_HEADER: \def \coNSPACE {\textbf{coNSPACE}}
#+LATEX_HEADER: \def \NTIME {\textbf{NTIME}}
#+LATEX_HEADER: \def \NP {\textbf{NP}}
#+LATEX_HEADER: \def \coNP {\textbf{coNP}}
#+LATEX_HEADER: \def \NEXP {\textbf{NEXP}}
#+LATEX_HEADER: \def \NE {\textbf{NE}}
#+LATEX_HEADER: \def \NL {\textbf{NL}}
#+LATEX_HEADER: \def \coNL {\textbf{coNL}}
#+LATEX_HEADER: \def \Pspoly {\textbf{P}/poly}
#+LATEX_HEADER: \def \AC {\text{AC}}
#+LATEX_HEADER: \def \BPP {\textbf{BPP}}
#+LATEX_HEADER: \def \start {\text{start}}
#+LATEX_HEADER: \def \tend {\text{end}}
#+LATEX_HEADER: \def \halt {\text{halt}}
#+LATEX_HEADER: \def \pad {\text{pad}}
#+LATEX_HEADER: \def \HALT {\text{HALT}}
#+LATEX_HEADER: \def \DTIME {\textbf{DTIME}}
#+LATEX_HEADER: \def \NP {\textbf{NP}}
#+LATEX_HEADER: \def \INDSET {\texttt{INDSET}}
#+LATEX_HEADER: \def \accept {\text{accept}}
#+LATEX_HEADER: \def \TMSAT {\texttt{TMSAT}}
#+LATEX_HEADER: \def \SAT {\texttt{SAT}}
#+LATEX_HEADER: \def \TSAT {\texttt{3SAT}}
#+LATEX_HEADER: \def \ZOIPROG {\texttt{1/0 IPROG}}
#+LATEX_HEADER: \def \dHAMPATH {\texttt{dHAMPATH}}
#+LATEX_HEADER: \def \TAUTOLOGY {\texttt{TAUTOLOGY}}
#+LATEX_HEADER: \def \PATH {\texttt{PATH}}
#+LATEX_HEADER: \def \TQBF {\texttt{TQBF}}
* Notational conventions
  Use \(\lcorner{x}\) to denote some canonical binary representation of the object \(x\).

  The length of a string \(x\) is denoted by \(\abs{x}\)
* Lecture 1
  \(\TIME(t(n))=\)all languages \(L\) decidable in \(O(t(n))\) steps on input of length \(n\)

  Language \(L\)(\(\Sigma^*\)) \(\equiv\) decision problem -> yes/no problem

  | Language \(L\)                    | decision problem | \(f:\{0,1\}^*\to\{0,1\}\)        |
  | \(\Sigma^*\)                           | yes/no problem   | \(x\in L\Leftrightarrow f(x)=1\) |
  | decide if a string is in language |                  |                                  |

  Model: multitape Turing machine (TM)

  Time Hierarchy Theorem (More time = more power to decide a language)

  \(\Rightarrow\) \(\TIME(n^2)\subsetneq\TIME(n^3)\)

  \(\bP=\TIME(poly(n))\), \(\EXP=\TIME(2^{poly(n)})\),\(\bE=\TIME(2^{O(n)})\)

  \(\Rightarrow\bP\subsetneq\bE\subsetneq\EXP\)

  \(\SPACE(s(n))=\) langs decidable using tape cells \(\subseteq O(s(n))\)

  \(\TIME(f(n))\subseteq\SPACE(f(n))\)

  (each operation takes a cell)

  \(\PSPACE=\SPACE(poly(n))\)
  
  \(\bP\subseteq\PSPACE\)

  \(\SPACE(f(n))\subseteq\TIME(2^{O(f(n))})\) (since only \(O(f(n))\) possible states if each state
  is different)

    \(\bL=\SPACE(\log n)\)

    \(\bL\subseteq\bP\subseteq\PSPACE\subseteq\EXP\)

    #+ATTR_LATEX: :options [HPV77]
    #+BEGIN_theorem
    \(\TIME(t(n))\subseteq\SPACE(\frac{t(n)}{\log t(n)})\subsetneq\SPACE(t(n))\)
    #+END_theorem

    Space is more valuable than time.

    \(\NP=\NTIME(poly(n))\) computed by nondeterministic multitape turing machine

    \(\NE=\NTIME(2^{O(n)})\)

    Circuits - "Non-uniform" model

    "Non-uniform" different algorithms for different input length

    \(\bP/poly\)=langs decidable by \(poly(n)\)-size circuit familys

    \(\bP\subsetneq\bP/poly\)

    if \(\NP\neq\bP\) then \(\NP\not\subseteq\Pspoly\)

    which is equivalent to \(\SAT\) not decidable by \(poly(n)\)-size circuits

    #+ATTR_LATEX: :options []
    #+BEGIN_theorem
    there exists language with no poly-size constant-depth circuits (actually in \(\bP\))
    #+END_theorem

    #+ATTR_LATEX: :options []
    #+BEGIN_theorem
    CLIQUE requires exponential size AND/OR circuits
    #+END_theorem

    #+ATTR_LATEX: :options []
    #+BEGIN_theorem
    There exists a language \(L\in\bP\) requiring circuit families of size \(\ge3 n\)
    #+END_theorem


    #+ATTR_LATEX: :options [Santhanam theorem]
    #+BEGIN_theorem
    for all \(c\) there exists \(L\) s.t. \(L\) is not computable by \(O(n^c)\)-size circuit
    #+END_theorem

    #+ATTR_LATEX: :options [William's Theorem]
    #+BEGIN_theorem
    \(\exists L\in\NEXP\) is not computable by \(\AC^0[6]\) (constant depth, \(poly(n)\) size, also
    get \(\mod6\) gates)
    #+END_theorem

    Randomness

    \(\BPP=\) langs decidable in \(poly(n)\)-time using randomness

    \(\bP\subseteq\BPP\subseteq\EXP\)

    PIT = "polynomial identity testing" that are in \(\BPP\), but we don't know if they are in \(\bP\)

    Hardness vs Randomness Paradigm
    

* Chap 1: The computational model
    
*** Efficiency and Running Time
    #+ATTR_LATEX: :options []
    #+BEGIN_definition
    A TM \(M\) is described by a tuple \((\Gamma,Q,\delta)\) containing
    * A finite set \Gamma of the symbols that \(M\)'s tapes can contain. We assume that \Gamma contains a
      designated "blank" symbol, denoted \(\Box\); a designated "start" symbol, denoted \(\rhd\);
      and the numbers 0 and 1. We call \Gamma the *alphabet* of \(M\)
    * A finite set \(Q\) of possible states \(M\)' register can be in. We assume that \(Q\) contains
      a designated start state, denoted \(q_{\start}\), and a designated halting state, denoted \(q_{\halt}\)
    * A function \(\delta:Q\times\Gamma^k\to Q\times\Gamma^{k-1}\times\{\text{L,S,R}\}^k\),
      where \(k\ge2\), describing the rules \(M\) use in performing each step. This function is
      called the *transition function* of \(M\)
    #+END_definition

    #+ATTR_LATEX: :width 0.8\textwidth
    [[../images/ComputationalComplexity/1.png]]

    
    #+ATTR_LATEX: :options [Computing a function and running time]
    #+BEGIN_definition
    Let \(f:\{0,1\}^*\to\{0,1\}\) and let \(T:\N\to\N\) be some functions, and let \(M\) be a Turing
    machine. We say that \(M\) *computes* \(f\) if for every \(x\in\{0,1\}^*\), whenever \(M\) is
    initialized to the start configuration on input \(x\), then it halts with \(f(x)\) written on
    its output tape. We say \(M\) *computes \(f\) in \(T(n)\)-time* if its computation on every
    input \(x\) requires at most \(T(\abs{x})\) steps
    #+END_definition

    A function \(T:\N\to\N\) is *time constructible* if \(T(n)\ge n\) and there is a TM \(M\) that
    computes the function \(x\mapsto\lcorner{T(\abs{x})}\) in time \(T(n)\). (\(\lcorner{T(\abs{x})}\)
    denotes the binary representation of the number \(T(\abs{x})\)). The restriction \(T(n)\ge n\) is
    to allow the algorithm time to read its input.

    #+ATTR_LATEX: :options []
    #+BEGIN_proposition
    For every \(f:\{0,1\}^*\to\{0,1\}\) and a time-constructible b\(T:\N\to\N\), if \(f\) is
    computable in time \(T(n)\) by a TM \(M\) using alphabet \Gamma, then it's computable in time
    \(4\log\abs{\Gamma}T(n)\) by a TM \(M\) using the alphabet \(\{0,1,\Box,\rhd\}\).
    #+END_proposition

    #+BEGIN_proof
    Let \(M\) be a TM with alphabet \Gamma, \(k\) tapes and state set \(Q\) that computes the
    function \(f\) in \(T(n)\) times. We describe an equivalent TM \(\tilde{M}\) computing \(f\)
    with alphabet \(\{0,1,\Box,\rhd\}\), \(k\) tapes and a set \(Q'\) of states.

    One can encode any member of \Gamma using \(\log\abs{\Gamma}\) bits. Thus each of \(\tilde{M}\)'s work
    tapes will simply encode one of \(M\)'s tapes: For every cell in \(M\)'s tape we will
    have \(\log\abs{\Gamma}\) cells in the corresponding tape of \(\tilde{M}\)

    To simulate one step of \(M\), the machine \(\tilde{M}\) will 1. use \(\log\abs{\Gamma}\) steps to
    read from each tape the \(\log\abs{\Gamma}\) bits encoding of a symbol of \Gamma 2. use its state register
    to store the symbols read 3. use \(M\)'s transition function to compute the symbols \(M\) writes
    and \(M\)'s new state given this information 4. store this information in its state register 5.
    use \(\log\abs{\Gamma}\) steps to write the encodings of these symbols on its tapes

    
    #+END_proof

    #+ATTR_LATEX: :options []
    #+BEGIN_proposition
    label:prop1.6
    Define a single-tape Turing machine to be a TM that has only one read-write tape. For every
    \(f:\{0,1\}^*\to\{0,1\}\) and time-constructible \(T:\N\to\N\) if \(f\) is computable in
    time \(T(n)\) by a TM \(M\) using \(k\) tapes, then it is computable in time \(5kT(n)^2\) by a
    single-tape TM \(M\)
    #+END_proposition

    #+BEGIN_proof
    The TM \(\tilde{M}\) encodes \(k\) tapes of \(M\) on a single tape by using
    locations \(1,k+1,2k+1,\dots\) to encode the first tape, locations \(2,k+2,2k+2,\dots\) to
    encode the second tape etc. For every symbol \(a\) in \(M\)'s alphabet, \(\tilde{M}\) will
    contain both the symbol \(a\) and the symbol \(\hat{a}\). In the encoding of each tape, exactly
    one symbol will be of the "^ type", indicating that the corresponding head of \(M\) is
    positioned in that location. \(\tilde{M}\) will not touch the first \(n+1\) locations of its
    tape (where the input is located) but rather start by taking \(O(n^2)\) steps to copy the input
    bit by bit into the rest of the tape, while encoding it in the above way.
    #+END_proof

    #+ATTR_LATEX: :options [Oblivious Turing machines]
    #+BEGIN_remark
    One can ensure that the proof of Proposition ref:prop1.6 yields a TM \(\tilde{M}\) with the
    following property: its head movements do not depend on the input but only depend on the input
    length. That is, every input \(x\in\{0,1\}^*\) and \(i\in\N\), the location of each of \(M\)'s
    at the \(i\)th step of execution on input \(x\) is only a function of \(\abs{x}\) and \(i\). A
    machine with this property is called *oblivious*.
    #+END_remark

    #+ATTR_LATEX: :options []
    #+BEGIN_proposition
    Define a bidirectional TM to be a TM whose tapes are infinite in both directions. For
    every \(f:\{0,1\}^*\to\{0,1\}^*\) and time-constructible \(T:\N\to\N\) if \(f\) is computable in
    time \(T(n)\) by a directional TM M, then it is computable in time \(4T(n)\) by a standard
    (undirectional) TM \(\tilde{M}\)
    #+END_proposition

    #+BEGIN_proof
    #+ATTR_LATEX: :width .5\textwidth
    [[../images/ComputationalComplexity/2.png]]

    If \(M\) uses alphabet \Gamma, then \(\tilde{M}\) will use the alphabet \(\Gamma^2\) 
    #+END_proof

*** Machines as Strings and the Universal Turing Machine
     We will also find it convenient to assume that our representation scheme satisfies the following
     properties:
     1. We will also find it convenient to assume that our representation scheme satisfies the
        following properties:
     2. Every TM is represented by infinitely many strings
     
     We denote by \(\lcorner{M}\) the TM \(M\)'s representation as a binary string. If \alpha is a string
     then \(M_\alpha\) denotes the TM that \alpha represents.

     #+ATTR_LATEX: :options [Efficient universal Turing machine]
     #+BEGIN_theorem
     label:thm1.9
     There exists a TM \(\calu\) s.t. for
     every \(x,\alpha\in\{0,1\}^*\), \(\calu(x,\alpha)=M_\alpha(x)\). Moreover, if \(M_{\alpha}\) halts on
     input \(x\) within \(T\) steps then \(\calu(x,\alpha)\) halts within \(CT\log T\) steps, where \(C\)
     is a number independent of \(\abs{x}\) and depending only on \(M_\alpha\)'s alphabet size,
     number of tapes and number of states.
     #+END_theorem

     #+ATTR_LATEX: :options [Proof of relaxed version of theorem \ref{thm1.9}]
     #+BEGIN_proof
     We assume \(M\) has a single work tape (in addition to the input and output tape) and uses he
     alphabet \(\{\rhd,\Box,0,1\}\). The reason is that \(\calu\) can transform a representation of
     every TM \(M\) into a representation of an equivalent TM \(\tilde{M}\) that satisfies these
     properties. (which my takes \(C'T^2\) time)

     #+ATTR_LATEX: :float H :width .5\textwidth
     [[../images/ComputationalComplexity/3.png]]
     #+END_proof


*** Uncomputablity: An Introduction
     #+ATTR_LATEX: :options []
     #+BEGIN_theorem
     There exists a function \(\text{UC}:\{0,1\}^*\to\{0,1\}\) that is not computable by any TM
     #+END_theorem

     #+BEGIN_proof
     For every \(\alpha\in\{0,1\}^*\), if \(M_{\alpha}(\alpha)=1\) then \(\text{UC}(\alpha)=0\);
     otherwise \(\text{UC}(\alpha)=1\).

     If its computable, then there exists a TM \(M\) s.t. \(M(\alpha)=\text{UC}(\alpha)\), then
     \(M(\lcorner{M})=\text{UC}(\lcorner{M})\)
     #+END_proof

     #+ATTR_LATEX: :options []
     #+BEGIN_theorem
     \(\HALT\) is not computable by any TM
     #+END_theorem

*** The Class \texorpdfstring{\(P\)}{P}
     A *complexity class* is a set of function that can be computed within given resource bounds.

     [[index:decide]]
     We say that a machine *decides* a language \(L\subseteq\{0,1\}^*\) if it computes the
     function \(f_L:\{0,1\}^*\to\{0,1\}\) where \(f_L(x)=1\Leftrightarrow x\in L\)

     #+ATTR_LATEX: :options []
     #+BEGIN_definition
     Let \(T:\N\to\N\) be some function. A language \(L\) is in \(\DTIME(T(n))\) iff there is a
     Turing machine that runs in \(c\dot T(n)\) for some constant \(c>0\) and decides \(L\).
     #+END_definition

     The D in \(\DTIME\) refers to "deterministic".

     #+ATTR_LATEX: :options []
     #+BEGIN_definition
     \(\bP=\bigcup_{c\ge1}\DTIME(n^c)\)
     #+END_definition

* Chap 2: NP and NP completeness

*** The Class \(\NP\)
     [[index:$\NP$]]
     #+ATTR_LATEX: :options []
     #+BEGIN_definition
     A language \(L\subseteq\{0,1\}^*\) is in \(\NP\) if there exists  a polynomial \(p:\N\to\N\)
     and a polynomial-time TM \(M\) (called the *verifier* for \(L\)) s.t. for
     every \(x\in\{0,1\}^*\)
     \begin{equation*}
x\in L\Leftrightarrow \exists u\in\{0,1\}^{p(\abs{x})}\text{ s.t. }M(x,u)=1
     \end{equation*}
     If \(x\in L\) and \(u\in\{0,1\}^{p(\abs{x})}\) satisfy \(M(x,u)=1\) then we call \(u\) a
     *certificate* for \(x\)
     #+END_definition

     #+ATTR_LATEX: :options [\(\INDSET\in\NP\)]
     #+BEGIN_examplle
     By representing the possible invitees to a dinner party with the vertices of a graph having an
     edge between any two people who don't get along. The dinner party computational problem becomes
     the problem of finding a maximum sized *independent set* (set of vertices without any common
     edges) in a given graph. The corresponding language is
     \begin{equation*}
\INDSET=\{\la G,k\ra:\exists S\subseteq V(G)\text{ s.t. }\abs{S}\ge k\text{ and }\forall u,v\in S, \ove{uv}\not\in E(G)\}
     \end{equation*}

     Consider the following polynomial-time algorithm \(M\): Given a pair \(\la G,k\ra\) and a
     string \(u\in\{0,1\}^*\), output 1 iff \(u\) encodes a list of \(k\) vertices of \(G\) s.t.
     there is no edge between any two members of the list. Note that if \(n\) is the number of
     vertices in \(G\), then a list of \(k\) vertices can be encoded using \(O(k\log n)\) bits,
     where \(n\) is the number of vertices in \(G\). Thus \(u\) is a string of at
     most \(O(n\log n)\) bits, which is polynomial in the size of the representation of \(G\).
     #+END_examplle

     #+ATTR_LATEX: :options []
     #+BEGIN_proposition
     Let \(\EXP=\bigcup_{c>1}\DTIME(2^{n^c})\). Then \(\bP\subseteq\NP\subseteq\EXP\)
     #+END_proposition

     #+BEGIN_proof
     \(\bP\subseteq\NP\). Suppose \(L\in\bP\) is decided in polynomial-time by a TM \(N\).
     Then we take \(N\) as the machine \(M\) and make \(p(x)\) the zero polynomial

     \(\NP\subseteq\EXP\). We can decide \(L\) in time \(2^{O(p(n))}\)  by enumerating all
     possible \(n\) and using \(M\) to check whether \(u\) is a valid certificate for the
     input \(x\). Note that \(p(n)=O(n^c)\) for some \(c>1\), the number of choices for \(u\) is \(2^{O(n^c)}\).
     #+END_proof

     \(\NP\) stands for *nondeterministic polynomial time*.

     NDTM has *two* transition function \(\delta_0\) and \(\delta_1\), and a special state denoted
     by \(q_{\accept}\). When an NDTM \(M\) computes a function, we envision that at each
     computational step \(M\) makes an arbitrary choice at to which of its two transition functions
     to apply. For every input \(x\), we say that \(M(x)=1\) if there *exists* some sequence of this
     choices that would make \(M\) reach \(q_{\accept}\) on input \(x\). We say that \(M\) runs
     in \(T(n)\) time if for every input \(x\in\{0,1\}^*\) and every sequence of nondeterministic
     choices, \(M\) reaches the halting state or \(q_{\accept}\) within \(T(\abs{x})\) steps

     #+ATTR_LATEX: :options []
     #+BEGIN_definition
     For every function \(f:\N\to\N\) and \(L\subseteq\{0,1\}^*\) we say that \(L\in\NTIME(T(n))\)
     if there is a constant \(c>0\) and a \(c\dot T(n)\)-time NDTM \(M\) s.t. for
     every \(x\in\{0,1\}^*\), \(x\in L\Leftrightarrow M(x)=1\)
     #+END_definition

     #+ATTR_LATEX: :options []
     #+BEGIN_theorem
     \(\NP=\bigcup_{c\in\N}\NTIME(n^c)\)
     #+END_theorem

     #+BEGIN_proof
     The main idea is that the sequence of nondeterministic choices made by an accepting computation
     of an NDTM can be viewedas a certificate that the input is in the language, and vice versa

     Suppose \(p:\N\to\N\) is a polynomial and \(L\) is decidable by a NDTM \(N\) that runs in
     time \(p(n)\). For every \(x\in L\), there is a sequence of nondeterministic choices that
     makes \(N\) reach \(q_{\accept}\) on input \(x\). We can use this sequence as a certificate
     for \(x\). This certificate has length \(p(\abs{x})\) and can be verified in polynomial time by
     a deterministic machine.

     Conversely, if \(L\in\NP\), then we describe a polynomial time NDTM \(N\) that decides \(L\).
     On input \(x\), it uses the ability to make nondeterministic choices to write down a
     string \(u\) of length \(p(\abs{x})\). (Having transition \(\delta_0\) correspond to writing a
     0 and \(\delta_1\) ). Then it runs the deterministic verifier 
     #+END_proof

*** Reducibility and NP-Completeness
     #+ATTR_LATEX: :options []
     #+BEGIN_definition
     A language \(L\subseteq\{0,1\}^*\) is *polynomial-time Karp reducible to a
     language* \(L'\subseteq\{0,1\}^*\) (sometimes shortened to just "polynomial-time reducible"), denoted
     by \(L\le_p L'\) if there is a polynomial-time
     computable function \(f:\{0,1\}^*\to\{0,1\}^*\) s.t. for every \(x\in\{0,1\}^*\),
     \(x\in L\) iff \(f(x)\in L'\)

     We say that \(L'\) is *\(\NP\)-hard* if \(L\le_pL'\) for every \(L\in\NP\). We say that \(L'\)
     is *\(\NP\)-complete* if \(L'\) is \(\NP\)-hard and \(L'\in\NP\)
     #+END_definition

    #+ATTR_LATEX: :options []
    #+BEGIN_theorem
    1. (Transitivity) If \(L\le_pL'\) and \(L'\le_pL''\) then \(L\le_pL''\)
    2. If language \(L\) is \(\NP\)-hard and \(L\in\bP\) then \(\bP=\NP\)
    3. If language \(L\) is \(\NP\)-complete, then \(L\in\bP\) iff \(\bP=\NP\)
    #+END_theorem

    #+ATTR_LATEX: :options []
    #+BEGIN_theorem
    The following language is \(\NP\)-complete
    \begin{equation*}
\TMSAT=\{\la\alpha,x,1^n,1^t\ra:\exists u\in\{0,1\}^n\text{ s.t. }M_\alpha\text{ outputs }1
\text{ on input }\la x,u\ra\text{ within }t\text{ steps}\}
    \end{equation*}
    #+END_theorem

    #+BEGIN_proof
    There is a polynomial \(p\) and a verifier TM \(M\) s.t. \(x\in L\) iff there is a
    string \(u\in\{0,1\}^{p(\abs{x})}\) satisfying \(M(x,u)=1\) and \(M\) runs in time \(q(n)\) for
    some polynomial \(q\).

    Map every string \(x\in\{0,1\}^*\) to the tuple \(\la\lcorner{M},x,1^{p(\abs{x})},1^{q(m)}\)
    where \(m=\abs{x}+p(\abs{x})\) and \(\lcorner{M}\) denotes the representation of \(M\) as
    string.
    \begin{align*}
&\la\lcorner{M},x,1^{p(\abs{x})},1^{q(m)}\ra\in\TMSAT\\
&\Leftrightarrow\exists u\in\{0,1\}^{p(\abs{x})}\text{ s.t. }M(x,u)\text{ outputs 1 within }q(m)\text{ steps}\\
&\Leftrightarrow x\in L
    \end{align*}
    #+END_proof

*** The Cook-Levin Theorem: Computation is Local
     We denote by \(\SAT\) the language of all satisfiable CNF formulae and by \(\TSAT\) the
     language of all satisfiable 3CNF formulae

     #+ATTR_LATEX: :options [Cook-Levin Theorem]
     #+BEGIN_theorem
     label:thm2.10
     1. \(\SAT\) is \(\NP\)-complete
     2. \(\TSAT\) is \(\NP\)-complete
     #+END_theorem

     #+ATTR_LATEX: :options [Universality of AND, OR, NOT]
     #+BEGIN_lemma
     label:lemma2.13
     For every Boolean function \(f:\{0,1\}^l\to\{0,1\}\), there is an \(l\)-variable CNF formula \varphi
     of size \(l2^l\) s.t. \(\varphi(u)=f(u)\) for every \(u\in\{0,1\}^l\), where the size of a CNF
     formula is defined to be the number of \(\wedge/\vee\) symbols it contains
     #+END_lemma

     #+BEGIN_proof
     For every \(v\in\{0,1\}^l\), there exists a clause \(C_v(z_1,\dots,z_l)\) s.t. \(C_v(v)=0\)
     and \(C_v(u)=1\) for every \(u\neq v\).

     We let \varphi be the AND of all the clauses \(C_v\) for \(v\) s.t. \(f(v)=0\)
     \begin{equation*}
\varphi=\bigwedge_{v:f(v)=0}C_v(z_1,\dots,z_l)
     \end{equation*}
     Note that \varphi has size at most \(l2^l\).
     #+END_proof

     #+ATTR_LATEX: :options []
     #+BEGIN_lemma
     \(\SAT\) is \(\NP\)-hard
     #+END_lemma

     #+BEGIN_proof
     Let \(L\) be an \(\NP\) language. By definition, there is a polynomial time TM \(M\) s.t. for
     every \(x\in\{0,1\}^*\), \(x\in L\Leftrightarrow M(x,u)=1\) for
     some \(u\in\{0,1\}^{p(\abs{x})}\), where \(p:\N\to\N\) is some polynomial. We show \(L\) is
     polynomial-time Karp reducible to \(\SAT\) by describing a polynomial-time
     transformation \(x\to\varphi_x\) from strings to CNF formulae s.t. \(x\in L\) iff \(\varphi_x\)
     is satisfiable. Equivalently
     \begin{equation*}
\varphi_x\in\SAT \quad\text{ iff }\quad\exists u\in\{0,1\}^{p(\abs{x})}
\text{ s.t. }M(x\circ u)=1
     \end{equation*}
     where \(\circ\) denotes concatenation

     Assume \(M\)
     1. \(M\) only has two tapes - an input tape and a work/output tape
     2. \(M\) is an oblivious TM in the sense that its head movement does not depend on the contents
        of its tapes. That is, \(M\)'s computation takes the same time for all inputs of size \(n\),
        and for every \(i\) the location of \(M\)'s head at the \(i\)th step depends only on \(i\)
        and the length of the input


     We can make these assumptions without loss of generality because for every \(T(n)\)-time TM \(M\)
     there exists a two-tape oblivious TM \(\tilde{M}\) computing the same function
     in \(O(T(n)^2)\). Thus in particular, if \(L\in\NP\), then there exists a two-tape oblivious
     polynomial-time TM \(M\) and a polynomial \(p\) s.t.
     \begin{equation}
     \label{eq:2.2}
x\in L \Leftrightarrow \exists u\in\{0,1\}^{p(\abs{x})}\text{ s.t. }M(x\circ u)=1
     \end{equation}

     Note that because \(M\) is oblivious, we can run it on the trivial input \((x,0^{p(\abs{x})})\)
     to determine the precise head position of \(M\) during its computation on every other input of
     the same length.

     Denote by \(Q\) the set of \(M\)'s possible states and by \Gamma its alphabet. The *snapshot*
     of \(M\)'s execution on some input \(y\) at a particular step \(i\) is the triple
     \(\la a,b,q\ra\in\Gamma\times\Gamma\times Q\) s.t. \(a,b\) are the symbols read by \(M\)'s
     heads from the two tapes and \(q\) is the state \(M\) is in at the \(i\)th step. Clearly the
     snapshot can be encoded as a binary string. Let \(c\) denote the length of this string, which
     is some constant depending upon \(\abs{Q}\) and \(\abs{\Gamma}\)

     #+ATTR_LATEX: :width .5\textwidth :float H
     [[/Users/wu/notes/images/ComputationalComplexity/4.png]]

     For every \(y\in\{0,1\}^*\), the snapshot of \(M\)'s execution on input \(y\) at the \(i\)th
     step depends on its state in the \((i-1)\)st step and the contents of the current cells of its
     input and work tapes.

     Suppose somebody were to claim the existence of some \(u\) satisfying \(M(x\circ u)=1\) and as
     evidence, present you with the sequence of snapshots that arise from \(M\)'s execution
     on \(x\circ u\). How can you tell that the snapshots present a valid computation that was
     actually performed by \(M\).

     Clearly, it suffices to check that for each \(i\le T(n)\), the snapshot \(z_i\) is correct
     given the snapshot for the previous \(i-1\) steps. However, since the TM can only read/modify
     one bit at a time, to check the correctness of \(z_i\) it suffices to look at only /two/ of the
     previous snapshots. Specifically, to check \(z_i\) we need to only look at the following:
     \(z_{i-1}\), \(y_{\text{inputpos}(i)}\), \(z_{\text{prev}(i)}\). 

     #+ATTR_LATEX: :width .8\textwidth :float H
     [[../images/ComputationalComplexity/5.png]]

     Here \(y\) is a shorthand
     for \(x\circ u\). \(\text{inputpos}(i)\) denotes the location of \(M\)'s input tape head at
     the \(i\)th step. \(\text{prev}(i)\) is the last step before \(i\) when \(M\)'s head was in the
     same cell on its work tape that it is during step \(i\). The reason this small amount of
     information suffices to check the correctness of \(z_i\) is that the contents of the current
     cell have not been affected between step \(\text{prev}(i)\) and step \(i\).

     Since \(M\) is a deterministic TM, for every triple of values
     to \(z_{i-1},y_{\text{inputpos}(i)}\), \(z_{\text{prev}(i)}\), there is at most one value
     of \(z_i\) that is correct. Thus there is some function \(F\) that maps \(\{0,1\}^{2c+1}\)
     to \(\{0,1\}^c\) s.t. a correct \(z_i\) satisfies
     \begin{equation*}
z_i=F(z_{i-1},z_{\text{prev}(i)},y_{\text{inputpos}(i)})
     \end{equation*}

     Because \(M\) is oblivious, the values \(\text{inputpos}(i)\) and \(\text{prev}(i)\) do not
     depend on the particular input \(i\). These indices can be computed in polynomial-time by
     simulating \(M\) on a trivial input.

     By eqref:eq:2.2 , \(x\in\{0,1\}^{n}\in L\) iff \(M(x\circ u)=1\) for
     some \(u\in\{0,1\}^{p(n)}\). The previous discussion shows this latter condition occurs iff
     there exists a string \(y\in\{0,1\}^{n+p(n)}\) and a sequence of strings
     \(z_1,\dots,z_{T(n)}\in\{0,1\}^c\) (where \(T(n)\) is the number of steps \(M\) takes on inputs
     of length \(n+p(n)\)) satisfying the following four conditions
     1. The first \(n\) bits of \(y\) are equal to \(x\)
     2. The string \(z_1\) encodes the initial snapshot of \(M\). That is, \(z_1\) encodes the
        triple \(\la\rhd,\Box,q_{\start}\ra\).
     3. For every \(i\in\{2,\dots,T(n)\}\), \(z_i=F(z_{i-1},z_{\text{prev}(i)},y_{\text{inputpos}(i)})\).
     4. The last string \(z_{T(n)}\) encodes a snapshot where the machine halts and outputs 1


     The formula \(\varphi_x\) will take variables \(y\in\{0,1\}^{n+p(n)}\)
     and \(z\in\{0,1\}^{cT(n)}\) and will verify that \(y,z\) satisfy the AND of these four
     conditions. Thus \(x\in L\Leftrightarrow\varphi_x\in\SAT\).

     Condition 1 can be expressed as a CNF formula of size \(4n\) . Conditions 2 and 4 each depend
     on \(c\) variables and hence by Proposition ref:lemma2.13 can be expressed by CNF formulae of
     size \(c2^c\). Condition 3, which is an AND of \(T(n)\) conditions each  depending on at most \(3c+1\)
     variables, can be expressedas a CNF formula of size at most \(T(n)(3c+1)2^{3c+1}\). Hence the AND of all
     these conditions can be expressed as a CNF formula of size d(n + T(n)) where d is some constant
     depending only on \(M\). Moreover, this CNF formula can be computedin time polynomial in the running
     time of \(M\).
     #+END_proof

     #+ATTR_LATEX: :options []
     #+BEGIN_lemma
     \(\SAT\le_p\TSAT\)
     #+END_lemma

     #+BEGIN_proof
     Suppose \varphi is a 4CNF. Let \(C\) be a clause of \varphi, say \(C=u_1\vee\baru_2\vee\baru_3\vee u_4\).
     We add a new variable \(z\) to the \varphi and replace \(C\) with the pair
     \(C_1=u_1\vee\baru_2\vee z\) and \(C_2=\baru_3\vee u_4\vee\barz\). If \(C\) is true, then there
     is an assignment to \(z\) that satisfies both \(C_1\) and \(C_2\). If \(C\) is false, then no
     matter what value we assign to \(z\) either \(C_1\) or \(C_2\) will be false.

     For every clause \(C\) of size \(k>3\), we change it into an equivalent pair of clauses \(C_1\)
     of size \(k-1\) and \(C_2\) of size 3.
     #+END_proof


*** The Web of Reductions
     #+ATTR_LATEX: :float H
     [[../images/ComputationalComplexity/6.png]]

     #+ATTR_LATEX: :options []
     #+BEGIN_theorem
     \(\INDSET\) is \(\NP\)-complete
     #+END_theorem

     #+BEGIN_proof
     Transform in polynomial time every \(m\)-clause 3CNF formula \varphi into a \(7m\)-vertex graph \(G\)

     #+ATTR_LATEX: :float H
     [[../images/ComputationalComplexity/7.png]]

     We associate a cluster of 7 vertices in \(G\) with each clause of \varphi. The vertices in a cluster
     associated with a clause \(C\) correspond to the seven possible satisfying partial assignments
     to the three variables on which \(C\) depends. For example, if \(C\)
     is \(\baru_2\vee\baru_5\vee u_7\), then the seven vertices in the cluster associated with \(C\)
     correspond to all partial assignments of the form \(u_1=a,u_2=b,u_3=c\) for a binary
     vector \(\la a,b,c\ra\neq\la1,1,0\ra\). We put an edge between two vertices of \(G\) if they
     correspond to inconsistent partial assignments. In addition, we put edges between every two
     vertices that are in the same cluster

     \varphi is satisfiable iff \(G\) has an independent set of size \(m\)
     #+END_proof

     We let \(\ZOIPROG\) be the set of satisfiable 0/1 integer programs.
     That is, a set of linear inequalities with rational coefficients over
     variables \(u_1,\dots,u_n\) is in \(\ZOIPROG\) if there is an assignment of numbers in \(\{0,1\}\)
     to \(u_1,\dots,u_n\) that satisfies it

     #+ATTR_LATEX: :options []
     #+BEGIN_theorem
     \(\ZOIPROG\)is \(\NP\)-complete

     Every CNF formula can be expressed as an integer program by expressing every clause as
     inequality. For example, the clause \(u_1\vee\baru_2\vee\baru_3\) can be expressed by
     \(u_1+(1-u_2)+(1-u_3)\ge1\).
     #+END_theorem

     A *Hamilton path* in a directed graph is a path that visits all vertices exactly once. Let
     \(\dHAMPATH\) denote the set of all directed graphs that contain such a path
     #+ATTR_LATEX: :options []
     #+BEGIN_theorem
     \(\dHAMPATH\) is \(\NP\)-complete
     #+END_theorem

     #+BEGIN_proof
     #+ATTR_LATEX: :float H
     [[../images/ComputationalComplexity/8.png]]

     The graph \(G\) has
     1. \(m\) vertices for each of \(\varphi\)'s clause \(c_1,\dots,c_m\)
     2. a special starting vertex \(v_{\start}\) and ending vertex \(v_{\tend}\)
     3. \(n\) "chains" of \(4m\) vertices corresponding to the \(n\) variables of \varphi . A chain is a
        set of vertices \(v_1,\dots,v_{4m}\) s.t. for every \(i\in[1,4m-1]\), \(v_i\)
        and \(v_{i+1}\) are connected by two edges in both directions


     If \(C\) contains the literal \(u_j\), then we take two neighboring
     vertices \(v_i\), \(v_{i+1}\) in the \(j\)th chain and put an edge from \(v_i\) to \(C\) and
     from \(C\) to \(v_{i+1}\). If \(C\) contains the literal \(\baru_j\) then we construct these
     edges in the opposite direction. When adding these edges, we never "reuse" a
     link \(v_i, v_{i+1}\) in a particular chain and always keep an unused link between every two
     used links.

     
     \(G\in\dHAMPATH\Rightarrow\varphi\in\SAT\). Suppose that \(G\) has an Hamiltonian path \(P\).
     We first note that the path \(P\) must start in \(v_{\start}\) and end at \(v_{\tend}\).
     Furthermore, we claim that \(P\) needs to traverse all the chains in order and, within each
     each chain, traverse it either in left-to-right order or right-to-left order.
     #+END_proof

*** Decision versus Search
     #+ATTR_LATEX: :options []
     #+BEGIN_theorem
     label:thm2.18
     Suppose that \(\bP=\NP\). Then for every \(\NP\) language \(L\) and a verifier TM \(M\)
     for \(L\), there is a polynomial-time TM \(B\) that on input \(x\in L\) outputs a certificate
     for \(x\).
     #+END_theorem

     #+BEGIN_proof
     We need to show that if \(\bP=\NP\) then for every polynomial-time TM \(M\) and
     polynomial \(p(n)\), there is a polynomial-time TM \(B\) with the following property: for every
     \(x\in\{0,1\}^n\) if there is \(u\in\{0,1\}^{p(n)}\) s.t. \(M(x,u)=1\) then \(\abs{B(x)}=p(n)\)
     and \(M(x,B(x))=1\)

     We start by showing the theorem for the case of \(\SAT\). In particular, we show that given an
     algorithm \(A\) that decides \(\SAT\), we can come up an algorithm \(B\) that on input a
     satisfiable CNF formula \varphi with \(n\) variables, finds a satisfying assignment for \varphi
     using \(2n+1\) calls to \(A\) and some additional polynomial-time computation.

     We first use \(A\) to check that the input formula is satisfiable. If so, we first
     substitute \(x_1=0\) and then \(x_1=1\) in \varphi and then use \(A\) to decide which of the two is
     satisfiable. Say the first is satisfiable. Then we fix \(x_1=0\). Continuing this way, we end
     up with an assignment

     To solve the search problem for an arbitrary \(\NP\)-language \(L\), we use the fact that the
     reduction of Theorem ref:thm2.10 from \(L\) to \(\SAT\)is actually a Levin reduction. This
     means that we have a polynomial-time computable function \(f\) s.t. we can map a satisfying
     assignment of \(f(x)\) into a certificate for \(x\).
     #+END_proof

     The theorem ref:thm2.18 shows that \(\SAT\) is *downward self-reducible*, which means that
     given an algorithm that solves \(\SAT\) on inputs of length smaller than \(n\) we can
     solve \(\SAT\) on inputs of length \(n\).

*** \textbf{CONP,EXP} and \textbf{NEXP}

     #+ATTR_LATEX: :options []
     #+BEGIN_definition
     label:def2.19
     \(\coNP=\{L:\barL\in\NP\}\)
     #+END_definition

     #+ATTR_LATEX: :options [alternative definition]
     #+BEGIN_definition
     label:def2.20
     For every \(L\subseteq\{0,1\}^*\), we say that \(L\in\coNP\) if there exists a
     polynomial \(p:\N\to\N\) and a polynomial-time TM \(M\) s.t. for every \(x\in\{0,1\}^*\)
     \begin{equation*}
x\in L \Leftrightarrow\forall u\in\{0,1\}^{p(\abs{x})},\; M(x,u)=1
     \end{equation*}
     #+END_definition

     #+ATTR_LATEX: :options []
     #+BEGIN_examplle
     The following language is \(\coNP\)-complete
     \begin{align*}
\TAUTOLOGY=\{\varphi:\varphi\text{ is a tautology}\}
     \end{align*}
     It's clearly in \(\coNP\) by Definition ref:def2.20 (Make \(u\) to be the all possible
     assignments). Modify the Cook-Levin reduction 
     from \(\barL\)(which is in \(\NP\)) to \(\SAT\). For every input \(x\in\{0,1\}^*\) that
     reduction produces a formula \(\varphi_x\) that is satisfiable iff \(x\in\barL\). Now consider
     the formula \(\neg\varphi_x\). It is in \(\TAUTOLOGY\) iff \(x\in L\)
     #+END_examplle

*** \(\EXP\) and \(\NEXP\)
     #+ATTR_LATEX: :options []
     #+BEGIN_theorem
     If \(\EXP\neq\NEXP\) then \(\bP\neq\NP\)
     #+END_theorem

     #+BEGIN_proof
     We prove the contrapositive: Assuming \(\bP=\NP\) we show \(\EXP=\NEXP\).
     Suppose \(L\in\NTIME(2^{n^c})\) and NDTM \(M\) decides it. We claim that the language
     \begin{equation*}
L_{\pad}=\left\{\la x,1^{2^{\abs{x}^c}}\ra:x\in L
\right\}
     \end{equation*}
     is in \(\NP\). Here is an NDTM for \(L_{\pad}\): Given \(y\), first check if there is a
     string \(z\) s.t. \(y=\la z,1^{2^{\abs{z}^c}}\ra\). If not, output 0. If \(y\) is of this form,
     then simulate \(M\) on \(z\) for \(2^{\abs{z}^c}\) steps and output its answer. The running
     time is polynomial in \(\abs{y}\), and hence \(L_{\pad}\in\NP\). Hence if \(\bP=\NP\)
     then \(L_{\pad}\in\bP\). But if \(L_{\pad}\) is in \(\bP\) then \(L\) is in \(\EXP\). To
     determine whether an input \(x\) is in \(L\), we just pad the input and decide whether it is
     in \(L_{\pad}\) using the polynomial-time machine for \(L_{\pad}\)
     #+END_proof

     
*** Exercise
     #+BEGIN_exercise
     label:ex2.11
     Argue at a high level that the following language is \(\NP\)-complete
     \begin{equation*}
\left\{\la\varphi,1^n\ra:\text{ math statement }\varphi
\text{ has a proof of size at most $n$ in the ZF system}
\right\}
     \end{equation*}
     #+END_exercise

     #+BEGIN_proof
     Essential part is to find a reduction.

     Idea: if there are \(n\) derivation rules, then we consider \(n\SAT\)
     #+END_proof
     
     #+BEGIN_exercise
     label:ex2.23
     Prove that \(\bP\subseteq\NP\cap\coNP\)
     #+END_exercise

     #+BEGIN_exercise
     label:ex2.24
     Prove that Definition ref:def2.19 and ref:def2.20 do indeed define the same class
     #+END_exercise

     #+BEGIN_proof
     Suppose \(\coNP=\{L:\barL\in\NP\}\).
     \begin{align*}
x\in L\in\coNP& \Leftrightarrow x\not\in\barL\in\NP\\
& \Leftrightarrow\neg\exists u\in\{0,1\}^{p(\abs{x})} M'(x,u)=1\\
&\Leftrightarrow\forall u\in\{0,1\}^{p(\abs{x})}M'(x,u)\neq1\\
&\Leftrightarrow\forall u\in\{0,1\}^{p(\abs{x})}M(x,u)=1\\
     \end{align*}
     where \(M'\) is a TM for \(\NP\) and \(M\) is a TM for \(\coNP\) by computing the value
     from \(M'\).

     Another direction is the same.
     #+END_proof

* Chap 4: Space Complexity
*** Definition of Space-Bounded Computation
    TM we use is
    #+ATTR_LATEX: :width .7\textwidth :float H
    #+NAME:
    #+CAPTION:
    [[../images/ComputationalComplexity/9.png]]

    #+ATTR_LATEX: :options [Space-bounded computation]
    #+BEGIN_definition
    Let \(S:\N\to\N\) and \(L\subseteq\{0,1\}^*\). We say that \(L\in\SPACE(s(n))\) if there is a
    constant \(c\) and a TM \(M\) deciding \(L\) s.t. at most \(c\cdot s(n)\) locations on \(M\)'s
    work tapes (excluding the input tape) are ever visited by \(M\)'s head during its computation on
    every input of length \(n\)

    Similarly we say that \(L\in\NSPACE(s(n))\) if there is an NDTM \(M\) deciding \(L\) that never
    uses more than \(c\cdot s(n)\) nonblank tape locations on length \(n\) inputs
    #+END_definition



    \(S:\N\to\N\) is *space-constructible* if there is a TM that computes \(S(\abs{x})\)
    in \(O(S(\abs{x}))\) space given \(x\) as input

    Since the TM's work tapes are separated from its input tape, it makes sense to consider
    space-bounded machines that use space less than the input length, namely, \(S(n)<n\). We will
    require however that \(S(n)>\log n\).

    \(\DTIME(S(n))\subseteq\SPACE(S(n))\) since a TM can access only one tape cell per step. But
    a \(\SPACE(S(n))\) machine can run for much longer than \(S(n)\) steps

    #+ATTR_LATEX: :options []
    #+BEGIN_theorem
    label:thm4.2
    For every space constructible \(S:\N\to\N\)
    \begin{equation*}
    \DTIME(S(n))\subseteq\SPACE(S(n))\subseteq\NSPACE(S(n))\subseteq\DTIME(2^{O(S(n))})
    \end{equation*}
    #+END_theorem


    We use the notion of a *configuration graph* of a Turing machine. Let \(M\) be a (deterministic or
    nondeterministic) TM. A *configuration* of a TM \(M\) consists of the contents of all nonblank
    entries of \(M\)'s tapes, along with its state and head position, at a particular point in its
    execution. For every space \(S(n)\) TM \(M\) and input \(x\in\{0,1\}^*\), the
    *configuration graph of \(M\) on input \(x\)*, denoted \(G_{M,x}\), is a directed graph whose nods
    correspond to all possible configuration of \(M\) where the input contains the value \(x\) and
    the work tapes have at most \(S(\abs{x})\) nonblank cells. The graph has a directed edge from a
    configuration \(C\) to a configuration \(C'\) if \(C'\) can be reached from \(C\) in one step
    according to \(M\)'s transition function. By modifying \(M\) to erase all its work tapes before
    halting, we can assume that there is only a single configuration \(C_{\accept}\) on which \(M\)
    halts and outputs 1.

    #+BEGIN_claim
    label:claim4.4
    Let \(G_{M,x}\) be the configuration graph of a space-\(S(n)\) machine \(M\) on some
     input \(x\) of length \(n\). Then
     1. Every vertex in \(G_{M,x}\) can be described using \(cS(n)\) bits for some constant \(c\)
        (depending on \(M\)'s alphabet size and number of tapes') and in particular, \(G_{M,x}\) has
        at most \(2^{cS(n)}\) nodes
     2. There is an \(O(S(n))\)-size CNF formula \(\varphi_{M,x}\) s.t. for every two
        strings \(C,C'\) \(\varphi_{M,x}(C,C')=1\) iff \(C\) and \(C'\) encodes two neighboring
        configuration in \(G_{M,x}\)
    #+END_claim

    #+ATTR_LATEX: :options [proof of theorem \ref{thm4.2}]
    #+BEGIN_proof
    By enumerating all possible configurations, we can construct the graph \(G_{M,x}\)
    in \(2^{O(S(n))}\)-times  and check whether \(C_{\start}\) is connected to \(C_{\accept}\)
    in \(G_{M,x}\) using the standard breadth-first search algorithm for connectivity
    #+END_proof

    #+ATTR_LATEX: :options []
    #+BEGIN_definition
    \begin{align*}
    \PSPACE&=\bigcup_{c>0}\SPACE(n^c)\\
    \NPSPACE&=\bigcup_{c>0}\NSPACE{n^c}\\
    \bL&=\SPACE(\log n)\\
    \NL&=\NSPACE(\log n)
    \end{align*}
    #+END_definition

    #+ATTR_LATEX: :options []
    #+BEGIN_examplle
    \(\TSAT\in\PSPACE\). The machine just uses the linear space to cycle through all \(2^k\)
    assignments to order. Once an assignment is checked, erase it on tape.

    In fact, \(\NP\subseteq\PSPACE\).
    #+END_examplle

    Let
    #+BEGIN_center
    \(\PATH=\{\la G,s,t\ra:G\) is a directed graph in which there is a path from \(s\) to \(t\}\)
    #+END_center
    Note that  \(\PATH\in\NL\).

    #+ATTR_LATEX: :options [Space Hierarchy Theorem]
    #+BEGIN_theorem
    If \(f,g\) are space-constructible functions satisfying \(f(n)=o(g(n))\), then
    \begin{equation*}
    \SPACE(f(n))\subsetneq\SPACE(g(n))
    \end{equation*}
    #+END_theorem
*** \(\PSPACE\) Completeness
    #+ATTR_LATEX: :options []
    #+BEGIN_definition
    A language \(L'\) is *\(\PSPACE\)-hard* if for every \(L\in\PSPACE\), \(L\le_p L'\). If in
    addition \(L'\in\PSPACE\) then \(L'\) is *\(\PSPACE\)-complete*
    #+END_definition

    #+ATTR_LATEX: :options [Quantified Boolean Formula]
    #+BEGIN_definition
    A *quantified Boolean formula* (QBF) is a formula of the form \(Q_1x_1\dots Q_nx_n\varphi(x_1,\dots,x_n)\) where
    each \(Q_i\)is one of the two quantifiers \(\forall\) or \(\exists\), \(x_1,\dots,x_n\) ranges over \(\{0,1\}\) and
    \varphi is a quantifier-free Boolean formula.
    #+END_definition

    Let \(\TQBF\) be the set of quantified Boolean formulae that are true
    #+ATTR_LATEX: :options []
    #+BEGIN_theorem
    label:thm4.13
    \(\TQBF\) is \(\PSPACE\)-complete
    #+END_theorem

    #+BEGIN_proof
    First we show that \(\TQBF\in\PSPACE\). Let
    \begin{equation*}
    \psi=Q_1x_1\dots Q_nx_n\varphi(x_1,\dots,x_n)
    \end{equation*}
    be a quantified Boolean formula with \(n\) variables, where we denote the size of \varphi by \(m\). We
    show a recursive algorithm \(A\) that can decide the truth of \psi in \(O(n+m)\) space.

    If \(n=0\) then \varphi can be evaluated in \(O(m)\) time and space, and so we assume \(n>0\).
    For \(b\in\{0,1\}\) denote by \(\psi\restriction_{x_1=b}\) the modification of \psi where the first
    quantifier \(Q_1\) is dropped and all occurrences of \(x_1\) are replaces with the constant \(b\).
    Algorithm \(A\) will works as follows: if \(Q_1=\exists\) then output 1 iff at least one
    of \(A(\psi\restriction_{x_1=0})\)  and \(A(\psi\restriction_{x_1=1})\) outputs 1. If \(Q_1=\forall\), then
    output 1 iff both  \(A(\psi\restriction_{x_1=0})\)  and \(A(\psi\restriction_{x_1=1})\) outputs 1.

    Let \(s_{n,m}\) denote the space \(A\) uses on formula with \(n\) variables and description
    size \(m\). The crucial point is - here we use the fact that space can be *reused* - that both
    recursive computations  \(A(\psi\restriction_{x_1=0})\)  and \(A(\psi\restriction_{x_1=1})\) can run in
    the same space. Thus assuming that \(A\) uses \(O(m)\) space to
    write  \(A(\psi\restriction_{x_1=b})\) for its recursive calls, we'll get that
    \(s_{n,m}=s_{n-1,m}+O(m)\) yielding \(s_{n,m}=O(n\cdot m)\)

    We now show that \(L\le_p\TQBF\) for every \(L\in\PSPACE\). Let \(M\) be a machine that
    decides \(L\) in \(S(n)\) space and let \(x\in\{0,1\}^n\). We show how to construct a quantified
    Boolean formula of size \(O(S(n)^2)\) that is true iff \(M\) accepts \(x\). Let \(m=O(S(n))\)
    denote the number of bits needed to encode a configuration of \(M\) on length \(n\). By Claim
    ref:claim4.4 there is a Boolean formula \(\varphi_{M,x}\) s.t. for every two
    strings \(C,C'\in\{0,1\}^m\) \(\varphi_{M,x}(C,C)=1\) iff \(C\) and \(C'\) encode two adjacent
    configurations in the configuration graph \(G_{M,x}\).

    let \(\psi_i(C,C')\) be true iff there is a path of length at most \(2^i\) from \(C\) to \(C'\)
    in \(G_{M,x}\). Note that \(\psi=\psi_m\) and \(\psi_0=\varphi_{M,x}\). The crucial point is
    \(\psi_i(C,C')=\exists C''\psi_{i-1}(C,C'')\wedge\psi_{i-1}(C'',C')\)

    But \(\psi_m\) has size about \(2^m\), which is not good. Instead, we use additional quantified
    variables to save on description size
    \begin{equation*}
    \exists C''\forall D_1\forall D_2((D_1=C\wedge D_2=C'')\vee(D_1=C''\wedge D_2=C'))\to \psi_{i-1}(D_1,D_2)
    \end{equation*}
    Note that \(size(\psi_i)\le size(\psi_{i-1})+O(m)\) and hence \(size(\psi_m)\le o(m^2)\)
    #+END_proof

    Since we don't require the graph in proof of Theorem ref:thm4.13 to have out-degree one, it
    actually yields a stronger statement
    \begin{equation*}
    \TQBF\in\NPSPACE
    \end{equation*}

    #+ATTR_LATEX: :options [Savitch's Theorem]
    #+BEGIN_theorem
    For any space-constructible \(S:\N\to\N\) with \(S(n)\ge\log n\), \(\NSPACE(S(n))\subseteq\SPACE(S(n)^2)\)
    #+END_theorem

    #+BEGIN_proof
    Let \(L\in\NSPACE(S(n))\) be a language decided by a TM \(M\) s.t. for every \(x\in\{0,1\}^n\), the
    configuration graph \(G=G_{M,x}\) has at most \(M=2^{O(S(n))}\) vertices, and determining
    whether \(x\in L\)is equivalent to determining whether \(C_{\accept}\) can be reached
    from \(C_{\start}\) in this graph. We describe a recursive procedure \(\text{REACH?}(u,v,i)\)
    that returns "YES" if there is a path from \(u\) to \(v\) of length at most \(2^i\) and "NO"
    otherwise.
    \begin{equation*}
    \text{REACH?}(u,v,i)=\exists w(\text{REACH?}(u,w,i-1)\vee\text{REACH?}(w,v,i-1))
    \end{equation*}
    Let \(s_{M,i}\) be the space complexity of \(\text{REACH?}(u,v,i)\),
    then \(s_{M,i}=s_{M,i-1}+O(\log M)\) (since we need to enumerate all \(w\) in TM, the space we
    need is \(O(\log M)\)) and thus
    \(s_{M,\log M}=O(\log^2 M)=O(S(n)^2)\)

    #+END_proof

    #+ATTR_LATEX: :options [The QBF game]
    #+BEGIN_examplle
    The "board" for the QBF game is a Boolean formula \varphi whose free variables are \(x_1,\dots,x_{2n}\).
    player 1 will pick values for the odd-numbered variables. We say player 1 wins iff at the end
    \(\varphi(x_1,\dots,x_{2n})\) is true

    In order for player 1 to have a *winning strategy* he must have a way to win for all possible
    sequences of moves by player 2, namely, if
    \begin{equation*}
    \exists x_1\forall x_2 \exists x_3\forall x_4\dots\forall x_{2n}\varphi(x_1,\dots,x_{2n})
    \end{equation*}
    Thus deciding whether player 1 has a winning strategy for a given board in the QBF game is \(\PSPACE\)-complete.
    #+END_examplle
*** \(\NL\) Completeness

    We cannot use the polynomial-time reduction since \(\bL\subseteq\NL\subseteq\bP\) (cf. Exercise ref:ex4.3)

    #+ATTR_LATEX: :options [logspace reduction and \(\NL\)-completeness]
    #+BEGIN_definition
    A function \(f:\{0,1\}^*\to\{0,1\}^*\) is *implicitly logspace computable*, if \(f\) is polynomially
    bounded (i.e., there is some \(c\) s.t. \(\abs{f(x)}\le\abs{x}^c\) for every \(x\in\{0,1\}^*\)) and the
    language \(L_f=\{\la x,i\ra\mid f(x)_i=1\}\) and \(L_f'=\{\la x,i\ra\mid i\le\abs{f(x)}\}\) are in \(\bL\)

    A language \(B\) is *logspace reducible* to language \(C\), denoted by \(B\le_lC\) if there is a
    function \(f:\{0,1\}^*\to\{0,1\}^*\) that is implicitly logspace computable and \(x\in B\)
    iff \(f(x)\in C\) for every \(x\in\{0,1\}^*\).

    We say that \(C\) is *\(\NL\)-complete* if it is in \(\NL\) and for every \(B\in\NL\), \(B\le_lC\)
    #+END_definition

    Another way(used by several texts) to think of logspace reductions is to imagine that the
    reduction is given
    a separate "write-once" output tape, on which it can either
    write a bit or move to the right but never move left or read the bits it wrote down
    previously.The two notions are easily proved to be equivalent (seeExercise ref:ex4.8).

    #+ATTR_LATEX: :options []
    #+BEGIN_lemma
    1. If \(B\le_lC\) and \(C\le_lD\) then \(B\le_lD\)
    2. if \(B\le_lC\) and \(C\in\bL\) then \(B\in\bL\)
    #+END_lemma

    #+BEGIN_proof
    We prove that if \(f,g\) are two implicitly logspace computable functions, then so
    if \(h(x)=g(f(x))\). Part 2 follows by letting \(f\) be the reduction from \(B\) to \(C\)
    and \(g\) be the characteristic function of \(C\) (i.e., \(g(y)=1\) iff \(y\in C\))

    Let \(M_f,M_g\) be the logspace machines that compute the mappings \(x,i\mapsto f(x)_i\)
    and \(y,j\mapsto g(y)_i\) respectively. We construct a machine \(M_h\) that given input \(x,j\)
    with \(j\le\abs{g(f(x))}\) outputs \(g(f(x))_j\)

    #+ATTR_LATEX: :width .9\textwidth :float H
    #+NAME:
    #+CAPTION:
    [[../images/ComputationalComplexity/10.png]]

    \(M_h\) always maintains on its work tape the index, say \(i\), of the cell on the fictitious
    tape that \(M_g\) is currently reading, this requires only \(\log\abs{f(x)}\) space. To compute
    for one step, \(M_g\) needs to know the contents of the cell, in other words, \(f(x)|_i\). At
    this point \(M_h\) temporarily suspends its simulation of \(M_g\) (copying the contents
    of \(M_g\)'s work tape to a safe place on its own work tape) and invokes \(M_f\) on
    inputs \(x,i\) to get \(f(x)|_i\). Then it resumes its simulation of \(M_g\) using this bit. The
    total space \(M_h\) uses is
    \(O(\log\abs{g(f(x))}+s(\abs{x})+s'(\abs{f(x)}))\). Since \(\abs{f(x)}\le poly(x)\), this
    expression is \(O(\log\abs{x})\)
    #+END_proof

    #+ATTR_LATEX: :options []
    #+BEGIN_theorem
    \(\PATH\) is \(\NL\)-complete
    #+END_theorem

    #+BEGIN_proof
    Let \(L\in\NL\) and \(M\) be a machine that decides it in space \(O(\log n)\). We describe a
    logspace implicitly computable function \(f\) that reduces \(L\) to \(\PATH\)

    For any input \(x\) of size \(n\), \(f(x)\) will be the configuration graph \(G_{M,x}\) whose
    nodes are all possible \(2^{O(\log n)}\) (since \(L\in\NL\)) configurations of the machine on input \(x\), along
    with the start configuration \(C_{\start}\)and \(C_{\accept}\). The graph is represented by an
    adjacency matrix. To finish the proof, we need to show that this adjacency matrix can be
    computed by a logspace reduction. Given \(\la C,C'\ra\) a deterministic machine can in space
    \(O(\abs{C}+\abs{C'})=O(\log\abs{x})\) examine \(C,C'\) and check whether they are neighbor
    #+END_proof

    #+ATTR_LATEX: :options [\(\NL\)-alternative definition]
    #+BEGIN_definition
    A language \(L\in \NL\) if there exists a deterministic TM \(M\) (called the *verifier*) with an
    additional special read-once input tape, and a polynomial \(p:\N\to\N\) s.t. for every \(x\in\{0,1\}^*\)
    \begin{equation*}
    x\in L\Leftrightarrow\exists u\in\{0,1\}^{p(\abs{x})}\text{ s.t. }M(x,u)=1
    \end{equation*}
    where by \(M(x,u)\) we note the output of \(M\) where \(x\) is placed on its input tape
    and \(u\) is placed on its special read-once tape, and \(M\) uses at most \(O(\log\abs{x})\)
    space on its read-write tapes for every input \(x\)
    #+END_definition

    This definition is an alternative definition of \(\NL\) since read-once access to bits in a
    certificate is just an alternative way to view _nondeterministic choices during a computation_

    Note that we have \(\ove{\PATH}\in\coNL\)

    #+ATTR_LATEX: :options [Immerman-Szelepcsényi Theorem]
    #+BEGIN_theorem
    \(\ove{\PATH}\in\NL\)
    #+END_theorem

    #+BEGIN_proof
    By the certificate-based definition of \(\NL\), it suffices to show an \(O(\log n)\)-space
    verification algorithm \(A\) s.t. for every \(n\)-vertex graph \(G\) and vertices \(s\)
    and \(t\), there exists a polynomial certificate \(u\) s.t. \(A(\la G,s,t\ra,u)=1\) iff \(t\) is
    not reachable from \(s\) in \(G\). Here \(A\) has only read-once access to \(u\). For
    simplicity, we identify \(G\)'s vertices with the numbers \(\{1,\dots,n\}\)

    Let \(C_i\) be the set of vertices that are reachable from \(s\) in \(G\) within at most \(i\)
    steps. For every \(i\in[n]\) and vertex \(v\), the following is a certificate that \(v\) is
    in \(C_i\): the sequence of vertices \(v_1,\dots,v_k\) along the path from \(s\) to \(v\),
    where \(k\le i\). Note that the certificate is indeed of size at most polynomial in \(n\). The
    algorithm can check the certificate using read-once access by verifying
    1. \(v_0=s\)
    2. for \(j>0\) there is an edge from \(v_{j-1}\) to \(v_j\)
    3. \(v_k=v\)
    4. the path ends within at most \(i\) steps.


    Now we use the fact that membership in \(C_i\) is certifiable to design two more types of
    certificates
    1. A certificate that a vertex \(v\) is not in \(C_i\), assuming the verifier has already been
       told the size of \(C_i\)
    2. A certificate that \(\abs{C_i}=c\) for some number \(c\), assuming the algorithm has already
       been convinced about the size of \(C_{i-1}\)


    Since \(C_0=\{s\}\), we can provide the second kind of certificate to the verifier iteratively to
    convince it of the sizes of the sets \(C_1,\dots,C_n\). Finally since \(C_n\) is just the set of all
    vertices reachable from \(s\), and the verifier has been convinced of \(\abs{C_n}\), we can use
    the first kind of certificate to convince the verifier \(t\not\in C_n\).

    Certifying that \(v\not\in C_i\) given \(\abs{C_i}\). The certificate is simply the list of
    certificates to the effects that \(u\in C_i\) for every \(u\in C_i\).

    Certifying that \(v\not\in C_i\), given \(\abs{C_{i-1}}\). like above.

    Certifying that \(\abs{C_i}=c\) given \(\abs{C_{i-1}}\).
    #+END_proof

    #+ATTR_LATEX: :options []
    #+BEGIN_corollary
    For every space constructible \(S(n)>\log n\), \(\NSPACE(S(n))=\coNSPACE(S(n))\)
    #+END_corollary

*** Exericse
    #+BEGIN_exercise
    label:ex4.3
    Prove that every language \(L\) that is not the empty or \(\{0,1\}^*\) is complete for \(\NL\)
    under polynomial-time Karp reductions
    #+END_exercise

    #+BEGIN_exercise
    label:ex4.8
    Define \(f:\{0,1\}^*\to\{0,1\}^*\) to be writ
    #+END_exercise
