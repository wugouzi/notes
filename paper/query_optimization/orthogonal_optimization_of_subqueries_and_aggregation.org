#+title: Orthogonal Optimization Of Subqueries And Aggregationn

#+AUTHOR:
#+LATEX_HEADER: \input{/Users/wu/notes/preamble.tex}
#+EXPORT_FILE_NAME: ../../latex/papers/query_optimization/orthogonal_optimization_of_subqueries_and_aggregation.tex
#+LATEX_HEADER: \graphicspath{{../../../paper/query_optimization/}}
#+LATEX_HEADER: \DeclareMathOperator{\SA}{\mathcal{SA}}
#+LATEX_HEADER: \DeclareMathOperator{LOJ}{\text{LOG}}
#+LATEX_HEADER: \definecolor{mintedbg}{rgb}{0.99,0.99,0.99}
#+LATEX_HEADER: \usepackage[cachedir=\detokenize{~/miscellaneous/trash}]{minted}
#+LATEX_HEADER: \setminted{breaklines,
#+LATEX_HEADER:   mathescape,
#+LATEX_HEADER:   bgcolor=mintedbg,
#+LATEX_HEADER:   fontsize=\footnotesize,
#+LATEX_HEADER:   frame=single,
#+LATEX_HEADER:   linenos}
#+OPTIONS: toc:nil
#+STARTUP: shrink

* Introduction
        In this paper, we present subquery and aggregation techniques implemented in Microsoft SQL Server.

** Standard subquery execution strategies
        Before describing subquery strategies in detail, it is important to clarify the two forms of
        aggregation in SQL, whose behavior diverges on an empty input.

        “Vector” aggregation specifies grouping columns as well as aggregates to compute.
        #+begin_src sql
select o_orderdate, sum(o_totalprice)
from orders
group by o_orderdate
        #+end_src

        And there are querys that /always returns exactly one row/:
        #+begin_src sql
select sum(o_totalprice) from orders
        #+end_src

        In algebraic expressions we denote vector aggregate as \(\calg_{A,F}\), where \(A\) are the grouping
        columns and \(F\) are the aggregates to compute; and denote scalar aggregate as \(\calg^1_F\)

        We review standard subquery execution strategies using the following SQL query, which finds customers
        who have ordered more than $1,000,000.
        #+begin_src sql
-- Q1
select c_custkey
from customer
where 100000 <
      (select sum(o_totalprice)
       from orders
       where o_custkey = c_custkey)
        #+end_src

        *Outerjoin, then aggregate*:
        #+begin_src sql
select c_custkey
from customer left outer join
     orders on o_custkey = c_custkey
group by c_custkey
having 1000000 < sum(o_totalprice)
        #+end_src

        *Aggregate, then join*:
        #+begin_src sql
select c_custkey
from customer,
     (select o_custkey from orders
      group by c_custkey
      having 1000000 < sum(o_totalprice))
     as aggresult
where o_custkey = c_custkey
        #+end_src

** Our technique: Use primitive, orthogonal pieces
        #+ATTR_LATEX: :width .5\textwidth :float nil
        #+NAME: 1
        #+CAPTION: Primitives connecting different execution strategies
        [[../../images/papers/95.png]]

        By implementing all these orthogonal techniques, the query processor should then pro- duce the same
        efficient execution plan for the various equiv- alent SQL formulations we have listed above, achieving
        a degree of syntax-independence.

        * *Algebrize into initial operator tree*
        * *Remove correlations*
        * *Simplify outerjoin*
        * *Reorder GroupBy*
** A useful tool: Represent parameterized execution algebraically
        *Apply* takes a relational input \(R\) and a parameterized expression \(E(r)\); it evaluates expression
        \(E\) for each row \(r\in R\), and collects the results. Formally,
        \begin{equation*}
        R\cala^{\otimes}E=\bigcup_{r\in R}(\{r\}\otimes E(r))
        \end{equation*}
        where \(\otimes\) is either cross product, left outerjoin, left semijoin, or left antijoin.

        The most primitive form is \(\cala^\times\), and cross product is assumed if no join variant is
        specified.

        All operators used in this paper are bag-oriented, and we assume no automatic removal of duplicates.
        In particular, the union operator above is ~UNION ALL~. Duplicates are removed explicitly using
        ~DISTINCT~.

        Now Q1 is like
        #+ATTR_LATEX: :width .5\textwidth :float nil
        #+NAME: 2
        #+CAPTION: Subquery execution using Apply
        [[../../images/papers/96.png]]

        Apply works on expressions that take scalar (or row-valued) parameters. A second useful construct is
        *SegmentApply*, which deals with expressions using /table/-valued parameters. It takes a relation input
        \(R\), a parameterized expression \(E(S)\), and a set of segmenting columns \(A\) from \(R\). It
        creates segments of \(R\) using columns \(A\), much like GroupBy, and for each such segment \(S\) it
        executes \(E(S)\). Formally,
        \begin{equation*}
        R\SA_AE=\bigcup_{a}(\{a\}\times E(\sigma_{A=a}R))
        \end{equation*}
        where \(a\) takes all values in the domain of \(A\).
* Representing and normalizing subqueries
** Direct algebraic representation with mutual recursion
** Algebraic representation with Apply
** Removal of Apply
        \begin{align*}
        R\cala^{\otimes}E&=R\otimes_{\text{true}}E\tag{1}\\
        &\hspace{-0.7cm}\text{if no parameters in \(E\) resolved from \(R\)}\\
        R\cala^{\otimes}(\sigma_pE)&=R\otimes_pE\tag{2}\\
        &\hspace{-0.7cm}\text{if no parameters in \(E\) resolved from \(R\)}\\
        R\cala^\times(\sigma_pE)&=\sigma_p(R\cala^\times E)\tag{3}\\
        R\cala^\times(\pi_vE)&=\pi_{v\cup\text{columns}(R)}(R\cala^\times E)\tag{4}\\
        R\cala^\times(E_1\cup E_2)&=(R\cala^\times E_1)\cup(R\cala^\times E_2)\tag{5}\\
        R\cala^\times(E_1- E_2)&=(R\cala^\times E_1)-(R\cala^\times E_2)\tag{6}\\
        R\cala^\times(E_1\times E_2)&=(R\cala^\times E_1)\bowtie_{R.key}(R\cala^\times E_2)\tag{7}\\
        R\cala^\times(\calg_{A,F}E)&=\calg_{A\cup\text{columns}(R),F}(R\cala^\times E)\tag{8}\\
        R\cala^\times(\calg^1_FE)&=\calg_{\text{columns}(R),F'}(R\cala^{LOJ}E)\tag{9}
        \end{align*}


        In (9), \(F'\) contains aggregates in \(F\) expressed over a single-column - for example, if \(F\) is
        ~COUNT(*)~, then \(F'\) is ~COUNT(C)~ for some not-nullable column \(C\) from \(E\). It is valid for all
        aggregates s.t. \(agg(\emptyset)=agg(\{null\})\), which is true for SQL aggregates.

        LOJ is left outerjoin

        The proof is in [[cite:&galindo-legaria2000parameterized]]
** All SQL subqueries
        For boolean-valued subqueries, i.e., ~EXISTS~, ~NOT EXISTS~, ~IN~ subquery, and quantified comparisons, the
        subquery can be rewritten as a scalar ~COUNT~ aggregate. From the utilization context of the aggregate
        result, either equal to zero or greater than zero, it is possible for the aggregate operator to stop
        requesting rows as soon as one has bee found, since additional rows do not affect the result of the
        comparison.

        A common case that is further optimized is when a relational select has an existential subquery as its
        only predicate. In this case, the complete select operator is turned into Apply-semijoin for /exists/,
        or Apply-antisemijoin for /not exists/. Such Apply is then converted into a non-correlated expression,
        if possible, using Identify (2).

        There are two scenarios where normalization into standard relational algebra operators is hindered in
        a fundamental way. We call those *exception subqueries* and they require scalar-specific features.
        Consider the following query.
        #+begin_src sql
-- Q2
select c_name,
       (select o_orderkey from orders
        where o_custkey = c_custkey)
from customer
        #+end_src

        For every customer, output the customer name, and the result of a subquery that retrieves an oderkey.
        There are three cases: If exactly one row is returned from the subquery, then such value is used in
        the scalar expression; if no rows are returned, then null is used; finally, if more than one row is
        returned, then a run-time error is generated. We call such operator ~Max1row~.
** Subquery classes
*** Class 1. Subqueries that can be removed with no additional common subexpressions
        In general, removing Apply requires introduction of additional common subexpressions. E.g., Identity
        (5) introduces two copies of \(R\).

        The common case of subqueries that are formed by a simple select/project/join/aggregate block are easy
        to handle.
*** Class 2. Subqueries that are removed by introducing common subexpressions
        It is hard to formulate a short, meaningful query that fits in this class, using the TPCH schema.
*** Class 3. Exception subqueries
* Comprehensive optimization of aggregation
** Reordering GroupBy
        We will denote GroupBy as \(\calg_{A,F}\), where \(A\) is the set of grouping columns and \(F\) are
        the aggregate functions.

        We can move a filter around a GroupBy iff all the columns used in the filter are functionally
        determined by the grouping columns in the input relation.

        A GroupBy can be pushed below a join if the grouping columns, the aggregate calculations and the join
        predicate each satisfy certain conditions. Suppose we have a GroupBy above a join of two relations,
        i.e., \(\calg_{A,F}(S\bowtie_pR)\), and we want to push the GroupBy below the join so that the
        relation \(R\) is aggregated before it is joined, i.e.,
        \begin{equation*}
        S\bowtie_p(\calg_{A\cup\text{columns}(p)-\text{columns}(S),F}R)
        \end{equation*}
        #+LATEX: \wu{
        Assuming \(S\) and \(R\) have no common columns, and \(p\) has columns from \(S\), so we need to
        filter them out.
        #+LATEX: }
        This is feasible iff the following conditions are met:
        1. If a column used in the join predicate \(p\) is defined by the relation \(R\) then it is part of
           the grouping columns
        2. The key of the relation \(R\) \wu{typo in the paper} is part of the grouping columns
        3. The aggregate expressions only use columns defined by the relation \(R\)

        Pulling a GroupBy above a join is a lot easier. All that is required is that the relation being joined
        has a key and that the join predicate does not use the results of the aggregate functions.
        \begin{equation*}
        S\bowtie_p(\calg_{A,F}R)=\calg_{A\cup\text{columns}(S),F}(S\bowtie_pR)
        \end{equation*}

        One can think of semijoins and antisemijoins as filters since they include or exclude rows of a
        relation based on the column values. The conditions necessary to reorder these operators around
** Moving GroupBy around an outerjoin
        Removing correlations for scalar valued subqueries results in an outerjoin followed by a GroupBy.

        In order to push a GroupBy below an outer join the join predicate, grouping columns and the aggregate
        calculations once again have to meet the three conditions mentioned above. The only difference is that
        an extra project may have to be added above the outerjoin if the aggregate expressions do not meet a
        certain condition.

        The result of an outerjoin has two types of rows vis. those that match, and those that do not and are
        padded with NULLs. We know that our grouping columns include a key of the outer relation. This implies
        that a group can never have both matched and unmatched rows. For the rows that match, correctness can
        be proved by using the same argument as join. For the rows that do not match, early aggregation means
        that they will not be aggregated at all. This is where the extra condition and the optional project
        comes in.

        In the result of an outerjoin, an unmatched row appears exactly once. Therefore given that our
        grouping columns include the key of the outer relation, a group that has an unmatched row cannot have
        any other row. The aggregate functions use only the columns from the non-outer relation. For an
        unmatched row all these columns are NULL. Therefore the property of aggregate expressions that is
        important to us is the result of applying it to NULLs. If the result is NULL as it is for most simple
        aggregate expressions, we need do nothing more. The outerjoin will automatically provide the NULLs we
        need. For the aggregate expressions which do not result in a NULL, we need to add a project which for
        each unmatched row sets the aggregate result to the appropriate constant value. Note that this
        constant can be calculated at compile time. For ~count(*)~, the value of this constant is zero.

        Formally, we have
        \begin{equation*}
        \calg_{A,F}(S\LOJ_pR)=\pi_c(S\LOJ_p(\calg_{A-\text{columns}(S),F}R))
        \end{equation*}
** Local Aggregates
* Problems


* References
<<bibliographystyle link>>
bibliographystyle:alpha

\bibliography{/Users/wu/notes/notes/references.bib}
