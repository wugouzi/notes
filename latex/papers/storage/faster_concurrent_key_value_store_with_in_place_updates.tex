% Created 2025-09-12 Fri 18:00
% Intended LaTeX compiler: xelatex
\documentclass[11pt]{article}
\usepackage{capt-of}
\usepackage{hyperref}
\input{/Users/wu/notes/preamble.tex}
\graphicspath{{../../../paper/storage/}}

%% ox-latex features:
%   !announce-start, !guess-pollyglossia, !guess-babel, !guess-inputenc, caption,
%   image, !announce-end.

\usepackage{capt-of}

\usepackage{graphicx}

%% end ox-latex features


\date{\today}
\title{Faster: A Concurrent Key Value Store with In-Place Updates}
\hypersetup{
 pdfauthor={},
 pdftitle={Faster: A Concurrent Key Value Store with In-Place Updates},
 pdfkeywords={},
 pdfsubject={},
 pdfcreator={},
 pdflang={English}}
\begin{document}

\maketitle
\section{Introduction}
\label{sec:org88afd99}
\begin{itemize}
\item Augment standard epoch-based synchronization into a generic framework that facilitates lazy
propagation of global changes to all threads via trigger actions.
\item Concurrent latch-free resizable cache-friendly hash index
\item log-structuring
\end{itemize}
\section{System Overview}
\label{sec:org2195c92}
\subsection{Architecture}
\label{sec:orgbee3b4d}
\begin{center}
\includegraphics[width=.8\textwidth]{../../images/papers/219.png}
\label{}
\end{center}

The hash bucket is a cache-line sized array of hash bucket entries. Each entry includes some metadata
and an address provided by a record allocator. The record allocator stores and manages individual
records. Hash collisions that are not resolved at the index level are handled by organizing records as
a linked-list. Each record consists of a record header, key, and value. Keys and values may be fixed
or variable-sized. The header contains some metadata and a pointer to the previous record in the
linked-list.

Note that keys are not part of the Faster hash index, unlike many traditional designs, which provides
two benefits:
\begin{itemize}
\item It reduces the in-memory footprint of the hash index, allowing us to retain it entirely in memory.
\item It separates user data and index metadata, which allows us to mix and match the hash index with
different record allocators.
\end{itemize}
\subsection{User Interface}
\label{sec:org1c78167}
\begin{itemize}
\item Read
\item Upsert
\item RMW
\item Delete
\end{itemize}
\subsection{Epoch Protection Framework}
\label{sec:orgc6db96f}
We extend the idea of multi-threaded epoch protection into a framework enabling lazy synchronization
over arbitrary global actions. While systems like Silo, Masstree and Bw-Tree have used epochs for
specific purposes, we extend it to a generic framework that can serve as a building block for Faster
and other parallel systems.

\emph{Epoch Basics}. The system maintains a shared atomic counter \(\bE\), called the \textbf{current epoch}, that
can be incremented by any thread. Every thread \(T\) has a thread-local version of \(\bE\), denoted by
\(E_T\). Threads refresh their local epoch values periodically. All thread-local epoch values \(E_T\)
are stored in a shared epoch table, with one cache-line per thread. An epoch \(c\) is said to be \textbf{safe},
if all threads have a strictly higher thread-local value than \(c\), i.e., \(\forall T:E_T>c\). Note
that if epoch \(c\) is safe, all epochs less than \(c\) are safe as well. We additionally maintain a
global counter \(\bE_s\), which tracks the current maximal safe epoch. \(\bE_s\) is computed by
scanning all entries in the epoch table and is updated whenever a thread refreshes its epoch. The
system maintains the following invariant:
\begin{equation*}
\forall T:\bE_s<E_T<\bE
\end{equation*}


\emph{Trigger Actions}. We augment the basic epoch framework with the ability to execute arbitrary global
actions when an epoch becomes safe using trigger actions. When incrementing the current epoch, say
from \(c\) to \(c+1\), threads can additionally associate an action that will be triggered by the
system at a future instant of time when epoch \(c\) is safe. This is enabled using the drain-list, a
list of \(\la epoch,action\ra\) pairs, where action is the callback code fragment that must be invoked
after epoch is safe. It is implemented using a small array that is scanned for actions ready to be
triggered whenever \(\bE_s\) is updated. We use atomic compare-and-swap on the array to ensure an
action is executed exactly once. We recompute \(\bE_s\) and scan through the drain-list only when
there is a change in current epoch, to enhance scalability.
\subsection{Using the Epoch Framework}
\label{sec:org72926d2}
We expose the epoch protection framework using the following four operations that can be invoked by
any thread \(T\):
\begin{itemize}
\item \texttt{Acquire}: Reserve an entry for \(T\) and set \(E_T\) to \(\bE\)
\item \texttt{Refresh}: update \(E_T\) to \(\bE\), \(\bE_s\) to current maximal safe epoch and trigger any ready
actions in the drain-list
\item \texttt{BumpEpoch(Action)}: Increment counter \(\bE\) from current value \(c\) to \((c+1)\) and add
\(\la c,Action\ra\) to drain-list
\item \texttt{Release}: Remove entry for \(T\) from epoch table
\end{itemize}

Epochs with trigger actions can be used to simplify lazy synchronization in parallel systems. Consider
a canonical example, where a function \texttt{active-now} must be invoked when a shared variable status is
updated to \texttt{active}. A thread updates status to \texttt{active} atomically and bumps the epoch with \texttt{active-now} as
the trigger action. Not all threads will observe this change in status immediately. However, all of
them are guaranteed to have observed it when they refresh their epochs (due to sequential memory
consistency using memory fences). Thus, \texttt{active-now} will be invoked only after all threads see the
status to be active and hence is safe.

We use the epoch framework in Faster to coordinate system operations such as memory-safe garbage
collection, index resizing, circular buffer maintenance and page flushing, shared log page boundary
maintenance, and checkpointing.
\subsection{Lifecycle of a Faster Thread}
\label{sec:orgc8f8766}
We use Faster to implement a \textbf{count store}, in which a set of Faster user threads increment the counter
associated with incoming key requests. A thread calls \texttt{Acquire} to register itself with the epoch
mechanism. Next, it issues a sequence of user operations, along with periodic invocations of \texttt{Refresh}
(e.g., every 256 operations) to move the thread to current epoch, and \texttt{CompletePending} (e.g., every 64K
operations) to handle any prior pending operations. Finally, the thread calls \texttt{Release} to deregister
itself from using Faster.
\section{The Faster Hash Index}
\label{sec:org806f6e3}
We assume a 64-bit machine with 64-byte cache lines.
\subsection{Index Organization}
\label{sec:orgc17a503}
\begin{center}
\includegraphics[width=.8\textwidth]{../../images/papers/220.png}
\label{f2}
\end{center}

The Faster index is a cache-aligned array of \(2^k\) hash buckets, where each bucket has the size and
alignment of a cache line. Thus, a 64-byte bucket consists of seven 8-byte hash bucket entries and one
8-byte entry to serve as an overflow bucket pointer. Each overflow bucket has the size and alignment
of a cache line as well, and is allocated on demand using an in-memory allocator.

The choice of 8-byte entries is critical, as it allows us to operate latch-free on the entries using
64-bit atomic compare-and-swap operations. On a 64-bit machine, physical addresses typically take up
fewer than 64 bits; e.g., Intel machines use 48-bit pointers. Thus, we can steal the additional bits
for index operations (at least one bit is required for Faster). We use 48-bit pointers in the rest of
the paper, but note that we can support pointers up to 63 bits long.

Each hash bucket entry (\ref{f2}) consists of three parts: a tag (15 bits), a tentative bit, and the
address (48 bits). An entry with value 0 (zero) indicates an empty slot. In an index with 2k hash
buckets, the tag is used to increase the effective hashing resolution of the index from \(k\) bits to
\(k+15\) bits, which improves performance by reducing hash collisions. The hash bucket for a key with
hash value \(h\) is first identified using the first \(k\) bits of \(h\), called the offset of
\(h\).The next 15 bits of \(h\) are called the tag of \(h\). Tags only serve to increase the hashing
resolution and may be smaller, or removed entirely, depending on the size of the address. The
tentative bit is necessary for insert, and will be covered shortly.
\subsection{Index Operations}
\label{sec:orgad9ee92}
Consider the case where a tag does not exist in the bucket, and a new entry has to be inserted.
However, two threads could concurrently insert the same tag at two \emph{different} empty slots in the
bucket.

\begin{center}
\includegraphics[width=.8\textwidth]{../../images/papers/221.png}
\label{f3}
\end{center}

As a workaround, consider a solution where every thread scans the bucket from left to right, and
deterministically chooses the first empty entry as the target. They will compete for the insert using
compare-and-swap and only one will succeed. Even this approach violates the invariant in presence of
deletes, as shown in Fig. \ref{f3}a. It can be shown that this problem exists with any algorithm that
independently chooses a slot and inserts directly: to see why, note that just before thread T1 does a
compare-and-swap, it may get swapped out and the database state may change arbitrarily, including
another slot with the same tag.

While locking the bucket is a possible (but heavy) solution, Faster uses a latch-free two-phase insert
algorithm that leverages the tentative bit entry. A thread finds an empty slot and inserts the record
with the tentative bit set. Entries with a set tentative bit are deemed invisible to concurrent reads
and updates. We then re-scan the bucket (note that it already exists in our cache) to check if there
is another tentative entry for the same tag; if yes, we back off and retry. Otherwise, we reset the
tentative bit to finalize the insert. Since every thread follows this two-phase approach, we are
guaranteed to maintain our index invariant. To see why, Fig. \ref{f3}b shows the ordering of operations
by  two threads: there exists no interleaving that could result in duplicate non-tentative tags.

\wu{
Consider only two slots in a bucket
\begin{enumerate}
\item find a new slot
\item (atomic) cas
\item (atomic) get another slot's value
\item check ifs the same key
\item (atomic) cas
\end{enumerate}


Now suppose the key has two slots resulted by two inserts \(i_1\) and \(i_2\) and \(i_1.5\to i2.5\)

Because \(i_1.3\to i_1.5\), we have \(i_1.3\to i_2.2\to i_2.4\). But now \(i_2\)  can get \(i_1\)'s
result and cannot succeed.
}
\subsection{Resizing and Checkpointing the Index}
\label{sec:org005a54c}
\section{An In-Memory Key-Value Store}
\label{sec:orgbf3efe4}
\subsection{Operations with In-Memory Allocator}
\label{sec:org221310e}
\section{Problems}
\label{sec:orgc83764a}


\section{References}
\label{sec:org9d0ff30}
\label{bibliographystyle link}
\bibliographystyle{alpha}

\bibliography{/Users/wu/notes/notes/references.bib}
\end{document}
