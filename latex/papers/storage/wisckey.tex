% Created 2024-04-25 Thu 20:01
% Intended LaTeX compiler: xelatex
\documentclass[11pt]{article}
\usepackage{hyperref}
\input{/Users/wu/notes/preamble.tex}
\graphicspath{{../../../paper/storage/}}

%% ox-latex features:
%   !announce-start, !guess-pollyglossia, !guess-babel, !guess-inputenc, caption,
%   underline, image, !announce-end.

\usepackage{capt-of}

\usepackage[normalem]{ulem}

\usepackage{graphicx}

%% end ox-latex features


\author{wu}
\date{\today}
\title{WiscKey: Separating Keys from Values in SSD-Conscious Storage}
\hypersetup{
 pdfauthor={wu},
 pdftitle={WiscKey: Separating Keys from Values in SSD-Conscious Storage},
 pdfkeywords={},
 pdfsubject={},
 pdfcreator={Emacs 29.1 (Org mode 9.7-pre)}, 
 pdflang={English}}
\begin{document}

\maketitle
\section{Abstract}
\label{sec:orge940db8}
WiscKey is a persistent LSM-tree-based key-value store with a performance-oriented data layout that
\textbf{separates keys from values to minimize I/O amplification}.
\section{Introduction}
\label{sec:org9437f3d}
As compared to HDDs, SSDs are fundamentally different in their performance and reliability
characteristics; when considering key-value storage system design, we believe the following three
differences are of paramount importance:
\begin{enumerate}
\item the difference between random and sequential performance is not nearly as large as with HDDs; thus,
an LSM-tree that performs a large number of sequential I/Os to reduce later random I/Os may be
wasting bandwidth needlessly
\item Second, SSDs have a large degree of internal parallelism; an LSM built atop an SSD must be
carefully designed to harness said parallelism
\item Third, SSDs can wear out through repeated writes; the high write ampliﬁcation in LSM-trees can
signiﬁcantly reduce device lifetime.
\end{enumerate}

The combination of these factors greatly impacts LSM-tree performance on SSDs, reducing throughput by
90\% and increasing write load by a factor over 10.

The central idea behind WiscKey is the separation of keys and values; only keys are kept sorted in the
LSM-tree, while values are stored separately in a log.
\begin{enumerate}
\item reduce write amplification by avoiding the unnecessary movement of values while sorting
\item decrease size of the LSM-tree
\end{enumerate}

Separating keys from values introduces a number of challenges and optimization opportunities
\begin{enumerate}
\item range query (scan) performance may be affected because values are not stored in sorted order
anymore.

WiscKey solves this challenge by using the abundant internal parallelism of SSD devices.

\item WiscKey needs garbage collection to reclaim the free space used by invalid values.

WiscKey proposes an online and lightweight garbage collector which only involves sequential I/Os
and impacts the foreground workload minimally.
\item separating keys and values makes crash consistency challenging;

WiscKey leverages an interesting property in modern ﬁle systems, that appends never result in
garbage data on a crash.
\end{enumerate}
\section{Background and Motivation}
\label{sec:org44d50cc}
\subsection{Write and Read Amplification}
\label{sec:orgff64b7d}
\begin{table}[htbp]
\caption{Write and Read Amplification}
\centering
\begin{tabular}{lrr}
Data Size & Write Amplification & Read Amplification\\
\hline
1GB & 3.1 & 8.2\\
100GB & 14 & 327\\
\end{tabular}
\end{table}
\subsection{Fast Storage Hardware}
\label{sec:org05b012c}
\begin{center}
\includegraphics[width=.7\textwidth]{../../images/db/15.png}
\captionof{figure}{\label{fig1}Sequential and Random Reads on SSD}
\end{center}
\section{WiscKey}
\label{sec:org62a577e}
To realize an SSD-optimized key-value store, WiscKey includes four critical ideas:
\begin{enumerate}
\item separate keys and values
\item to deal with unsorted values, WiscKey uses the parallel random-read characteristic of SSD devices
as shown in Figure \ref{fig1}.
\item WiscKey utilizes unique crash-consistency and garbage-collection techniques to efficiently manage
the value log.
\item removing the LSM-tree log without sacrificing consistency.
\end{enumerate}
\subsection{Design Goals}
\label{sec:org11a6527}
\subsection{Key-Value Separation}
\label{sec:orgd892f13}
Compaction only needs to sort keys, while values can be managed separately.
\subsection{Challenges}
\label{sec:org8e192c8}
\subsubsection{Parallel Range Query}
\label{sec:org827951e}
Based on Figure \ref{fig1}, parallel random reads with a fairly large request size can fully utilize the
device's internal parallelism, getting performance similar to sequential reads.

To make range queries efﬁcient, WiscKey leverages the parallel I/O characteristic of SSD devices to
prefetch values from the vLog during range queries.
\subsubsection{Garbage Collection}
\label{sec:orgff1fe4e}
In WiscKey, only invalid keys are reclaimed by the LSM-tree compaction. Since WiscKey does not compact
values, it needs a special garbage collector to reclaim free space in the vLog.

We introduce a small change to WiscKey’s basic data layout: while storing values in the vLog, we also
store the corresponding key along with the value. The new data layout is shown in Figure \ref{fig5}: the
tuple \texttt{(key size, value size, key, value)} is stored in the vLog.

\begin{center}
\includegraphics[width=.7\textwidth]{../../images/db/16.png}
\captionof{figure}{\label{fig5}WiscKey New Data Layout for Garbage Collection}
\end{center}

WiscKey's garbage collection aims to keep valid values in a \uline{contiguous range} of tghe vLog, as shown in
Figure \ref{fig5}. \textbf{head} always corresponds to the end of the vLog where new values will be appended.
\textbf{tail} is where garbage collection starts freeing space whenever it is triggered. Only the part of the
vLog between the head and the tail contains valid values and will be searched during lookups.

During garbage collection, WiscKey first reads a chunk of key-value pairs from the tail of the vLog,
then finds which of those values are valid by querying the LSM-tree. WiscKey then appends valid values
back to the head of the vLog. Finally, it frees the space occupied previously by the chunk, and
updates the tail accordingly.

To avoid losing any data if a crash happens, WiscKey has to make sure that the newly appended valid
values and the new tail are persistent on the device before actually freeing space. WiscKey achieves
this using the following steps.
\begin{enumerate}
\item After appending the valid values to the vLog, the garbage collection calls a \texttt{fsync()} on the vLog.
\begin{quote}
Calling \texttt{fsync()} does not necessarily ensure that the entry in the
directory containing the file has also reached disk.  For that an
explicit \texttt{fsync()} on a file descriptor for the directory is also needed.
\end{quote}
\item it adds these new values' addresses and current tail to the LSM-tree in a synchronous manner; the
tail is stored in the LSM-tree as \texttt{<tail, tail-vLog-offset>}
\item the free space in the vLog is reclaimed.
\end{enumerate}
\subsubsection{Crash Consistency}
\label{sec:orgceeee9e}
WiscKey provides same crash guarantees by using an interesting property of modern file systems (ext4,
btrfs, xfs).

Consider a file that contains the sequence of bytes \(\la b_1b_2\dots b_n\ra\) and the user appends
the sequence \(\la b_{n+1}b_{n+2}\dots b_{n+m}\ra\) to it. If a crash happens, after file-system recovery
in modern file systems, the file will be observed to contain the sequence of bytes
\(\la b_1\dots b_n\dots b_{n+1}\dots b_{n+x}\ra\) where \(x<m\) \cite{186194}. Since values are
appended sequentially to the end of the vLog file in WiscKey, the aforementioned property conveniently
translates as follows: \textbf{if a value \(X\) in the vLog is lost in a crash, all future values are lost
too}.

When the user queries a key-value pair,
\begin{itemize}
\item if WiscKey cannot find the key in the LSM-tree because the key had been lost during a system crash,
WiscKey behaves exactly like traditional LSM-trees: even if the value had been written in vLog before the crash, it will be garbage collected later.
\item if the key could be found in the LSM-tree, an additional step is required to maintain consistency.
\begin{enumerate}
\item verifies whether the value address retrieved from the LSM-tree falls within the current valid
range of the vLog, and then whether the value found corresponds to the queried key
\item if the verification fails, WiscKey assumes that the value was lost during a system crash, deletes
the key from the LSM-tree, and informs the user that the key was not found.
\end{enumerate}
\end{itemize}
\subsection{Optimizations}
\label{sec:org3558613}
\subsubsection{Value-Log Write Buffer}
\label{sec:org4c47d64}
For each \texttt{Put()}, WiscKey needs to append the value to the vLog by using a \texttt{write()} system call. However,
for an insert-intensive workload, issuing a large number of small writes to a ﬁle system can introduce
a noticeable overhead, especially on a fast storage device. Figure \ref{fig7} shows the total time to
sequentially write a 10-GB file in ext4.
\begin{center}
\includegraphics[width=.7\textwidth]{../../images/db/17.png}
\captionof{figure}{\label{fig7}Impact of Write Unit Size}
\end{center}

To reduce overhead, WiscKey buffers values in a userspace buffer, and ﬂushes the buffer only when the
buffer size exceeds a threshold or when the user requests a synchronous insertion.

TODO: how does leveldb handle crash
\subsubsection{Optimizing the LSM-tree Log}
\label{sec:org946f38f}
In WiscKey, the LSM-tree is only used for keys and value addresses. Moreover, the vLog also records
inserted keys to support garbage collection as described in the previous section. Hence, writes to the
LSM-tree log ﬁle can be avoided without affecting correctness.

If a crash happens before the keys are persistent in the LSM-tree, they can be recovered by scanning
the vLog.
As to require scanning only a small portion of the vLog, WiscKey records the head of the vLog
periodically in the LSM-tree, as a key-value pair \texttt{<head, head-vLog-offset>}

vLog is the WAL in essence.
\section{Evaluation}
\label{sec:org94fdfad}
\begin{center}
\includegraphics[width=.99\textwidth]{../../images/db/18.png}
\label{}
\end{center}

\begin{center}
\includegraphics[width=.99\textwidth]{../../images/db/19.png}
\label{}
\end{center}

\begin{center}
\includegraphics[width=.99\textwidth]{../../images/db/20.png}
\label{}
\end{center}

\begin{center}
\includegraphics[width=.99\textwidth]{../../images/db/21.png}
\label{}
\end{center}
\subsection{Crash Consistency}
\label{sec:org11bd409}
Not good illustration
\section{References}
\label{sec:orgcf4ebd5}
\label{bibliographystyle link}
\bibliographystyle{alpha}

\label{bibliography link}
\bibliography{../../../references}
\end{document}
