% Created 2025-04-18 Fri 10:40
% Intended LaTeX compiler: xelatex
\documentclass[11pt]{article}
\usepackage{capt-of}
\usepackage{hyperref}
\input{/Users/wu/notes/preamble.tex}
\graphicspath{{../../../paper/storage/}}

%% ox-latex features:
%   !announce-start, !guess-pollyglossia, !guess-babel, !guess-inputenc, caption,
%   image, !announce-end.

\usepackage{capt-of}

\usepackage{graphicx}

%% end ox-latex features


\date{\today}
\title{PebblesDB: Building Key-Valued Stores using Fragmented Log-Structured Merge Trees}
\hypersetup{
 pdfauthor={},
 pdftitle={PebblesDB: Building Key-Valued Stores using Fragmented Log-Structured Merge Trees},
 pdfkeywords={},
 pdfsubject={},
 pdfcreator={},
 pdflang={English}}
\begin{document}

\maketitle
\section{Introduction}
\label{sec:org69d58c4}
One fundamental problem that remains is the high write amplification of key-value stores for
write-intensive workloads.

\wu{
Keep in mind how does pebblesdb solve write amplification
}

Figure 1 shows the high write amplification (ratio of total IO to total user data written) that occurs
in several widely-used key-value stores when 500 million key-value pairs are inserted or updated in
random order.

\begin{center}
\includegraphics[width=.7\textwidth]{../../images/papers/121.png}
\label{f1}
\end{center}

Conventional wisdom is that reducing write amplification requires sacrificing either write or read
throughput. In todayâ€™s low-latency, write-intensive environments , users are not willing to sacrifice
either.
\section{Fragmented Log-Structured Merge Trees}
\label{sec:orgb41d256}
The challenge is to achieve three goals simultaneously:
\begin{itemize}
\item low write amplification
\item high write throughput
\item good read performance
\end{itemize}
\subsection{Guards}
\label{sec:org9d9dc96}
In the classical LSM, each level contains sstables with disjoint key ranges (i.e., each key will be
present in exactly one sstable). The chief insight in this work is that maintaining this invariant is
the root cause of write amplification, as it forces data to be rewritten in the same level.

The FLSM data structure discards this invariant: each level can contain multiple sstables with
overlapping key ranges, so that a key may be present in multiple sstables. To quickly find keys in
each level, FLSM organizes the sstables into guards

Each level contains multiple guards. Guards divide the key space (for that level) into disjoint units.
Each guard \(G_i\) has an associated key \(K_i\) , chosen from among keys inserted into the FLSM. Each
level in the FLSM contains more guards than the level above it; the guards get progressively more
fine-grained as the data gets pushed deeper and deeper into the FLSM. As in a skiplist, if a key is a
guard at a given level \(i\), it will be a guard for all levels \(>i\).

Each guard has a set of associated sstables. Each sstable is sorted. If guard \(G_i\) is associated
with key \(K_i\) and guard \(G_{i+1}\) with \(K_{i+1}\), an sstable with keys in the range
\([K_i,K_{i+1})\) will be attached to \(G_i\) . Sstables with keys smaller than the first guard are
stored in a special sentinel guard in each level. The last guard \(G_n\) in the level stores all
sstables with keys \(\ge K_n\). Guards within a level never have overlapping key ranges. Thus, to find
a key in a given level, only one guard will have to be examined.

In FLSM compaction, the sstables of a given guard are (merge) sorted and then fragmented
(partitioned), so that each child guard receives a new sstable that fits into the key range of that
child guard in the next level.

\begin{center}
\includegraphics[width=.8\textwidth]{../../images/papers/1212.png}
\label{f3}
\end{center}


\begin{examplle}[]
Figure \ref{f3} shows the state of the FLSM data structure after a few \texttt{put()} operations.
\begin{itemize}
\item A \texttt{put()} results in keys being added to the in-memory memtable (not shown). Eventually, the memtable
becomes full, and is written as an sstable to Level 0. Level 0 does not have guards, and collects
together recently written sstables.
\item The number of guards increases as the level number increases. The number of guards in each level
does not necessarily increase exponentially.
\item Each level has a sentinel guard that is responsible for sstables with keys < than the first guard.
In Figure \ref{f3}, sstables with keys < 5 are attached to the sentinel guard.
\item Data inside an FLSM level is partially sorted: guards do not have overlapping key ranges, but the
sstables attached to each guard can have overlapping key ranges.
\end{itemize}
\end{examplle}
\subsection{Selecting Guards}
\label{sec:org7bce243}
\begin{itemize}
\item Since: FLSM performance is significantly impacted by how guards are selected. In the worst case, if
one guard contains all sstables, reading and searching such a large guard (and all its constituent sstables) would cause an un-acceptable increase in latency for reads and range queries.
\item Therefore: guards are not selected statically; guards are selected probabilistically from inserted
keys, preventing skew.
\end{itemize}

\textbf{Guard Probability}. When a key is inserted into FLSM, guard probability determines if it becomes a
guard. Guard probability \texttt{gp(key, i)} is the probability that key becomes a guard at level \texttt{i}. For
example, if the guard probability is 1/10, one in every 10 inserted keys will be randomly selected to
be a guard. The guard probability is designed to be lowest at Level 1 (which has the fewest guards),
and it increases with the level number (as higher levels have more guards). Selecting guards in this
manner distributes guards across the inserted keys in a smooth fashion that is likely to prevent skew.

Much like skip lists, if a key \(K\) is selected as a guard in level \(i\), it becomes a guard for all
higher levels \(i+1\), \(i+2\) etc. The guards in level \(i+1\) are a strict superset of the guards in
level \(i\). Choosing guards in this manner allows the interval between each guard to be successively
refined in each deeper

\textbf{Othter schemes for selecting guards}. Probability does not take into account the amount of IO that will
result from partitioning sstables during compaction. FLSM could potentially select new guards for each
level at compaction time such that sstable partitions are minimized; however, this could introduce
skew.
\subsection{Inserting and Deleting Guards}
\label{sec:orgdd9d192}
When guards are selected, they are added to an in-memory set termed the \textbf{uncommitted} guards. Sstables
are not partitioned on storage based on (as of yet) uncommitted guards; as a result, FLSM reads are
performed as if these guards did not exist. At the next compaction cycle, sstables are partitioned and
compacted based on both old guards and uncommitted guards; any sstable that needs to be split due to
an uncommitted guard is compacted to the next level. At the end of compaction, the uncommitted guards
are persisted on storage and added to the full set of guards. Future reads will be performed based on
the full set of guards.

We note that in many of the workloads that were tested, guard deletion was not required. A guard could
become empty if all its keys are deleted, but empty guards do not cause noticeable performance
degradation as \texttt{get()} and range query operations skip over empty guards. Nevertheless, deleting guards
is useful in two scenarios: when the guard is empty or when data in the level is spread unevenly among
guards. In the second case, consolidating data among fewer guards can improve performance.

Guard deletion is also performed asynchronously similar to guard insertion. Deleted guards are added
to an in-memory set. At the next compaction cycle, sstables are re-arranged to account for the deleted
guards. Deleting a guard \(G\) at level \(i\) is done lazily at compaction time. During compaction,
guard \(G\) is deleted and sstables belonging to guard \(G\) will be partitioned and appended to
either the neighboring guards in the same level \(i\) or child guards in level \(i+1\). Compaction
from level \(i\) to \(i+1\) proceeds as normal (since \(G\) is still a guard in level i + 1). At the
end of compaction, FLSM persists metadata indicating \(G\) has been deleted at level \(i\). If
required, the guard is deleted in other levels in a similar manner. Note that if a guard is deleted at
level \(i\), it should be deleted at all levels \(<i\); FLSM can choose whether to delete the guard at
higher levels \(>i\).
\subsection{FLSM Operations}
\label{sec:org9d6c921}
\subsubsection{Get Operations}
\label{sec:orgd41f092}
A \texttt{get()} operation first checks the in-memory memtable. If the key is not found, the search continues
level by level, starting with level 0. During the search, if the key is found, it is returned
immediately. To check if a key is present in a given level, binary search is used to find the single
guard that could contain the key. Once the guard is located, its sstables are searched for the key.
Thus, in the worst case, a get() requires reading one guard from each level, and all the sstables of
each guard.
\subsubsection{Range Queries}
\label{sec:org1947120}
FLSM first identifies the guards at each level that intersect with the given range. Inside each guard,
there may be multiple sstables that intersect with the given range; a binary search is performed on
each sstable to identify the smallest key overall in the range. Identifying the next smallest key in
the range is similar to the merge procedure in merge sort; however, a full sort does not need to be
performed. When the end of range query interval is reached, the operation is complete, and the result
is returned to the user.
\subsubsection{Put Operations}
\label{sec:orgd8a6dc4}
A \texttt{put()} operation adds data to an in-memory memtable. When the memtable gets full, it is written as a
sorted sstable to Level 0. When each level reaches a certain size, it is compacted into the next
level. In contrast to compaction in LSM stores,
\wu{
FLSM avoids sstable rewrites in most cases by
partitioning sstables and attaching them to guards in the next level.
}
\subsubsection{Key Updates and Deletions}
\label{sec:org28ec4a5}
Similar to LSM, updating or deleting a key involves inserting the key into the store with an updated
sequence number or a deletion flag respectively. Reads and range queries will ignore keys with
deletion flags. If the insertion of a key resulted in a guard being formed, the deletion of the key
does not result in deletion of the related guard; deleting a guard will involve a significant amount
of compaction work. Thus, empty guards are possible.
\subsubsection{Compaction}
\label{sec:orgf2be6f8}
When a guard accumulates a threshold number of sstables, it is compacted into the next level. The
sstables in the guard are first (merge) sorted and then partitioned into new sstables based on the
guards of the next level; the new sstables are then attached to the correct guards.

Note that in most cases, FLSM compaction does not rewrite sstables. This is the main insight behind
how FLSM reduces write amplification. New sstables are simply added to the correct guard in the next
level. There are two exceptions to the no-rewrite rule.
\begin{enumerate}
\item At the highest level (e.g,. Level 5) of FLSM, the sstables have to be rewritten during compaction;
there is no higher level for the sstables to be partitioned and attached to.
\item For the second-highest level (e.g,. Level 4), FLSM will rewrite an sstable into the same level if
the alternative is to merge into a large sstable in the highest level (since we cannot attach new
sstables in the last level if the guard is full). The exact heuristic is rewrite in
second-highest-level if merge causes 25Ã— more IO.
\end{enumerate}

FLSM compaction is trivially parallelizable because compacting a guard only involves its descendants
in the next level; the way guards are chosen in FLSM guarantees that compacting one guard never
interferes with compacting another guard in the same level.
\subsection{Tuning FLSM}
\label{sec:org8434b7a}
\texttt{max\_sstables\_per\_guard}
\subsection{Limitations}
\label{sec:org6b077fb}
\subsection{Asymptotic Analysis}
\label{sec:org9c6d9b1}
\subsubsection{Model}
\label{sec:orgb6eec5b}
We use the standard Disk Access Model (DAM) and assume that each read/write operation can
access a block of size \(B\) in one unit cost. To simplify the model, we will assume a total of \(n\)
data items are stored.
\subsubsection{FLSM Analysis}
\label{sec:org5a64380}
        Consider a FLSM where the guard probability is \(1/B\) (so the number of guards in level \(i+1\) is in
        expectation B times more than the number of guards in level \(i\)). Since the expected fan-out of FLSM
        is \(B\), with high probability, an FLSM with \(n\) data items will have \(H=\log_Bn\) levels. It is easy to see that each data item is written just
once per level (it is appended once and never re-written to
the same level), resulting in a write cost of O (H ) = O (logB n).
Since in the DAM model, FLSM writes a block of B items at
unit cost, the total amortized cost of any put operation is
O (H /B) = O ((logB n)/B) over its entire compaction lifetime.
However, FLSM compaction in the last level does re-write
data. Since this last level re-write will occur with high prob-
ability O (B) times then the final total amortized cost of any
put operation is O ((B + logB n)/B).
The guards in FLSM induce a degree B Skip List. A detailed
theoretical analysis of the B-Skip List data structure shows
that with high probability each guard will have O (B) children,
each guard will have at most O (B) sstables, and each sstable
\section{Building PebblesDB Over FLSM}
\label{sec:org1aa5f00}
\subsection{Improving Read Performance}
\label{sec:org8fb1c21}
bloom filter\ldots{}
\subsection{Improving Range Query Performance}
\label{sec:orgd1ceaa6}
\subsubsection{Seek-Based Compaction}
\label{sec:org896aa86}
Compaction triggered by a threshold number of consecutive \texttt{seek()} operations
\subsubsection{Parallel Seeks}
\label{sec:orgad8f800}
\section{Evaluation}
\label{sec:orga58ca22}
\begin{center}
\includegraphics[width=.99\textwidth]{../../images/papers/122.png}
\label{}
\end{center}
\section{Problems}
\label{sec:org02853fc}


\section{References}
\label{sec:org81c93bf}
\label{bibliographystyle link}
\bibliographystyle{alpha}

\bibliography{/Users/wu/notes/notes/references.bib}
\end{document}
