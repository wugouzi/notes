% Created 2023-06-14 Wed 13:15
% Intended LaTeX compiler: pdflatex
\documentclass[11pt]{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{graphicx}
\usepackage{longtable}
\usepackage{wrapfig}
\usepackage{rotating}
\usepackage[normalem]{ulem}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{capt-of}
\usepackage{hyperref}
\graphicspath{{../../books/}}
\input{../preamble.tex}
\usepackage{minted}
\makeindex
\author{Mara Bos}
\date{\today}
\title{Rust Atomics And Locks}
\hypersetup{
 pdfauthor={Mara Bos},
 pdftitle={Rust Atomics And Locks},
 pdfkeywords={},
 pdfsubject={},
 pdfcreator={Emacs 29.0.90 (Org mode 9.6.1)}, 
 pdflang={English}}
\begin{document}

\maketitle
\tableofcontents


\section{Basics of Rust Concurrency}
\label{sec:orgf3e6388}
\subsection{Threads in Rust}
\label{sec:orgc48e941}
Rust std assigns every thread a unique identifier.

\begin{remark}[Output Locking]
The \texttt{println} macro uses \texttt{std::io::Stdout::lock()} to make sure its output does not get interrupted.
A \texttt{println!()} expression will wait until any concurrently running one is finished before writing
any output.
\end{remark}

Since a thread might run until the every end of the program's execution, the \texttt{spawn} function has
a \texttt{'static} lifetime bound on its argument type. In other words, it only accepts functions that
may kept around forever.

\begin{remark}[Thread Builder]
The \texttt{std::thread::spawn} function is a convenient shorthand for
\texttt{std::thread::Builder::new().spawn().unwrap()}.

A \texttt{std::thread::Builder} allows you to set some settings for the new thread before spawning it.
You can use it to configure the stack size for the new thread and to give the new thread a name.
The name of a thread is available through \texttt{std::thread::current().name()}, will be used in panic
messages, and will be visible in monitoring and debugging tools on most platforms.

Additionally, Builder’s spawn function returns an \texttt{std::io::Result}, allowing you
to handle situations where spawning a new thread fails. This might happen if the operating
system runs out of memory, or if resource limits have been applied to your program. The
\texttt{std::thread::spawn} function simply panics if it is unable to spawn a new thread.
\end{remark}
\subsection{Scoped Threads}
\label{sec:orgeadd6c8}
If we know for sure that a spawned thread will definitely not outlive a certain scope, that
thread could safely borrow things that do not live forever, such as local variables, as long as
they outlive that scope.
\subsection{Shared Overship and Reference Counting}
\label{sec:orgd229acb}
\subsubsection{Statics}
\label{sec:org51b7913}
\texttt{static} is ``owned'' by the entire program.
\begin{minted}[]{rust}
static X: [i32; 3] = [1, 2, 3];
thread::spawn(|| dbg!(&X));
thread::spawn(|| dbg!(&X));
\end{minted}
Every thread can borrow it, since it's guaranteed to always exist.
\subsubsection{Leaking}
\label{sec:org0faaa0e}
Using \texttt{Box::leak}, one can release ownership of a \texttt{Box}, promising to never drop it.
\begin{minted}[]{rust}
let x: &'static [i32; 3] = Box::leak(Box::new([1, 2, 3]));
thread::spawn(move || dbg!(x));
thread::spawn(move || dbg!(x));
\end{minted}
\subsubsection{Reference Counting}
\label{sec:org4099f7d}
To make sure that shared data gets dropped and deallocated, we can’t completely give up its
ownership. Instead, we can share ownership. By keeping track of the number of owners, we can
make sure the value is dropped only when there are no owners left.

\texttt{std::rc::Rc} is short for ``reference count''. Cloning it will not allocate anything new, but
instead increment a counter stored next to the contained value.

\texttt{Rc} is not \textbf{thread-safe}. Instead we can use \texttt{std::sync::Arc}, which stands for ``atomically
reference counted''
\subsubsection{Borrowing and Data Races}
\label{sec:orgedd671b}
\subsubsection{Interior Mutability}
\label{sec:orgfed2fe0}
A \texttt{std::cell::Cell<T>} simply wraps a \texttt{T}, but allows mutations through a shared reference. To avoid
undefined behavior, it only allows you to copy the value out (if \texttt{T} is \texttt{Copy}) or replace it with
another value as a whole. In addition, it can only be used within a single thread.
\begin{minted}[]{rust}
use std::cell::Cell;
fn f(a: &Cell<i32>, b: &Cell<i32>) {
    let before = a.get();
    b.set(b.get() + 1);
    let after = a.get();
    if before != after {
        x(); // might happen
    }
}
\end{minted}

\begin{minted}[]{rust}
fn f(v: &Cell<Vec<i32>>) {
    let mut v2 = v.take(); // Replaces the contents of the Cell with an empty Vec
    v2.push(1);
    v.set(v2); // Put the modified Vec back
}
\end{minted}

A \texttt{std::cell::RefCell} does allow you to borrow its content, at a small runtime cost. A
\texttt{RefCell<T>} does not only hold a \texttt{T}, but also holds a counter that keep track of any outstanding
borrows. If you try to borrow it while it is already mutably borrowed (or vice-versa), it will
panic, which avoids undefined behavior. A \texttt{RefCell} can only be used within a single thread.

Borrowing the contents is done by calling \texttt{borrow} or \texttt{borrow\_mut}.
\subsubsection{Mutex and RwLock}
\label{sec:orgb666289}
An \texttt{RwLock} or \textbf{reader-writer lock} is the concurrent version of a \texttt{RefCell}. An \texttt{RwLock<T>} holds a \texttt{T}
and tracks any outstanding borrows. However, unlike a \texttt{RefCell}, it does not panic on conflicting
borrows. Instead, it blocks the current thread—putting it to sleep—while waiting for conflicting
borrows to disappear.
\subsubsection{Atomics}
\label{sec:org3c7c8c8}
Unlike a \texttt{Cell}, though, they cannot be of arbitrary size. Because of this, there is no generic
\texttt{Atomic<T>} type for any \texttt{T}, but there are only specific atomic types such as \texttt{AtomicU32} and
\texttt{AtomicPtr<T>}.
\subsubsection{UnsafeCell}
\label{sec:org6a4a6da}
\texttt{UnsafeCell} is the primitive building block for interior mutability.

An \texttt{UnsafeCell<T>} wraps a \texttt{T}, but does not come with any conditions or restrictions to avoid
undefined behavior. Instead, its \texttt{get()} method just gives a raw pointer to the value it wraps,
which can only be meaningfully used in unsafe blocks.
\subsection{Locking: Mutexes and RwLocks}
\label{sec:org26ef606}
\subsubsection{Rust's Mutex}
\label{sec:orgfa7e57c}
\texttt{std::sync::Mutex<T>}

To ensure a locked mutex can only be unlocked by the thread that locked it, it does not have an
\texttt{unlock()} method. Instead, its \texttt{lock()} method returns a special type called a \texttt{MutexGuard}. This
guard represents the guarantee that we have locked the mutex. It behaves like an exclusive
reference through the \texttt{DerefMut} trait, giving us exclusive access to the data the mutex protects.
Unlocking the mutex is done by dropping the guard. When we drop the guard, we give up our
ability to access the data, and the Drop implementation of the guard will unlock the mutex.

\begin{minted}[]{rust}
use std::sync::Mutex;
fn main() {
    let n = Mutex::new(0);
    thread::scope(|s| {
        for _ in 0..10 {
            s.spawn(|| {
                let mut guard = n.lock().unwrap();
                for _ in 0..100 {
                    *guard += 1;
                }
            });
        }
    });
    assert_eq!(n.into_inner().unwrap(), 1000);
}
\end{minted}

The \texttt{into\_inner} method takes ownership of the mutex, which guarantees that nothing else can have a
reference to the mutex anymore, making locking unnecessary.
\subsubsection{Lock Poisoning}
\label{sec:org98b04ac}
The \texttt{unwrap()} calls in the examples above relate to lock poisoning.

A Mutex in Rust gets marked as \emph{poisoned} when a thread panics while holding the lock. When that
happens, the \texttt{Mutex} will no longer be locked, but calling its lock method will result in an Err
to indicate it has been poisoned.

This is a mechanism to protect against leaving the data that’s protected by a mutex in an
inconsistent state. In our example above, if a thread would panic after incrementing the integer
fewer than 100 times, the mutex would unlock and the integer would be left in an unexpected
state where it is no longer a multiple of 100, possibly breaking assumptions made by other
threads. Automatically marking the mutex as poisoned in that case forces the user to handle this
possibility.
\subsubsection{Reader-Writer Lock}
\label{sec:org48d1db0}
A mutex is only concerned with exclusive access. The \texttt{MutexGuard} will provide us an exclusive
reference (\texttt{\&mut T}) to the protected data, even if we only wanted to look at the data and a
shared reference (\texttt{\&T}) would have sufficed. It has \texttt{read()} and \texttt{write()} method for locking as
either a reader or a writer.

Both \texttt{Mutex<T>} and \texttt{RwLock<T>} require \texttt{T} to be \texttt{Send}, because they can be used to send a \texttt{T} to
another thread. An \texttt{RwLock<T>} additionally requires \texttt{T} to also implement \texttt{Sync}, because it allows
multiple threads to hold a shared reference (\texttt{\&T}) to the protected data.
\subsubsection{Waiting: Parking and Condition Variables}
\label{sec:orgb1f0298}
One way to wait for a notification from another thread is called \textbf{thread parking}.

Thread parking is available through the \texttt{std::thread::park()} function. For unparking, you call
the \texttt{unpark()} method on a \texttt{Thread} object representing the thread that you want to unpark. Such an
object can be obtained from the join handle returned by \texttt{spawn}, or by the thread itself through
\texttt{std::thread::current()}.

\begin{minted}[]{rust}
use std::collections::VecDeque;
fn main() {
    let queue = Mutex::new(VecDeque::new());
    thread::scope(|s| {
        // Consuming thread
        let t = s.spawn(|| loop {
            let item = queue.lock().unwrap().pop_front();
            if let Some(item) = item {
                dbg!(item);
            } else {
                thread::park();
            }
        });
        // Producing thread
        for i in 0.. {
            queue.lock().unwrap().push_back(i);
            t.thread().unpark();
            thread::sleep(Duration::from_secs(1));
        }
    });
}
\end{minted}

An important property of thread parking is that a call to \texttt{unpark()} before the thread parks
itself does not get lost. The request to unpark is still recorded, and the next time
the thread tries to park itself, it clears that request and directly continues without
actually going to sleep.

However, unpark requests don't stack up.

The Rust standard library provides a condition variable as \texttt{std::sync::Condvar}. Its
wait method takes a \texttt{MutexGuard} that proves we’ve locked the mutex. It first unlocks the mutex
and goes to sleep. Later, when woken up, it relocks the mutex and returns a new \texttt{MutexGuard}.

It has two notify functions: \texttt{notify\_one} to wake up just one waiting thread (if any),
and \texttt{notify\_all} to wake them all up.

\begin{minted}[]{rust}
use std::sync::Condvar;
let queue = Mutex::new(VecDeque::new());
let not_empty = Condvar::new();
thread::scope(|s| {
    s.spawn(|| {
        loop {
            let mut q = queue.lock().unwrap();
            let item = loop {
                if let Some(item) = q.pop_front() {
                    break item;
                } else {
                    q = not_empty.wait(q).unwrap();
                }
            };
            drop(q);
            dbg!(item);
        }
    });
    for i in 0.. {
        queue.lock().unwrap().push_back(i);
        not_empty.notify_one();
        thread::sleep(Duration::from_secs(1));
    }
});
\end{minted}
\section{Atomics}
\label{sec:orgaedb3bc}
\end{document}