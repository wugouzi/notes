#+TITLE: Basic Proof Theory
#+AUTHOR: A. S. Troelstra and H. Schwichtenberg

#+LATEX_HEADER: \input{../preamble.tex}
#+LATEX_HEADER: \usepackage{bussproofs}
#+LATEX_HEADER: \def \EBA {\EnableBpAbbreviations}
#+LATEX_HEADER: \def \RL[#1]{\RightLabel{#1}}
#+EXPORT_FILE_NAME: ../latex/BasicProofTheory/BasicProofTheory.tex
#+LATEX_HEADER: \DeclareMathOperator{\blambdato}{\symbf{\lambda_\to}}
#+LATEX_HEADER: \DeclareMathOperator{\blambdaetato}{\symbf{\lambda\eta_\to}}
#+LATEX_HEADER: \DeclareMathOperator{\Nm}{\textbf{Nm}}
#+LATEX_HEADER: \DeclareMathOperator{\Ni}{\textbf{Ni}}
#+LATEX_HEADER: \DeclareMathOperator{\Nc}{\textbf{Nc}}
#+LATEX_HEADER: \def \etapar {\eta\text{par}}
#+LATEX_HEADER: \def \lambdamon{\lambda\text{mon}}
#+LATEX_HEADER: \def \appmon {\text{appmon}}
#+LATEX_HEADER: \def \betapar {\beta\text{par}}

#+LATEX_HEADER: 

* Introduction
** Preliminaries
    #+ATTR_LATEX: :options []
    #+BEGIN_definition
    The notion of *positive*, *negative*, *strictly positive* subformula are defined
    in a similar style
    1. $A$ is a positive and a strictly positive subformula of itself
    2. if $B\wedge C$ or $B\vee C$ is a positive [negative, strictly positive]
       subformula of $A$, then so are $B,C$
    3. if $\forall xB$ or $\exists xB$ is a positive [negative, strictly
       positive] subformula of $A$, then so is $B[x/t]$ for any $t$ free for $x$
       in $B$
    4. if $B\to C$ is a positive [negative] subformula of $A$, then $B$ is a
       negative [positive] subformula of $A$, and $C$ is a positive [negative]
       subformula of $A$
    5. if $B\to C$ is a strictly positive subformula of $A$ then so is $C$


    A strictly positive subformula of $A$ is called a *strictly positive part
    (s.p.p.)* of $A$
    #+END_definition
*** Contexts and Formula Occurrences
    Formula occurrences (f.o.'s) will play an even more important role than the
    formulas themselves. An f.o. is nothing but a formula with a position in
    another structure (prooftree, sequent, a larger formula etc.).

    A *context* is nothing but a formula with an occurrences of a special
    propositional variable. Alternatively, a context is sometimes described as a
    formula with a hole in it. 

    #+ATTR_LATEX: :options []
    #+BEGIN_definition
    We define *positive* ($\calp$) and *negative (formula-)contexts* ($\caln$)
    simultaneously by an induction definition. The symbol "$*$" functions as a
    special proposition letter, a *placeholder*
    1. $*\in\calp$
       

    and if $B^+\in \calp,B^{\minus}\in\caln$ and $A$ is any formula, then
    2. [@2] $A\wedge B^+,B^+\wedge A,A\vee B^+,B^+\vee A,A\to B^+,B^{\minus}\to A,
       \forall xB^+,\exists xB^+\in\calp$
       
    3. $A\wedge B^-,B^-\wedge A,A\vee B^-,B^-\vee A,A\to B^-,B^+\to A,
       \forall xB^-,\exists xB^-\in\caln$


    The set of *formula contexts* is the union of $\calp$ and $\caln$. Note that a
    context contains always only a single occurrence of $*$.

    For arbitrary contexts we sometimes write $F[*],G[*],\dots$ Then
    $F[A],G[A],\dots$ are the formulas obtained by replacing $*$ by $A$

    The *strictly positive* contexts $\cals\calp$ are defined by
    4. [@4] $*\in\cals\calp$; and if $B\in\cals\calp$, then
    5. $A\wedge B,B\wedge A,A\vee B,B\vee A,A\to B,\forall xB,\exists
       xB\in\cals\calp$


    An alternative definition
    \begin{align*}
    &\calp=*\mid A\wedge\calp\mid\calp\wedge A\mid A\vee\calp\mid\calp\vee A\mid 
    A\to\calp\mid\caln\to A\mid\forall x\calp\mid\exists x\calp\\
    &\caln=A\wedge\caln\mid\caln\wedge A\mid A\vee\caln\mid\caln\vee A\mid A\to\caln
    \mid\calp\to A\mid\forall x\caln\mid \exists x\caln\\
    &\cals\calp=*\mid A\wedge\cals\calp\mid\cals\calp\wedge A\mid
    A\vee\cals\calp\mid\cals\calp\vee A\mid A\to\cals\calp
    \mid\forall x\cals\calp\mid\exists x\cals\calp
    \end{align*}

    A *formula occurence* (*f.o.* for short) in a formula $B$ is a literal
    subformula $A$ together with a context indicating the place where $A$ occurs.
    #+END_definition

    #+ATTR_LATEX: :options []
    #+BEGIN_definition
    The *length* or *size* of a finite tree is the number of nodes in the tree. We
    write \(s(\calt)\) for the size of \(\calt\)

    The *depth* or *height* \(\abs{\calt}\) of a tree \(\calt\) is the maximum
    length of the branches

    The *leafszie* of a tree \(\calt\) is the number of top nodes of the trees
    #+END_definition


** Simple type theories
   #+attr_latex: :options [the set of simple types]
   #+begin_definition
   the set of *simple types* $\calt_\to$ is constructed from a countable set
   of *type variables* $P_0,P_1,\dots$ by means of a type-forming operation
   (*function-type constructor*) $\to$
   1. type variables belong to $\calt_\to$
   2. if $A,B\in\calt_\to$, then $(A\to B)\in\calt_\rightarrow$

      
   A type of the form $A\to B$ is called a *function type*
   #+END_definition

   #+ATTR_LATEX: :options [Terms of the simply typed lambda calculus $\blambda_{\bto}$]
   #+BEGIN_definition
   label:def1.2.2
   All terms appear with a type; for terms of type $A$ we use $t^A,s^A,r^A$. The
   terms are generated by the following three clauses
   1. For each $A\in T_\to$ there is a countably infinite supply of variables of
      type $A$; for arbitrary variables of type $A$ we use
      $u^A,v^A,w^A,x^A,y^A,z^A$
   2. if $t^{A\to B},s^A$ are terms, then $\app(t^{A\to B},s^A)^B$ is a term of
      type $B$
   3. if $t^B$ is a term of type $B$ and $x^A$ a variable of type $A$, then
      $(\lambda x^A.t^B)^{A\to B}$
   #+END_definition
   For $\app(t^{A\to B},s^A)^B$ we usually write simply $(t^{A\to B}s^A)^B$

   #+ATTR_LATEX: :options []
   #+BEGIN_examplle
   \(\bk_\lambda^{A,B}:=\lambda x^Ay^B.x^A,\bs_\lambda^{A,B,C}:=\lambda x^{A\to(B\to C)}y^{A\to B}z^A.xz(yz)\)
   #+END_examplle
   #+ATTR_LATEX: :options []
   #+BEGIN_definition
   The set $\FV(t)$ of variables free in $t$ is specified by
   \begin{alignat*}{2}
   &\FV(x^A)&&:=x^A\\
   &\FV(ts)&&:=\FV(t)\cup\FV(s)\\
   &\FV(\lambda x.t)&&:=\FV(t)\backslash\{x\}
   \end{alignat*}
   #+END_definition


   #+ATTR_LATEX: :options [Substitution]
   #+BEGIN_definition
   The operation of substitution of a term $s$ for a variable $x$ in a term $t$
   (notation $t[x/s]$) may be defined by recursion on the complexity of $t$, as
   follows
   \begin{alignat*}{2}
   &x[x/s]&&:=s\\
   &y[x/s]&&:=y\text{ for } y\not\equiv x\\
   &(t_1t_2)[x/s]&&:=t_1[x/s]t_2[x/s]\\
   &(\lambda x.t)[x/s]&&:=\lambda x.t\\
   &(\lambda y.t)[x/s]&&:=\lambda y.t[x/s]\text{ for } y\not\equiv x; \text{
   w.l.o.g. } y\not\in\FV(s)
   \end{alignat*}
   #+END_definition

   #+ATTR_LATEX: :options [Substitution lemma]
   #+BEGIN_lemma
   If $x\not\equiv y, x\not\in\FV(t_2)$, then
   \begin{equation*}
   t[x/t_1][y/t_2]\equiv t[y/t_2][x/t_1[y/t_2]]
   \end{equation*}
   #+END_lemma

   #+ATTR_LATEX: :options [Conversion, reduction, normal form]
   #+BEGIN_definition
   Let $\mathsf{T}$ be a set of terms, and let conv be a binary relation on
   $\mathsf{T}$, written in infix notation: $t$ conv $s$. If $t$ conv $s$, we
   say that $t$ *converts to* $s$; $t$ is called a *redex* or
   *convertible* term and $s$ the *conversum* of $t$. The replacement of a
   redex by its conversum is called a *conversion*. We write $t\succ_1 s$
   ($t$ *reduces in one step to* $s$) if $s$ is obtained from $t$ by
   replacement of a redex $t'$ of $t$ by a conversum $t''$ of $t'$. The relation
   $\succ$ (*properly reduces to*) is the transitive closure of $\succ_1$ and
   $\succeq$ (*reduces to*) is the reflexive and transitive closure of
   $\succ_1$. The relation $\succeq$ is said to be the notion of reduction
   *generated* by cont.

   With the notion of reduction generated by cony we associate a relation on
   $\mathsf{T}$ called *conversion equality*: $t=_{\conv}s$ ($t$ is equal by
   conversion to $s$) if there 
   is a sequence $t_0,\dots,t_n$ with $t_0\equiv t,t_n\equiv s$, and $t_i\preceq
   t_{i+1}$ or $t_i\succeq t_{i+1}$ for each
   $i, 0\le i < n$. The subscript "conv" is usually omitted when clear from the
   context

   A term $t$ is in *normal form*, or $t$ is *normal*, if $t$ does not contain a redex. $t$
   *has a normal form* if there is a normal $s$ such that $t\succeq s$.

   A *reduction sequence* is a (finite or infinite) sequence of pairs
   $(t_0,\delta_0),(t_1,\delta_1),\dots$ 
   with $\delta_i$ an (occurrence of a) redex in $t_i$ and $t_i\succ t_{i+1}$ by
   conversion 
   of $\delta_i$, for all $i$. This may be written as
   \begin{equation*}
   t_0\overset{\delta_0}{\succ}_1 t_1\overset{\delta_1}{\succ}_1 t_2
   \overset{\delta_2}{\succ}_1\dots
   \end{equation*}
   We often omit the $\delta_i$, simply writing $t_0\succ_1 t_1\succ_1 t_2$

   Finite reduction sequences are partially ordered under the initial part
   relation ("sequence \sigma is an initial part of sequence \tau "); the collection of
   finite
   reduction sequences starting from a term $g$ forms a tree, the *reduction tree*
   of $t$. The branches of this tree may be identified with the collection of all
   infinite and all terminating finite reduction sequences.


   A term is *strongly normalizing* (is SN) if its reduction tree is finite
   
   #+END_definition

   \(\beta\)-conversion:
   \begin{equation*}
   (\lambda x^A.t^B) s^A\e\cont_\beta\e t^B[x^A/s^A]
   \end{equation*}
   \(\eta\)-conversion:
   \begin{equation*}
   \lambda x^A.tx\e\cont_\eta\e  t\quad(x\not\in\FV(t))
   \end{equation*}
   \(\beta\eta\)-conversion $\cont_{\beta\eta}$ is $\cont_\beta\cup\cont_\eta$

   No free variables may become bound when executing the substitution in a \(\beta\)-conversion

   #+ATTR_LATEX: :options []
   #+BEGIN_definition
   A relation $R$ is said to be *confluent*, or to have the *Church-Rosser property*
   (CR), if whenever $t_0 Rt_1$ and $t_0Rt_2$, then there is a $t_3$ s.t.
   $t_1Rt_3$ and $t_2Rt_3$. A relation $R$ is said to be *weakly confluent* or to
   have the *weak Church-Rosser property* if whenever $t_0Rt_1,t_0Rt_2$ there is a
   $t_3$ s.t. $t_1R^*t_3$ and $t_2R^* t_3$ where $R^*$ is the reflexive and
   transitive closure of $R$
   #+END_definition
   
   #+ATTR_LATEX: :options []
   #+BEGIN_theorem
   For a confluent reduction relation $\succeq$ the normal forms of terms are
   unique. Furthermore, if $\succeq$ is a confluent reduction relation we have
   $t=t'$ iff there is a term $t''$ s.t. $t\succ t''$ and $t'\succ t''$
   #+END_theorem

   #+BEGIN_proof
   If \(t=t'\) (for the equality induced by \(\succeq\)), then by definition
   there is a chain \(t\equiv t_0,t_1,\dots,t_n\equiv t'\) s.t. for all \(i<n\),
   \(t_i\succeq t_{i+1}\) or \(t_{i+1}\preceq t_i\). The existence of the
   required \(t''\) is now established by induction on \(n\). Consider the step
   from \(n\) to \(n+1\). By induction hypothesis there is an \(s\) s.t.
   \(t_0\succeq s,t_n\succeq s\). If \(t_{n+1}\succeq t_n\), take \(s''=s\). If
   \(t_n\succeq t_{n+1}\), using the confluence to find a \(t''\) s.t.
   \(s\succeq t''\) and \(t_{n+1}\succeq t''\)
   #+END_proof

   #+ATTR_LATEX: :options [Newman's lemma]
   #+BEGIN_theorem
   Let $\succeq$ be the transitive and reflexive closure of $\succ_1$, and let
   $\succ_1$ be weakly confluent. Then the normal form w.r.t. $\succ_1$ of a
   strongly normalizing $t$ is unique. Moreover, if all terms are strongly
   normalizing w.r.t. $\succ_1$ then the relation $\succeq$ is confluent.
   #+END_theorem

   #+BEGIN_proof
   Assume WCR, and let write $s\in UN$ to indicate that $s$ has a unique normal
   form. If a term is strongly normalizing, then so are all the terms occuring
   in its reduction tree

   Assume $t\in SN, t\not\in UN$. Then there are two reduction sequences
   $t\succ_1 t_1'\dots\succ_1 t'$ and $t\succ_1 t_1''\succ_1\dots\succ_1 t''$ with
   $t'\not\equiv t''$. Then either $t'_1=t''_1$ or $t'_1\neq t_1''$

   In the first case we can take $t_1:=t_1'=t_1''$. In the second case, by WCR
   we can find a $t^*$ s.t. $t^*\prec t_1',t_1''$; $t\in SN$ hence $t^*\succ
   t'''$ for some normal $t'''$. Since $t'\neq t'''$ or $t''\neq t'''$, either
   $t_1'\not\in UN$ or $t_1''\not\in UN$; so take $t_1:=t_1'$ if $t'\neq t'''$,
   $t_1:=t_1''$ otherwise.

   Hence we can always find a $t_1\prec t$ with $t_1\not\in UN$ and get an
   infinite sequence contradicting the SN of $t$
   #+END_proof

   #+ATTR_LATEX: :options []
   #+BEGIN_definition
   The *simple typed lambda calculus* $\blambdato$ is the calculus of
   \beta-reduction and \beta-equality on the set of terms of $\blambda_{\bto}$
   defined in ref:def1.2.2
   $\blambda_{\bto}$ has the term system as described with the following axioms and
   rules for $\prec$ ($\prec_\beta$) and $=$ (is $=_\beta$)
   \begin{align*}
   &t\succeq t\quad(\lambda x^A.t^B)s^A\succeq t^B[x^A/s^A]\\
   &\frac{t\succeq s}{rt\succeq rs}\quad
   \frac{t\succ s}{tr\succ sr}\quad
   \frac{t\succeq s}{\lambda x.t\succeq\lambda x.s}\quad
   \frac{t\succeq s\quad s\succeq r}{t\succeq r}\\
   &\frac{t\succeq s}{t=s}\quad\frac{t=s}{s=t}\quad
   \frac{t=s\quad s=r}{t=r}
   \end{align*}
   The *extensional simple typed lambda calculus* $\blambda\boldeta_\to$ is the
   calculus of \beta\eta-reduction and \beta\eta-equality and the set of terms
   of $\blambda_{\bto}$; in addition there is the axiom
   \begin{equation*}
   \lambda x.tx\succeq t\quad(x\not\in\FV(t))
   \end{equation*}
   #+END_definition

   #+ATTR_LATEX: :options [Substitutivity of $\succ_\beta$ and $\succ_{\beta\eta}$]
   #+BEGIN_lemma
   For $\succeq$ either $\succeq_\beta$ or $\succ_{\beta\eta}$ we have
   \begin{equation*}
   \text{if } s\succeq s' \text{ then } s[y/s'']\succeq s'[y/s'']
   \end{equation*}
   #+END_lemma
   #+BEGIN_proof
   By induction on the depth of a proof of $s\succeq s'$. It suffices to check
   the crucial basis step, where $s$ is $(\lambda x.t)t'$ and $s'$ is $t[x/t']$.
   \begin{equation*}
   (\lambda x.t)t'[y/s'']=(\lambda x.(t[y/s''])t'[y/s''])=
   t[y/s''][x/t'[y/s'']]=t[x/t'][y/s'']
   \end{equation*}
   #+END_proof

   #+ATTR_LATEX: :options []
   #+BEGIN_proposition
   $\succ_{\beta,1}$ and $\succ_{\beta\eta,1}$ are weakly confluent
   #+END_proposition
   #+BEGIN_proof
   If the conversions leading from $t$ to $t'$ and $t$ to $t''$ concern disjoint
   redexes, then $t'''$ is simply obtained by converting both redexes

   If $t\equiv\dots(\lambda x.s)s'\dots$, $t'\equiv\dots s[x/s']\dots$ and
   $t''\equiv\dots(\lambda x.s)s''\dots$, $s'\succ_1 s''$, then $t'''\equiv\dots
   s[x/s'']\dots$ and $t'\succeq t'''$  
   in as many steps as there are occurrences of $x$ in $s$, hence /weak/

   If $t\equiv\dots(\lambda x.s)s'\dots$, $t'\equiv\dots s[x/s']\dots$ and
   $t''\equiv\dots(\lambda x.s'')s'\dots$, $s\succ_1 s''$, then $t'''\equiv\dots
   s''[x/s']\dots$

   If $t\equiv\dots(\lambda x.sx)s'$, $t'=\dots (sx)[x/s']\dots$,
   $t''\equal\dots ss'\dots$
   #+END_proof

   #+ATTR_LATEX: :options []
   #+BEGIN_theorem
   The terms of $\blambda_{\bto},\blambda\boldeta_{\bto}$ are SN for $\succeq_\beta$ and
   $\succeq_{\beta\eta}$ respectively, then hence the \beta- and
   \beta\eta-normal forms are unique
   #+END_theorem

   From the preceding theorem it follows that the reduction relations are
   confluent. This can also be proved directly, without relying on strong
   normalization, by the following method, due to W. W. Tait and P. Martin-Löf
   (see Barendregt [1984, 3.2]) which also applies to the untyped lambda calculus.
   The idea is to prove confluence for a relation $\succeq_p$ which intuitively
   corresponds to conversion of a finite set of redexes such that in case of
   nesting the 
   inner redexes are converted before the outer ones.
   #+ATTR_LATEX: :options []
   #+BEGIN_definition
   $\succeq_p$ on $\blambda_{\bto}$ is generated by the axiom and rules
   \begin{alignat*}{2}
   &(\text{id})x\succeq_p x\\
   &(\lambda\text{mon})\frac{t\succeq_p t'}{\lambda x.t\succeq_p \lambda x.t'}&&
   (\text{appmon})\frac{t\succeq_p t'\quad s\succeq_p s'}{ts\succeq_p t's'}\\
   &(\beta\text{par})\frac{t\succeq_p t'\quad s\succeq_ps'}{(\lambda x.t)s\succeq_pt'[x/s']}
   &&(\eta\text{par})\frac{t\succeq_p t'}{\lambda x.tx\succeq_pt'}
   (x\not\in\FV(t))
   \end{alignat*}
   #+END_definition
   
   #+ATTR_LATEX: :options [Substitutivity of $\succeq_p$]
   #+BEGIN_lemma
   If $t\succeq_p t',s\succeq_p s'$, then $t[x/s]\succeq_p t'[x/s']$
   #+END_lemma

   #+BEGIN_proof
   By induction on $t$. Assume, w.l.o.g., $x\not\in\FV(s)$

   1. $t\equiv(\lambda y.t_1)t_2$, then
      \begin{align*}
      &t\succeq_p t_1'[y/t_2']\\
      &t[x/s]\equiv(\lambda y.t_1[x/s])t_2[x/s]\succeq_p
      t_1'[x/s'][y/t_2'[x/s']]\equiv
      t_1'[y/t_2'][x/s']
      \end{align*}

   #+END_proof

   #+ATTR_LATEX: :options []
   #+BEGIN_lemma
   $\succeq_p$ is confluent
   #+END_lemma

   #+BEGIN_proof
   Induction on $\abs{t}$ we show: for all \(t',t''\), if \(t\succeq_p t',t''\),
   then there is a \(t'''\) s.t. \(t',t''\succeq_p t'''\)
   1. If \(t\succeq_p t',t''\) by applications of the same clause  in the
      definition of \(\succeq_p\)
   2. Let
      \begin{align*}
      &t\equiv\lambda x.t_0x\succeq_p\lambda x.t_0'x,\text{ where }t_0\succeq_p t_0'(\lambda\text{mon})\\
      &t\succeq_p t_0'',\text{ where }t_0\succeq_p t_0''(\eta\text{par})
      \end{align*}
   3. Let
      \begin{align*}
      &t\equiv\lambda x.(\lambda x.t_0)x\succeq_p\lambda x.t_0',
      \text{where }t_0\succeq_p t_0'(\betapar,\lambdamon)\\
      &t\succeq_p t_0'',\text{ where }\lambda x.t_0\succeq_pt_0''(\etapar)
      \end{align*}
   4. Let
      \begin{align*}
      &t\equiv(\lambda x.t_0)t_1\succeq_p(\lambda x.t_0')t_1'\\
      &\quad\text{where }t_0\succeq_p t_0',t_1\succeq_p t_1'(\lambdamon,\appmon)\\
      &t\succeq_p t_0''[x/t_1''],\text{where }t_0\succeq_pt_0'',t_1\succeq_pt_1''(\betapar)
      \end{align*}
   5. Let
      \begin{align*}
      &t\equiv(\lambda x.t_0x)t_1\succeq_p t_0't_1'\\
      &\quad\text{ where }t_0\succeq_pt_0',t_1\succeq t_1',x\not\in\FV(t_0)(
      \etapar,\appmon)\\
      &t\succeq_pt_0''[x/t_1''],\text{where }t_0x\succeq_p t_0'',t_1\succeq_pt_1''(\betapar)
      \end{align*}
   #+END_proof

   #+ATTR_LATEX: :options []
   #+BEGIN_theorem
   \beta- and \beta\eta-reduction are confluent
   #+END_theorem
   #+BEGIN_proof
   The reflexive closure of $\succ_1$ for \beta\eta-reduction is contained in
   $\succeq_p$, and $\succeq$ is therefore the transitive closure of
   $\succeq_p$. Write $t\succeq_{p,n}t'$ if there is a chain
   $t\equiv t_0\succeq_p t_1\succeq_p\dots\succeq_pt_n\equiv t'$. Then we show
   by induction on $n+m$ using the preceding lemma, that if
   $t\succeq_{p,n}t',t\succeq_{p,m}t''$ then there is a $t'''$ s.t.
   $t'\succeq_{p,m}t''',t''\succeq_{p,n}t'''$ 
   \begin{center}
   \begin{tikzcd}
   t \arrow[r,"\alpha-1"] \arrow[rd,"n+m+1-\alpha"{left}]&
   t_0' \arrow[r,"1"] \arrow[rd,"n+m+1-\alpha"]&
   t' \arrow[rd]\\
   &t'' \arrow[r,"\alpha-1"] &
   t_0''' \arrow[r]&t'''
   \end{tikzcd}
   \end{center}
   
   #+END_proof

   #+ATTR_LATEX: :options [Terms of typed combinatory logic $\cl_\to$]
   #+BEGIN_definition
   The terms are inductive defined as in the case of $\blambda_{\bto}$, but now with
   the clauses
   1. For each $A\in\calt_\to$ there is a countably infinite supply of variables
      of type $A$; for arbitrary variables of type $A$ we use
      $u^A,v^A,w^A,x^A,y^A,z^A$
   2. for each $A,B,C\in\calt$ there are constant terms
      \begin{align*}
      &\bk^{A,B}\in A\to(B\to A)\\
      &\bs^{A,B,C}\in (A\to(B\to C))\to((A\to B)\to(A\to C))
      \end{align*}
   3. if $t^{A,B},s^A$ are terms, then so is $t^{A,B}s$

      
   $\FV(\bk)=\FV(\bs)=\emptyset$
   #+END_definition

   #+ATTR_LATEX: :options []
   #+BEGIN_definition
   The *weak reduction* relation $\succeq_w$ on the terms of $\cl_\to$ is
   generated by a conversion relation $\cont_w$ consisting of the following
   pairs
   \begin{equation*}
   \bk^{A,B}x^Ay^B\e\cont_w\e x,\quad\bs^{A,B,C}x^{A\to(B\to C)}y^{A\to B}z^A
   \e\cont_w\e xz(yz)
   \end{equation*}

   In otherwords, $\cl_\to$ is the term system defined above with the following
   axioms and rules for $\succeq_w$ and $=_w$
   \begin{alignat*}{3}
   &t\succeq t&&\bk xy\succeq x\quad&&\bs xyz\succeq xz(yz)\\
   &\frac{t\succeq s}{rt\succeq rs}\quad&&\frac{t\succeq s}{tr\succeq sr}&&
   \frac{t\succeq s\quad s\succeq r}{t\succeq r}\\
   &\frac{t\succeq s}{t=s}&&\frac{t=s}{s=t}&&\frac{t=s\quad s=r}{t=r}
   \end{alignat*}
   #+END_definition

   #+ATTR_LATEX: :options []
   #+BEGIN_theorem
   The weak reduction relation in $\cl_\to$, is confluent and
   strongly normalizing, so normal forms are unique.
   #+END_theorem

   #+ATTR_LATEX: :options []
   #+BEGIN_theorem
    To each term $t$ in $\cl_\to$, there is another term $\lambda^*x^A.t$ such
    that
    1. $x^A\not\in\FV(\lambda^*x^A.t)$
    2. $(\lambda^*x^A.t)s^A\succ_wt[x^A/s^A]$
   #+END_theorem
   #+BEGIN_proof
   \begin{align*}
   &\lambda^*x^A.x:=\bs^{A,A\to A,A}\bk^{A,A\to A}\bk^{A,A}\\
   &\lambda^*x^A.y^B:=\bk^{B,A}y^B\text{ for }y\not\equiv x\\
   &\lambda^*x^A.t_1^{B\to C}t_2^B:=\bs^{A,B,C}(\lambda^*x.t_1)(\lambda^*x.t_2)
   \end{align*}
   #+END_proof

   #+ATTR_LATEX: :options []
   #+BEGIN_corollary
   $\cl_\to$ is *combinatorially complete*, i.e. for every applicative
   combination $t$ of $\bk,\bs$ and variables $x_1,x_2,\dots x_n$ there is a
   closed term $s$ s.t. in $\cl_\to\vdash sx_1\dots x_n=_w t$, in fact even
   $\cl_\to\vdash sx_1\dots x_n\succeq_w t$
   #+END_corollary

   #+BEGIN_remark
   Note that: it's not true that if $t=t'$ then $\lambda^*x.t=\lambda^*x.t'$. 
   $\bk x\bk=x$ but $\lambda^*x.\bk x\bk=\bs(\bs(\bk\bk)(\bs\bk\bk))(\bk\bk)$,
   $\lambda^*x.x=\bs\bk\bk$
   #+END_remark

   #+ATTR_LATEX: :options []
   #+BEGIN_definition
   The *Church numerals* of type $A$ are \beta-normal terms $\bar{n}_A$ of type 
   $(A\to A)\to(A\to A), n\in\N$, defined by
   \begin{equation*}
   \bar{n}_A:=\lambda f^{A\to A}\lambda x^A.f^n(x)
   \end{equation*}
   where $f^0(x):=x,f^{n+1}(x):=f(f^n(x))$. $N_A=\{\bar{n}_A\}$
   #+END_definition
   N.B. If we want to use \beta\eta-normal terms, we must use $\lambda f^{A\to
   A}.f$ instead of $\lambda fx.fx$ for $\bar{1}_A$

   #+ATTR_LATEX: :options []
   #+BEGIN_definition
   A function ff$f:\N^k\to\N$ is said to be *A-representable* if there is a term $F$
   of $\blambda_{\bto}$ s.t. (abbreviating $\bar{n}_A$ as $\bar{n}$)
   \begin{equation*}
   F\bar{n}_1\dots\bar{n}_k=\bar{f(n_1,\dots,n_k)}
   \end{equation*}
   for all $n_1,\dots,n_k\in\N,\bar{n}_i=(\bar{n}_i)_A$
   #+END_definition


   #+ATTR_LATEX: :options []
   #+BEGIN_definition
   *Polynomials*, *extended polynomials*
   1. The \(n\)-argument *projections* $\bp_i^n$ are given by
      $\bp_i^n(x_1,\dots,x_n)=x_i$, the unary constant functions $\bc_m$ by
      $\bc_m(x)=m$, and $\sg$, $\overline{\sg}$ are unary functions which satisfy
      $\sg(S_n)=1$, $\sg(0)=0$, where $S$ is the successor function.
   2. The \(n\)-argument function $f$ is the *composition* of \(m\)-argument $g$,
      \(n\)-argument $h_1,\dots,h_m$ if $f$ satisfies
      $f(\bar{x})=g(h_1(\bar{x}),\dots,h_m(\bar{x}))$
   3. The *polynomials* in $n$ variables are generated from $\bp_i^n,\bc_m$,
      addition and multiplication by closure under composition. The *extended
      polynomials* are generated from $\bp_i^n,\bc_m,\sg,\bar{sg}$, addition and
      multiplication by closure under proposition
   #+END_definition

   #+BEGIN_exercise
   Show that all terms in \beta-normal form of type $(P\to P)\to(P\to P)$, $P$ a
   propositional variable, are either of the form $\bar{n}_P$ or of the form
   $\lambda f^{P\to P}.f$
   #+END_exercise
   #+BEGIN_proof
   1. $\lambda f^{P\to P}\lambda x^P.t^P$ and $t$ is in \beta-normal form.
   2. $\lambda f^{P\to P}.f$
   #+END_proof

   #+ATTR_LATEX: :options []
   #+BEGIN_theorem
   All extended polynomials are representable in $\blambda_{\bto}$
   #+END_theorem
   #+BEGIN_proof
   Abbreviate $\N_A$ as $N$.
   \begin{alignat*}{2}
   &F_+&&:=\lambda x^Ny^Nf^{A\to A}z^A.xf(yfz)\\
   &F_\times&&:=\lambda x^Ny^Nf^{A\to A}.x(yf)\\
   &F_{\bp_i^k}&&:=\lambda x_1^N\dots x_k^N.x_i\\
   &F_{\bc_n}&&:=\lambda x^N.\overline{n}\\
   &F_{\sg}&&:=\lambda x^Nf^{A\to A}z^A.x(\lambda u^A.fz)z\\
   &F_{\overline{\sg}}&&:=\lambda x^Nf^{A\to A}z^A.x(\lambda u^A.z)(fz)
   \end{alignat*}
   #+END_proof

** Three Types of Formalism
*** The BHK-interpretation
    Minimal logic and intuitionistic logic differ only in the treatment of
    negation, or (equivalently) falsehood, and minimal implication logic is the
    same  
    as intuitionistic implication logic
    
    The informal interpretation underlying intuitionistic logic is the
    Brouwer-Heyting-Kolmogorov interpretation; this interpretation tells us what
    it means to 
    prove a compound statement such as $A\to B$ in terms of what it means to
    prove the components $B$ and $A$ 
    \begin{align*}
    &\text{A construction }p\text{ proves }A\to B\text{ if }p\text{ transforms any
    possible proof }q\\
    &\text{of }A\text{ into a proof }p(q)\text{ of }B
    \end{align*}

    The BHK-interpretation of intuitionistic logic is based on the notion of *proof*
    instead of truth

    A *logical law* of implication logic, according to the BHK-interpretation, is a
    formula for which we can give a proof, no matter how we interpret the atomic
    formulas. A *rule* is valid for this interpretation if we know how to construct
    a proof for the conclusion, given proofs of the premises

    The following two rules for $\to$ are obviously valid on the basis of the
    BHK-interpretation: 
    1. If, starting from a hypothetical (unspecified) proof $u$ of $A$, we can find
       a proof $t(u)$ of B, then we have in fact given a proof of $A\to B$ (without
       the assumption that $u$ proves $A$). This proof may be denoted by
       $\lambda u.t(u)$.
    2. Given a proof $t$ of $A\to B$, and a proof $s$ of A, we can apply $t$ to $s$
       to obtain a proof of $B$. For this proof we may write $\app(t,s)$ or $ts$ ($t$
       applied to $s$).
*** A natural deduction system for minimal implication logic 
    Characteristic for natural deduction is the use of assumptions which may
    be *closed* at some later step in the deduction.

    The assumptions in a deduction which are occurrences of the same formula
    with the same marker form together an *assumption class*. The notations
    \begin{alignat*}{4}
    &[A]^u\e\e&&A^u\e\e&&\cald'\e\e&&\cald'\\
    &\cald&&\cald&&[A]&&A\\
    &B&&B&&\cald&&\cald\\
    & && &&B&&B
    \end{alignat*}
    have the following meaning, from left to right: 
    1. a deduction $\cald$, with
       conclusion $B$ and a set $[A]$ of open assumptions, consisting of all
       occurrences of 
       the formula $A$ at top nodes of the prooftree $\cald$ with marker $u$ (note: both $B$
       and the $[A]$ are part of $\cald$, and we do not talk about the *multiset* $[A]^u$ since
       we are dealing with formula occurrences);
    2. a deduction $\cald$, with conclusion
       $B$ and a single assumption of the form $A$ marked $u$ occurring at some top
       node;
    3. deduction $\cald$ with a deduction $\cald'$, with conclusion $A$, substituted
       for the assumptions $[A]^u$ of $\cald$; (4) the same, but now for a single assumption
       occurrence $A$ in $\cald$. 
    4. the formula $A$ shown is the conclusion of $\cald'$
       as well as the formula in an assumption class of $\cald$.


    We now consider a system $\tonm$ for the minimal theory of implication.

    A single formula occurrence $A$ labelled with a marker is a single-node
    prooftree, representing a deduction with conclusion A from open assumption
    A.

    \begin{center}
    \AxiomC{$[A]^u$}
    \noLine
    \UnaryInfC{$\cald$}
    \noLine
    \UnaryInfC{$B$}
    \RightLabel{${\to}$I$,u$}
    \UnaryInfC{$A\to B$}
    \DisplayProof
    \hspace{1cm}
    \AxiomC{$\cald$}
    \noLine
    \UnaryInfC{$A\to B$}
    \AxiomC{$\cald'$}
    \noLine
    \UnaryInfC{$A$}
    \RightLabel{${\to}$E}
    \BinaryInfC{$B$}
    \DisplayProof
    \end{center}

    By application of the rule ${\to}\text{I}$ of *implication introduction*, a
    new prooftree is  
    formed from $\cald$ by adding at the bottom the conclusion $A\to B$ while *closing*
    the set of open assumptions $A$ marked by $u$. All other open assumptions
    remain open in the new prooftree

    The rule ${\to}\text{E}$ of *implication elimination* (also known as *modus
    ponens*) 
    constructs from two deductions $\cald,\cald'$ with conclusions $A\to B,A$ a new
    combined deduction with conclusion $B$, which has as open assumptions the
    open assumptions of $\cald$ and $\cald'$ combined

    Two occurrences \alpha,\beta of the same formula belong to the same 
    *assumption class* if they bear the same label and either are both open or
    have both been 
    closed at the same inference.

    It should be noted that in the rule \(\to\)I the "degenerate case", where
    $[A]^u$ is empty, is permitted; thus for example the following is a correct
    deduction:
    \begin{prooftree}
    \AxiomC{$A^u$}
    \RightLabel{$v$}
    \UnaryInfC{$B\to A$}
    \RightLabel{$u$}
    \UnaryInfC{$A\to(B\to A)$}
    \end{prooftree}
*** Formulas-as-types
    1. To assumptions $A$ correspond variables of type $A$; more precisely,
       formulas with the same marker get the same variable.
    2. For the rules \(\to\)I and \(\to\)E the assignment of terms to the
       conclusion is shown below
       \begin{center}
       \AxiomC{$[u:A]$}
       \noLine
       \UnaryInfC{$\calc$}
       \noLine
       \UnaryInfC{$t:B$}
       \RightLabel{$u$}
       \UnaryInfC{$\lambda u^A.t^B:A\to B$}
       \DisplayProof
       \hspace{1cm}
       \AxiomC{$\cald$}
       \noLine
       \UnaryInfC{$t:A\to B$}
       \AxiomC{$\cald'$}
       \noLine
       \UnaryInfC{$s:A$}
       \BinaryInfC{$(t^{A\to B}s^A):B$}
       \DisplayProof
       \end{center}


    Thus there is a very close relationship between $\blambda_\bto$ and $\tonm$

    A \beta-conversion
    \begin{equation*}
    (\lambda x^A.t^B)s^A\e\cont_\beta\e t^B[x^A/s^A]
    \end{equation*}
    corresponds to a transformation on prooftrees:
    \begin{center}
    \AxiomC{$[A]^u$}
    \noLine
    \UnaryInfC{$\cald$}
    \noLine
    \UnaryInfC{$B$}
    \RightLabel{$u$}
    \UnaryInfC{$A\to B$}
    \AxiomC{$\cald'$}
    \noLine
    \UnaryInfC{$A$}
    \BinaryInfC{$B$}
    \DisplayProof
    $\e\mapsto\e$
    \alwaysNoLine
    \AxiomC{$\cald'$}
    \UnaryInfC{$[A]$}
    \UnaryInfC{$\cald$}
    \UnaryInfC{$B$}
    \DisplayProof
    \noLine
    
    \end{center}

    A proof without detours is said to be a *normal* proof. In a normal proof the
    left premise of \(\to\)E is never the conclusion of \(\to\)I
*** Gentzen systems
    There are two motivations leading to Gentzen systems, which will be discussed
    below. The first one views a Gentzen system as a metacalculus for natural
    deduction; this applies in particular to systems for minimal and intuitionistic
    logic. The second motivation is semantical: Gentzen systems for classical logic
    are obtained by analysing truth conditions for formulas. This also applies to
    intuitionistic and minimal logic if we use Kripke semantics instead of classical
    semantics.



    A *Gentzen system as a metacalculus*. Let us first consider a Gentzen system
    obtained as a metacalculus for the system $\tonm$. Consider the following
    four construction steps for prooftrees.
    1. The single-node tree with label $A$, marker $u$ is a prooftree
    2. Add at the bottom of a prooftree an application of \(\to\)I, discharging
       an assumption class
    3. Given a prooftree $\cald$ with open assumption class $[B]^u$ and a
       prooftree $\cald_1$ deriving $A$, replace all occurrences of $B$ in
       $[B]^u$ by
       \begin{prooftree}
       \AxiomC{$A\to B^v$}
       \AxiomC{$\cald_1$}
       \noLine
       \UnaryInfC{$A$}
       \BinaryInfC{$B$}
       \end{prooftree}
    4. Substitute a deduction of $A$ for the occurrences of an (open) assumption
       class $[A]^u$ of another deduction


    These construction principles suffice to obtain any prooftree of $\tonm$.
    The closure under \(\to\)E is seen as follows: in order to obtain the tree
    \begin{prooftree}
    \AxiomC{$\cald_1$}
    \noLine
    \UnaryInfC{$A\to B$}
    \AxiomC{$\cald_2$}
    \noLine
    \UnaryInfC{$A$}
    \BinaryInfC{$B$}
    \end{prooftree}
    we first combine the first and third construction principles to obtain
    \begin{prooftree}
    \AxiomC{$A\to B^u$}
    \AxiomC{$\cald_2$}
    \noLine
    \UnaryInfC{$A$}
    \BinaryInfC{$B$}
    \end{prooftree}
    and then use the fourth principle to obtain the desired tree


    Let $\Gamma\Rightarrow A$ express that $A$ is deducible in $\tonm$ from
    assumptions in \Gamma. Then the four construction principles correspond to
    the following axiom and rules
    \begin{align*}
    &\Gamma\cup\{A\}\Rightarrow A\text{ (Axiom)}\\
    &
    \AxiomC{$\Gamma\cup\{A\}\Rightarrow B$}
    \RightLabel{R${\to}$}
    \UnaryInfC{$\Gamma\Rightarrow A\to B$}
    \DisplayProof
    \hspace{1cm}
    \AxiomC{$\Gamma\Rightarrow A$}
    \AxiomC{$\Delta\cup\{B\}\Rightarrow C$}
    \RightLabel{L${\to}$}
    \BinaryInfC{$\Gamma\cup\Delta\cup\{A\to B\}\Rightarrow C$}
    \DisplayProof
    \\
    &\AxiomC{$\Gamma\Rightarrow A$}
    \AxiomC{$\Delta\cup\{A\}\Rightarrow B$}
    \RightLabel{Cut}
    \BinaryInfC{$\Gamma\cup\Delta\Rightarrow B$}
    \DisplayProof
    \end{align*}


    Call the resulting system $\cals$. Here in the sequents $\Gamma\Rightarrow
    A$ the \Gamma is treated as a (finite) set. If we rewrite the system above
    with multisets, we get the Genzten system $\cals'$ described below.
    \begin{alignat*}{2}
    &A\Rightarrow A\text{ (Axiom)}&&\\
    &\AxiomC{$\Gamma\Rightarrow A$}
    \AxiomC{$\Delta,B\Rightarrow C$}
    \RightLabel{L$\to$}
    \BinaryInfC{$\Gamma,\Delta,A\to B\Rightarrow C$}
    \DisplayProof
    \quad
    &&\AxiomC{$\Gamma,A\Rightarrow B$}
    \RightLabel{R$\to$}
    \UnaryInfC{$\Gamma\Rightarrow A\to B$}
    \DisplayProof\\
    &\AxiomC{$\Gamma\Rightarrow A$}
    \RightLabel{LW}
    \UnaryInfC{$\Gamma,B\Ra A$}
    \DisplayProof
    &&\AxiomC{$\Gamma,B,B,\Ra A$}
    \RightLabel{LC}
    \UnaryInfC{$\Gamma,B\Ra A$}
    \DisplayProof\\
    &\AxiomC{$\Gamma\Ra A$}
    \AxiomC{$A,\Delta\Ra B$}
    \RightLabel{Cut}
    \BinaryInfC{$\Gamma,\Delta\Ra B$}
    \DisplayProof
    &&
    \end{alignat*}

        

    R\(\to\) and L\(\to\) are called the logical rules, LW, LC and Cut the
    structural rules. 
    LC is called the rule of (left-) *contraction*, LW the rule of
    (left-) *weakening*. 
    

    It is not hard to convince oneself that, as long as only the principles 1-3
    for the construction of prooftrees are applied, the resulting proof will always
    be *normal*. Conversely, it may be proved that all normal prooftrees can be
    obtained using construction principles 1-3 only. Thus we see that normal
    prooftrees in $\tonm$ correspond to deduction in the sequent calculus without
    Cut; 

    Deductions in $\cals$ without the rule Cut have a very nice property, which is
    immediately obvious: the *subformula property*: all formulas occurring in a
    deduction of $\Gamma\Ra A$ are subformulas of the formulas in $\Gamma,A$.

    #+BEGIN_exercise
    There are other possible choices for the construction principles for
    prooftrees. For example, we might replace principle 3 by the following
    principle 3':

    Given a prooftree $\cald$ with open assumption class $[B]^u$, replace all
    occurrences of $B$ in $[B]^u$ by
    \begin{prooftree}
    \AxiomC{$A\to B^v$}
    \AxiomC{$A$}
    \BinaryInfC{$B$}
    \end{prooftree}
    #+END_exercise
*** Semantical motivation of Gentzen systems
    Here we use sequents $\Gamma\Ra\Delta$ with $\Gamma$ and \Delta finite sets;
    the intuitive interpretation is that $\Gamma\Ra\Delta$ is valid iff
    $\bigwedge\Gamma\to\bigvee\Delta$ is true. Now suppose we want to find out if there is a valuation making all of
    $\Gamma$ true and all of \Delta false. We can break down this problem by means of two
    rules, one for reducing $A\to B$ on the left, another for reducing $A\to B$ on
    the right:
    \begin{center}
    \AxiomC{$\Gamma\Ra A,\Delta$}
    \AxiomC{$\Gamma,B\Ra\Delta$}
    \RightLabel{L$\to$}
    \BinaryInfC{$\Gamma,A\to B\Ra\Delta$}
    \DisplayProof
    \hspace{0.6cm}
    \AxiomC{$\Gamma,A,\Ra B,\Delta$}
    \RightLabel{R$\to$}
    \UnaryInfC{$\Gamma\Ra A\to B,\Delta$}
    \DisplayProof
    \end{center}
*** A Hilbert system
    The Hilbert system $\tohm$ for minimal implication logic has as axioms all
    formulas of the forms:
    \begin{align*}
    &A\to (B\to A)\quad\text{k-axioms}\\
    &(A\to(B\to C))\to((A\to B)\to(A\to C))\quad(s-axioms)
    \end{align*}

    The corresponding term system for $\tohm$ is $\cl_\bto$
* N-systems and H-systems
** Natural Deduction Systems
   #+ATTR_LATEX: :options [\textit{The systems} $\Nm,\Ni,\Nc$ ]
   #+BEGIN_definition
   Assumptions are formula occurrences always appearing at the top of a branch
   and are supposed to be labelled by markers. The set of assumptions of the
   same form with the same marker forms an *assumption class*. Distinct formulas
   must have distinct markers. _We permit empty assumption classes_.

   Assumptions may be closed; assumption classes are always closed "en bloc",
   that is to say, at each inference, either all assumptions in a class are
   closed, or they are left open.

   Deductions in the system of natural deduction are generated as follows.

   \noindent /Basis/. The single-node tree with label $A$ is a (natural) *deduction*
   from the open assumption $A$; there are no closed assumptions

   \noindent /Inductive step/. Let $\cald_1,\cald_2,\cald_3$ be deductions. A
   (natural) *deduction* $\cald$ may be constructed according to one of the rules
   below. The class $[A]^u,[B]^v$ 

   For $\wedge,\vee,\to,\forall,\exists$ we have *introduction rules* (*I-rules*)
   and *elimination rules* (*E-rules*)
   \begin{gather*}
   \AxiomC{$\cald_1$}
   \noLine
   \UnaryInfC{$A$}
   \AxiomC{$\cald_2$}
   \noLine
   \UnaryInfC{$B$}
   \RightLabel{\(\wedge\)I}
   \BinaryInfC{$A\wedge B$}
   \DisplayProof\hspace{0.7cm}
   \AxiomC{$\cald_1$}
   \noLine
   \UnaryInfC{$A\wedge B$}
   \RightLabel{$\wedge\text{E}_{\text{R}}$}
   \UnaryInfC{$A$}
   \DisplayProof\hspace{0.7cm}
   \AxiomC{$\cald_1$}
   \noLine
   \UnaryInfC{$A\wedge B$}
   \RightLabel{$\wedge\text{E}_{\text{L}}$}
   \UnaryInfC{$B$}
   \DisplayProof\\
   \AxiomC{$[A]^u$}
   \noLine
   \UnaryInfC{$\cald_1$}\noLine\UnaryInfC{$B$}
   \RightLabel{$\to\text{I},u$}
   \UnaryInfC{$A\to B$}\DisplayProof\hspace{1cm}
   \AxiomC{$\cald_1$}
   \noLine\UnaryInfC{$A\to B$}
   \AxiomC{$\cald$}\noLine\UnaryInfC{$A$}
   \RightLabel{$\to$E}\BinaryInfC{$B$}\DisplayProof\\
   \AxiomC{$\cald_1$}\noLine\UnaryInfC{$A$}
   \RightLabel{$\vee\text{I}_{\text{R}}$}
   \UnaryInfC{$A\vee B$}\DisplayProof\quad
   \AxiomC{$\cald_1$}\noLine\UnaryInfC{$B$}
   \RightLabel{$\vee\text{I}_{\text{L}}$}
   \UnaryInfC{$A\vee B$}\DisplayProof\quad
   \AxiomC{$\cald_1$}\noLine\UnaryInfC{$A\vee B$}
   \AxiomC{$[A]^u$}\noLine\UnaryInfC{$\cald_2$}\noLine
   \UnaryInfC{$C$}\AxiomC{$[B]^u$}\noLine\UnaryInfC{$\cald_3$}
   \noLine\UnaryInfC{$C$}
   \RightLabel{$\vee\text{E},u,v$}
   \TrinaryInfC{$C$}\DisplayProof\\
   \AxiomC{$\cald_1$}\noLine\UnaryInfC{$A[x/y]$}
   \RightLabel{$\forall$I}\UnaryInfC{$\forall xA$}\DisplayProof\quad
   \parbox{11em}{In $\forall\text{I},y\equiv x$ or $y\not\in\FV(A)$, and $y$ is
   not free in any assumption open in $\cald_1$}\hspace{0.9cm}
   \AxiomC{$\cald_1$}\noLine\UnaryInfC{$\forall xA$}
   \RightLabel{$\forall$E}\UnaryInfC{$A[x/t]$}\DisplayProof\\
   \AxiomC{$\cald_1$}\noLine\UnaryInfC{$A[x/t]$}
   \RightLabel{$\exists$I}\UnaryInfC{$\exists xA$}\DisplayProof\hspace{0.9cm}
   \AxiomC{$\cald_1$}
   \noLine\UnaryInfC{$\exists xA$}\AxiomC{$[A[x/y]]^u$}\noLine
   \UnaryInfC{$\cald_2$}\noLine\UnaryInfC{$C$}
   \RightLabel{$\exists\text{E},u$}\BinaryInfC{$C$}\DisplayProof\quad
   \parbox{11em}{In $\exists\text{I},y\equiv x$ or $y\not\in\FV(A)$, and $y$ is
   not free  in $C$ nor in any assumption open in $\cald_2$ except in
   $[A[x/y]]^u$}
   \end{gather*}

   This completes the description of the rules for the minimal logic $\Nm$. Note
   that $\bot$ has not been mentioned in any of the above rules, and therefore
   it behaves in minimal logic as an arbitrary unprovable propositional
   constant.

   To obtain the intuitionistic and classical system $\Ni$ and $\Nc$ we add the 
   *intuitionistic absurdity rule* $\bot_\text{i}$ and the more general 
   *classical absurdity rule* $\bot_\text{c}$ respectively:
   \begin{equation*}
   \AxiomC{$\cald_1$}
   \noLine
   \UnaryInfC{$\bot$}\RightLabel{$\bot_\text{i}$}
   \UnaryInfC{$A$}\DisplayProof\hspace{1.5cm}
   \AxiomC{$[\neg A]^u$}\noLine\UnaryInfC{$\cald_1$}
   \noLine\UnaryInfC{$\bot$}\RightLabel{$\bot_{\text{c}},u$}\UnaryInfC{$A$}
   \DisplayProof
   \end{equation*}

   ($\bot_{\text{c}}$ is more general than $\bot_{\text{i}}$ since $[\neg A]^u$
   may be empty). In an E-rule application, the premise containing the occurence
   of the logical operator being eliminated is called the *major* premise. The
   other premise(s) are called the *minor* premise(s). As a standard convention in
   displaying prooftrees, we place the major premises of elimination rule
   applications in leftmost position.

   As to individual variables which are considered to be free in deduction, we
   stipulate
   * The deduction consisting of assumption $A$ only has $\FV(A)$ as free
     variables;
   * at each rule application, the free individual variables are inherited from
     the immediate subdeduction, except that
   * in an application of \(\exists\)E the occurrences of the free variable
     $y$ in $\cald_2$ become bound, and in an application of \(\forall\)I the
     occurrences of variable $y$ in $\cald_1$ become bound, and
   * in \(\to\)I the vairables in $\FV(A)$ have to be added in case $[A]^u$ is
     empty, in $\vee\text{I}_\text{R}$ those in $\FV(B)$ have to be added, and
     in $\vee\text{I}_\text{L}$ those in $\FV(A)$ have to be added


   The individual variable becoming bound in an application \alpha of
   \(\forall\)I or \(\exists\)E is said to be the *proper* variable of \alpha. 


   If $A$ is among the open assumptions of a dduction $\cald$ with conclusion
   $B$, then conclusion $B$ in $\cald$ is said to *depend* on $A$ in $\cald$. From
   now on we regard "assumption of $\cald$" and "open assumption of $\cald$" as
   synonymous. 
   #+END_definition

   #+ATTR_LATEX: :options []
   #+BEGIN_definition
   A convenient global assumption in the presentation of a deduction is the 
   *variable convention*. A deduction is said to satisfy the variable convention
   if the proper variables of the application of \(\exists\)E and \(\forall\)I
   are kept distinct.

   If moreover the bound and free variables are kept distinct, the deduction is
   said to be a *pure-variable* deduction.
   #+END_definition

   #+BEGIN_remark
   Since in out notation for prooftrees, $[A]^u$ refers to all assumptions
   $A$ labelled $u$, it is tacitly understood that in \(\vee\)E the label $u$
   occurs in $\cald_2$ only, and $v$ in $\cald_3$ only.
   #+END_remark

   #+ATTR_LATEX: :options []
   #+BEGIN_definition
   The theories generated by $\Nm,\Ni$ and $\Nc$ are denoted by $\bM$ (minimal
   logic), $\bI$ (intuitionistic logic) and $\bC$ (classical logic)
   respectively.

   $\Gamma\vdash_{\bS}A$ for $\bS=\bM,\bI,\bC$ iff $A$ is derivable from the set
   of assumptions \Gamma in the N-systems for $\bS$
   #+END_definition

   #+BEGIN_remark
   1. Sometimes it is more natural to write \(\forall\)E and \(\exists\)I as
      two-premise rules, with the individual term as second premise
      \begin{align*}
      \AxiomC{$\forall xA$}
      \AxiomC{$t$}
      \BinaryInfC{$A[x/t]$}
      \DisplayProof\hspace{1cm}
      \AxiomC{$A[x/t]$}
      \AxiomC{$t$}
      \BinaryInfC{$\exists xA$}
      \DisplayProof
      \end{align*}
   2. The statement of the rules \(\forall\)I and \(\exists\)E may be simplified
      somewhat if we rely on convention that formulas differing only in the
      naming of bound variables are equal. These rules may then be written as:
      \begin{gather*}
      \AxiomC{$\cald_1$}
      \noLine\UnaryInfC{$A$}\RightLabel{$\forall$I}
      \UnaryInfC{$\forall xA$}\DisplayProof\hspace{1cm}
      \AxiomC{$\cald_1$}
      \noLine\UnaryInfC{$\exists xA$}
      \AxiomC{$[A]^u$}\noLine\UnaryInfC{$\cald_2$}\noLine
      \UnaryInfC{$C$}\RightLabel{$\exists\text{E},u$}
      \BinaryInfC{$C$}\DisplayProof
      \end{gather*}
      where in \(\forall\)I $x$ is not free in any assumption open in $\cald_1$
      and and \(\exists\)E $x$ is not free in $C$ nor in any assumption open in
      $\cald_2$ except in $[A]^u$
   #+END_remark
*** Natural deductions in sequent style
    We call the set of open assumptions at a node the *context*. A context is a set
    \begin{equation*}
    u_1:A_1,u_2:A_2,\dots,u_n:A_n
    \end{equation*}
   where $u_i$ are pairwise distinct; the $A_i$ need not be distinct. The
   deductions now become trees where each node is labelled with a sequent of the
   form $\Gamma\Ra B$, \Gamma is a context. Below, when writing a union of
   contexts such as $\Gamma\Delta$ (short for $\Gamma\cup\Delta$), it will
   always be assumed that the union is *consistent*
   \begin{alignat*}{2}
   &u:A\Ra A\e(\text{Axiom})&&\\
   &\AxiomC{$\Gamma[u:A]\Ra B$}\RightLabel{$\to$I}
   \UnaryInfC{$\Gamma\Ra A\to B$}\DisplayProof&&
   \AxiomC{$\Gamma\Ra A\to B$}
   \AxiomC{$\Delta\Ra A$}\RightLabel{$\to$E}\BinaryInfC{$\Gamma\Delta\Ra B$}
   \DisplayProof\\
   &\AxiomC{$\Gamma\Ra A$}\AxiomC{$\Delta\Ra B$}\RightLabel{$\wedge$I}
   \BinaryInfC{$\Gamma\Delta\Ra A\wedge B$}\DisplayProof\quad&&
   \AxiomC{$\Gamma\Ra A_0\wedge A_1$}\RightLabel{$\wedge$E}
   \UnaryInfC{$\Gamma\Ra A_i$}\DisplayProof\\
   &\AxiomC{$\Gamma\Ra A_i$}\RightLabel{$\vee$I}
   \UnaryInfC{$\Gamma\Ra A_0\vee A_1$}\DisplayProof&&
   \def\defaultHypSeparation{\hskip 1pt}
   \AxiomC{$\Gamma\Ra A\vee B$}
   \AxiomC{$\Delta[u:A]\Ra C$}
   \AxiomC{$\Delta'[v:B]\Ra C$}
   \RightLabel{$\vee$E}
   \TrinaryInfC{$\Gamma\Delta\Delta'\Ra C$}\DisplayProof\\
   &\AxiomC{$\Gamma[x:\neg A]\Ra\bot$}\RightLabel{$\bot_\text{c}$}
   \UnaryInfC{$\Gamma\Ra A$}\DisplayProof&&
   \AxiomC{$\Gamma\Ra\bot$}\RightLabel{$\bot_{\text{i}}$}
   \UnaryInfC{$\Gamma\Ra A$}\DisplayProof\\
   &\EBA\AXC{$\Gamma\Ra[x/y]$}
   \RightLabel{$\forall$I}
   \UIC{$\Gamma\Ra\forall xA$}\DP&&\EBA
   \AXC{$\Gamma\Ra\forall xA$}\RL{$\forall$E}
   \UIC{$\Gamma\Ra A[x/t]$}\DP\\
   &\EBA\AXC{$\Gamma\Ra A[x/t]$}
   \RL{$\exists$I}\UIC{$\Gamma\Ra\exists xA$}\DP&&
   \EBA\AXC{$\Gamma\Ra\exists yA[x/y]$}
   \AXC{$\Delta[u:A]\Ra C$}\RL{$\exists$E}
   \BIC{$\Gamma\delta\Ra C$}\DP
   \end{alignat*}

   Here $[u:C]$ means that the assumption $u:C$ in the context may be present or
   absent.


   #+BEGIN_exercise
   Give proofs in $\Nm$ or in $\Ni$ of
   \begin{align*}
   &A\to(B\to A)\\
   &(A\to A\vee B),B\to(A\vee B)\\
   &(A\to C)\to[(B\to C)\to(A\vee B\to C)]\\
   &A\wedge B\to A,A\wedge B\to B,A\to(B\to A\wedge B)\\
   &\bot\to A\\
   &\forall xA\to A[x/t];\quad A[x/t]\to\exists xA\\
   &\forall x(B\to A)\leftrightarrow(B\to\forall yA[x/y])\e
   (x\not\in\FV(B),y\equiv x\text{ or }y\not\in\FV(A))\\
   &\forall x(A\to B)\leftrightarrow(\exists yA[x/y]\to B)\e
   (x\not\in\FV(B),y\equiv x\text{ or }y\not\in\FV(A))
   \end{align*}
   #+END_exercise
   #+BEGIN_proof
   \begin{gather*}
   \EBA\AXC{$A^u$}
   \RL{${\to}\text{I},v$}\UIC{$B\to A$}
   \RL{${\to}\text{I},u$}\UIC{$A\to(B\to A)$}\DP\quad
   \EBA\AXC{$A^u$}\RL{$\forall\text{I}_\text{R}$}
   \UIC{$A\vee B$}\RL{${\to}\text{I},u$}
   \UIC{$A\to (A\vee B)$}\DP
   \end{gather*}
   #+END_proof

   #+BEGIN_exercise
   Give proofs in $\Nm$ of 
   \begin{align*}
   &A\to\neg\neg A\\
   &\neg\neg\neg A\leftrightarrow\neg A\\
   &\neg\neg(A\to B)\to(\neg\neg A\to\neg\neg B)\\
   &\neg\neg(A\wedge B)\leftrightarrow(\neg\neg A\wedge\neg\neg B)\\
   &\neg(A\vee B)\leftrightarrow(\neg A\wedge \neg B)\\
   &\neg\neg\forall xA\to\forall x\neg\neg A\\
   \end{align*}
   #+END_exercise
   #+BEGIN_proof
   \begin{gather*}
   \EBA\AXC{$A\to\bot^u$}
   \AXC{$A^v$}\RL{$\to$E}
   \BIC{$\bot$}\RL{$\to,u$}
   \UIC{$(A\to\bot)\to\bot$}\RL{$\to,v$}
   \UIC{$A\to((A\to\bot)\to\bot)$}\DP\hspace{0.5cm}
   \EBA\AXC{$\neg\neg\neg A^u$}
   \AXC{$A^v$}
   \noLine\UIC{$\cald$}\noLine\UIC{$\neg\neg A$}
   \BIC{$\bot$}\DP
   \end{gather*}
   #+END_proof

   #+BEGIN_exercise
   Give proofs in $\Nm$ of
   1. $(B\to C)\to(A\to B)\to A\to C$ (*b*-axioms)
   2. $(A\to B\to C)\to B\to A\to C$ (*c*-axioms)
   3. $(A\to A\to B)\to A\to B$ (*w*-axioms)
   #+END_exercise

   #+ATTR_LATEX: :options [$\bigstar$]
   #+BEGIN_exercise
   Prove in $\Ni$ $(\neg\neg A\to\neg\neg B)\to\neg\neg(A\to B)$
   #+END_exercise
   #+BEGIN_proof
   \begin{gather*}
   \EBA\AXC{$(A\to B)\to\bot^v$}
   \AXC{$\cald$}\noLine\UIC{$B\to(A\to B)$}
   \AXC{$B^u$}
   \BIC{$A\to B$}
   \BIC{$\bot$}\RL{$\to,u$}
   \UIC{$B\to\bot$}\DP
   \end{gather*}
   #+END_proof

   #+BEGIN_exercise
   Prove in $\Nc$
   1. $A\vee B\leftrightarrow\neg(\neg A\wedge\neg B)$
   2. $\exists xA\leftrightarrow\neg\forall x\neg A$
   3. $((A\to B)\to A)\to A$ (Peirce's law)
   #+END_exercise
   #+BEGIN_proof
   \begin{gather*}
   \EBA\AXC{$(\neg A\wedge\neg B)\to\bot^u$}
   \AXC{$(\neg(A\vee B))^v$}
   \noLine\UIC{$\cald$}\noLine
   \UIC{$(\neg A\wedge\neg B)$}
   \BIC{$\bot$}
   \UIC{$A\vee B$}\DP
   \end{gather*}
   #+END_proof
   #+BEGIN_exercise
   Construct in $\tonm$ a proof of
   \begin{equation*}
   ((A\to B)\to C)\to(A\to C)\to C
   \end{equation*}
   from two instances of Peirce's law as assumptions: $((A\to B)\to A)\to A$ and 
   $((C\to A)\to C)\to C$
   #+END_exercise

   #+BEGIN_exercise
   Derive in $\tonm$ $P_{A,B\wedge C}$ from $P_{A,B}$ and $P_{A,C}$ where
   $P_{X,Y}$ is $((X\to Y)\to X)\to X$
   #+END_exercise

   #+BEGIN_exercise
   Let $F[*],G[*]$ be a positive and negative context respectively. Prove in
   $\Nm$ that
   \begin{align*}
   &\vdash\forall\overrightarrow{x}(A\to B)\to(F[A]\to F[B])\\
   &\vdash\forall\overrightarrow{x}(A\to B)\to(G[A]\to G[B])\\
   \end{align*}
   where $\overrightarrow{x}$ consists of the variables in $A\to B$ becoming
   bound by substitution of $A$ and $B$ into $F[*]$ in the first line, and into
   $G[*]$ in the second line
   #+END_exercise
*** The Complete Discharge Convention
$wef$
