t#+title: Distributed Algorithms

#+AUTHOR: Nancy Lynch
#+EXPORT_FILE_NAME: ../latex/DistributedAlgorithms/DistributedAlgorithms.tex
#+LATEX_HEADER: \input{/Users/wu/notes/preamble.tex}
#+LATEX_HEADER: \graphicspath{{../../books/}}
#+LATEX_HEADER: \makeindex
#+LATEX_HEADER: \SetKw{KwShared}{Shared variables:}
#+LATEX_HEADER: \SetKw{KwProcess}{Process $i$:\\}
#+LATEX_HEADER: \SetKwData{KwRem}{\ruleline{Remainder region}\\}
#+LATEX_HEADER: \SetKwData{KwCrit}{\ruleline{Critical region}\\}
#+LATEX_HEADER: \SetKwData{KwTry}{\ruleline{Trying region}\\}
#+LATEX_HEADER: \SetKwData{KwExit}{\ruleline{Exit region}\\}
#+LATEX_HEADER: \SetKw{Waitfor}{waitfor}
#+LATEX_HEADER: \def \rem {rem}
#+LATEX_HEADER: \def \setflagi {set\mhyphen flag\mhyphen 1}
#+LATEX_HEADER: \def \setflagii {set\mhyphen flag\mhyphen 2}
#+LATEX_HEADER: \def \setflag {set\mhyphen flag}
#+LATEX_HEADER: \def \testturn {test\mhyphen turn}
#+LATEX_HEADER: \def \testflag {test\mhyphen flag}
#+LATEX_HEADER: \def \checkflag {check\mhyphen flag}
#+LATEX_HEADER: \def \checkturn {check\mhyphen turn}
#+LATEX_HEADER: \def \setturn {set\mhyphen turn}
#+LATEX_HEADER: \def \leavetry {leave\mhyphen try}
#+LATEX_HEADER: \def \leaveexit {leave\mhyphen exit}
#+LATEX_HEADER: \def \Effect {\qw\text{Effect:}}
#+LATEX_HEADER: \def \Precondition {\qw\text{Precondition:}}
#+LATEX_HEADER: \SetKw{KwGoTo}{go to}
#+STARTUP: shrink
* Modelling \rom{2}: Asynchronous System Model
** I/O Automata
        A *signature* \(S\) is a triple consisting of three disjoint sets of actions: the *input actions*,
        \(in(S)\), the *output actions*, \(out(S)\), and the *internal actions*, \(int(S)\). We define the
        *external actions*, \(ext(S)\), to be \(in(S)\cup out(S)\); and *locally controlled actions*, \(local(S)\)
        to be \(out(S)\cup int(S)\); and \(acts(S)\) to be all the actions of \(S\). The *external signature*,
        \(extsig(S)\), is defined to be the signature \((in(S),out(S),\emptyset)\).

        An *I/O automaton* \(A\), which we also call simply an *automaton*, consists of five components:
        * \(sig(A)\), a signature
        * \(states(A)\)
        * \(start(A)\), a nonempty subset of \(states(A)\) known as the *start states* or *initial states*
        * \(trans(A)\), a *state-transition relation* where \(trans(A)\subseteq states(A)\times
          acts(sig(A))\times states(A)\).
        * \(tasks(A)\), a *task partition*, which is an equivalence relation on \(local(sig(A))\) having at most
          countably many equivalence classes

        We use \(acts(A)\) as shorthand for \(acts(sig(A))\), and similarly \(in(A)\), and so on.

        We call an element \((s,\pi,s')\) of \(trans(A)\) a *transition*, or *step*, of \(A\). The transition
        \((s,\pi,s')\) is called  an *input transition*, *output transition*, and so on, based on whether the
        action \(\pi\) is an input action, output action, and so on.

        If for a particular state \(s\) and action \(\pi\), \(A\) has some transition of the form
        \((s,\pi,s')\), then we say that \(\pi\) is *enabled* in \(s\). Since every input action is required to
        be enabled in every state, automata are said to be *input-enabled*. We say that state \(s\) is *quiescent*
        if the only actions that are enabled in s are input actions.

        A task \(C\) is *enabled* in a state \(s\) means somes action in \(C\) is enabled in \(s\).

        #+ATTR_LATEX: :options [Channel I/O automaton]
        #+BEGIN_examplle
        [[label:8.1.1]]
        Consider a communication channel automaton \(C_{i,j}\). Let \(M\) be a fixed message alphabet.
        * *Signature*:
          \begin{alignat*}{2}
          &\text{Input}:\hspace{3cm}&&\text{Output:}\\
          &\quad send(m)_{i,j},m\in M&&\quad receive(m)_{i,j},m\in M
          \end{alignat*}
        * *States*: \(queue\), a FIFO queue of elements of \(M\), initially empty
        * *Transitions*:
          \begin{alignat*}{2}
          &send(m)_{i,j}\hspace{3cm}&&receive(m)_{i,j}\\
          &\quad\text{Effect:}&&\quad\text{Precondition:}\\
          &\quad\quad\text{add }m\text{ to }queue&&\quad\quad m\text{ is first on }queue\\
          &&&\quad\text{Effect:}\\
          &&&\quad\quad\text{remove first element of }queue
          \end{alignat*}
        * *Tasks*: \(\{receive(m)_{i,j}:m\in M\}\)
        #+END_examplle

        #+ATTR_LATEX: :options [Process I/O automata]
        #+BEGIN_examplle
        [[label:8.1.2]]

        Consider a process automaton \(P_i\). \(V\) is a fixed value set, \(null\) is a special value not in \(V\), \(f\) is a fixed function,
        \(f:V^n\to V\)
        * *Signature*:
          * Input:
            * \(init(v)_i,v\in V\)
            * \(receive(v)_{j,i}\), \(v\in V\), \(1\le j\le n\), \(j\neq i\)
          * Output:
            * \(decide(v)_i\), \(v\in V\)
            * \(send(v)_{i,j}\), \(v\in V\), \(1\le j\le n\), \(j\neq i\)
        * *States*: \(val\), a vector indexed by \(\{1,\dots,n\}\) of elements in \(V\cup\{null\}\), all
          initially \(null\)
        * *Transitions*:
          \begin{alignat*}{2}
          &init(v)_i,v\in V\hspace{2cm}&&receive(v)_{j,i},v\in V\\
          &\quad\text{Effect:}&&\quad\text{Effect:}\\
          &\quad\quad val(i):=v&&\quad\quad val(j):=v\\\\
          &send(v)_{i,j}, v\in V&&decide(v)_i,v\in V\\
          &\quad\text{Precondition:}&&\quad\text{Precondition:}\\
          &\quad\quad val(i)=v&&\quad\quad\text{for all }j, 1\le j\le n:\\
          &\quad\text{Effect:}&&\quad\quad\quad val(j)\neq null\\
          &\quad\quad\quad\text{none}&&\quad\quad v=f(val(1),\dots,val(n))\\
          &&&\quad\text{Effect:}\\
          &&&\quad\quad\text{none}
          \end{alignat*}
        * *Tasks*: for every \(j\neq i\): \(\{send(v)_{i,j}:v\in V\}\), \(\{decide(v)_i:v\in V\}\).

        [[index:execution]]
        An *execution fragment* of \(A\) is either a finite sequence \(s_0,\pi_1,s_1,\pi_2,\dots,\pi_r,s_r\) or
        an infinite sequence \(s_0,\pi_1,s_1,\pi_2,\dots\), of alternating states and actions of \(A\) s.t.
        \((s_k,\pi_{k+1},s_{k+1})\) is a transition of \(A\) for every \(k\ge 0\). An execution fragment
        beginning with a start state is called an *execution*. We denote the set of executions of \(A\) by
        \(execs(A)\). A state is *reachable* if it is the final state of a finite execution of \(A\).

        If \(\alpha\) is a finite execution fragment of \(A\) and \(\alpha'\) is any execution fragment of
        \(A\) that begins with the last state of \(\alpha\), then we write \(\alpha\cdot\alpha'\) to represent
        the sequence obtained by concatenating \(\alpha\) and \(\alpha'\), eliminating the duplicate
        occurrence of the last state of \(\alpha\).
        #+END_examplle


        [[index:trace]]
        The *trace* of an execution \(\alpha\) of \(A\), denoted by \(trace(\alpha)\), is the subsequence of
        \(\alpha\) consisting of all the external actions. We say that \(\beta\) is a *trace* of \(A\)  if
        \(\beta\) is the trace of an execution of \(A\). We denote the set of traces of \(A\) by
        \(traces(A)\).

        #+ATTR_LATEX: :options [Executions]
        #+BEGIN_examplle
        [[label:8.1.3]]

        The following are three executions of the automaton \(C_{i,j}\) described in Example ref:8.1.1
        (assuming that the message alphabet \(M\) is equal to the set \(\{1,2\}\)). Here we indicate the
        states by putting the sequences in /queue/ in brackets; \(\lambda\) denotes the empty sequence.

        \begin{align*}
        &[\lambda],send(1)_{i,j},[1],receive(1)_{i,j},[\lambda],send(2)_{i,j},[2],receive(2)_{i,j},[\lambda]\\
        &[\lambda],send(1)_{i,j},[1],receive(1)_{i,j},[\lambda],send(2)_{i,j},[2]\\
        &[\lambda],send(1)_{i,j},[1],send(1)_{i,j},[11],send(1)_{i,j},[111],\dots
        \end{align*}
        #+END_examplle
** Operations on Automata
*** Composition
        The composition identifies actions with the same name in different component automata. When any
        component automaton performs a step involving \(\pi\), so do all component automata that have \(\pi\)
        in their signatures.

        We impose certain restrictions on the automata that may be composed.
        1. Since internal actions of an automaton \(A\) are intended to be unobservable by any other automaton
           \(B\), we do not allow \(A\) to be composed with \(B\) unless the internal actions of A are
           disjoint from the actions of B.

           Otherwise, A's performance of an internal action could force B to take a step.
        2. In order that the composition operation might satisfy nice properties, we establish a convention
           that at most one component automaton "controls" the performance of any given action; that is, we do
           not allow \(A\) and \(B\) to be composed unless the sets of output actions of A and B are disjoint.
        3. We do not preclude the possibility of composing a countably infinite collection of automata, but we
           do require in this case that each action must be an action of only finitely many of the component automata.

        A countable collection \(\{S_i\}_{i\in I}\) of signatures to be *compatible* if for all \(i,j\in I\),
        \(i\neq j\), all of the following hold:
        1. \(int(S_i)\cap acts(S_j)=\emptyset\)
        2. \(out(S_i)\cap out(S_j)=\emptyset\)
        3. No action is contained in infinitely many sets \(acts(S_i)\)
        We say that a collection of automata is *compatible* if their signatures are compatible.

        The *composition* \(S=\prod_{i\in I}S_i\) of a countable compatible collection of signatures
        \(\{S_i\}_{i\in I}\) is defined to be the signature with
        * \(out(S)=\bigcup_{i\in I}out(S_i)\)
        * \(int(S)=\bigcup_{i\in I}int(S_i)\)
        * \(in(S)=\bigcup_{i\in I}in(S_i)-\bigcup_{i\in I}out(S_i)\)

        Now the *composition* \(A=\prod_{i\in I}A_i\) of a countable, compatible collection of I/O automata
        \(\{A_i\}_{i\in I}\) can be defined. It is the automaton defined as:
        * \(sig(A)=\prod_{i\in I}sig(A_i)\)
        * \(states(A)=\prod_{i\in I}states(A_i)\)
        * \(start(A)=\prod_{i\in I}start(A_i)\)
        * \(trans(A)\) is the set of triples \((s,\pi,s')\) s.t., for all \(i\in I\), if \(\pi\in acts(A_i)\),
          then \((s_i,\pi,s_i')\in trans(A_i)\); otherwise \(s_i=s_i'\).
        * \(tasks(A)=\bigcup_{i\in I}tasks(A_i)\)


        Note that an action \(\pi\) that is an output of one component and an input of another is classified
        as an output action in the composition, not as an internal action. This is because we want to permit
        the possibility of further communication using \(\pi\).

        #+ATTR_LATEX: :options [Composition of automata]
        #+BEGIN_examplle
        [[label:8.2.1]]
        Consider a fixed index set \(I=\{1,\dots,n\}\) and let \(A\) be the composition of all the process
        automata \(P_i\), \(i\in I\) from Example [[ref:8.1.2]]. In order to compose them, we must assume that the
        message alphabet \(M\) for the channel automata contains the value set \(V\) for the process automata.
        #+ATTR_LATEX: :width .8\textwidth :float nil
        #+NAME: 8.3
        #+CAPTION: Composition of \(P_i\)s and \(C_{i,j}\)s
        [[../images/DistributedAlgorithms/3.png]]

        1. An \(init(v)_i\) input action, which deposits a value in \(P_i\)'s \(val(i)\) variable, \(val(i)_i\).
        2. A \(send(v)_{i,j}\) output action, by which \(P_i\)'s value \(val(i)_i\) gets put into channel \(C_{i,j}\).
        3. A \(receive(v)_{i,j}\) output action, by which the first message in \(C_{i,j}\) is removed and
           simultaneously placed into \(P_j\)'s variable \(val(i)_j\).
        4. A \(decide(v)_i\) output action, by which \(P_i\) announcs its current computed value.

        #+END_examplle

        Given an execution \(\alpha=s_0,\pi_1,s_1,\dots\), of \(A\), let \(\alpha|A_i\) be the sequence
        obtained by deleting each pair \(pi_r,s_r\) for which \(\pi_r\) is not an action of \(A_i\) and
        replacing each remaining \(s_r\) by \((s_r)_i\).

        #+ATTR_LATEX: :options []
        #+BEGIN_theorem
        [[label:8.1]]
        Let \(\{A_i\}_{i\in I}\) be a compatible collection of automata and let \(A=\prod_{i\in I}A_i\).
        1. If \(\alpha\in execs(A)\), then \(\alpha|A_i\in execs(A_i)\) for every \(i\in I\).
        2. If \(\beta\in traces(A)\), then \(\beta|A_i\in traces(A_i)\) for every \(i\in I\).
        #+END_theorem

        #+BEGIN_proof
        1. Execution of any automaton \(A_j\) where \(j\neq i\) doesn't affect automaton \(A_i\).
        2. Immediately
        #+END_proof

        #+ATTR_LATEX: :options []
        #+BEGIN_theorem
        [[label:8.2]]
        Let \(\{A_i\}_{i\in I}\) be a compatible collection of automata and let \(A=\prod_{i\in I}A_i\).
        Suppose \(\alpha_i\) is an execution of \(A_i\) for every \(i\in I\), and suppose \(\beta\) is a
        sequence of actions in \(ext(A)\) s.t. \(\beta|A_i=traces(\alpha_i)\) for every \(i\in I\). Then there
        is an execution \(\alpha\) of \(A\) s.t. \(\beta=trace(\alpha)\) and \(\alpha_i=\alpha|A_i\) for every
        \(i\in I\).
        #+END_theorem


        #+ATTR_LATEX: :options []
        #+BEGIN_theorem
        [[label:8.3]]
        Let \(\{A_i\}_{i\in I}\)  be a compatible collection of automata and let \(A=\prod_{i\in I}A_i\).
        Suppose \(\beta\) is a sequence of actions in \(ext(A)\). If \(\beta|A_i\in traces(A_i)\) for every
        \(i\in I\), then \(\beta\in traces(A)\).
        #+END_theorem
*** Hiding
        If \(S\) is a signature and \(\Phi\subset out(S)\), then \(hide_\phi(S)\) is defined to be the new
        signature \(S'\), where \(in(S')=in(S)\), \(out(S')=out(S)-\Phi\) and \(int(S')=int(S)\cup\Phi\).

        If \(A\) is an automaton and \(\Phi\subseteq out(A)\), then \(hide_\Phi(A)\) is the automaton \(A'\)
        obtained from \(A\) by replacing \(sig(A)\) with \(sig(A')=hide_\Phi(sig(A))\).
*** Fairness
        [[index:fair]]
        An execution fragment \(\alpha\) of an I/O automaton \(A\) is said to be *fair* if the following
        conditions hold for each class \(C\) of \(tasks(A)\):
        1. If \(\alpha\) is finite, then \(C\) is not enabled in the final state of \(\alpha\)
        2. If \(\alpha\) is infinite, then \(\alpha\) contains either infinitely many events from \(C\) or
           infinitely many occurrences of states in which \(C\) is not enabled.

        We use the term *event* to denote the occurrence of an action in a sequence.

        * We can understand the definition of fairness as saying that infinitely often, each task \(C\) is
          given a turn. Whenever this happens, either an action of \(C\) gets performed or no action from
          \(C\) could possibly be performed since no such action is enabled.
        * We can think of a finite fair execution as an execution at the end of which the automaton
          repeatedly gives turns to all the tasks in round-robin order, but never succeeds in performing any
          action since none are enabled in the final state. <<P1>>

        We denote the set of fair executions of \(A\) by \(fairexecs(A)\). We say that \(\beta\) is a *fair
        trace* of \(A\) if \(\beta\) is the trace of a fair execution of \(A\), and we denote the set of fair
        traces of \(A\) by \(fairtraces(A)\).

        #+ATTR_LATEX: :options [Fairness]
        #+BEGIN_examplle
        In Example [[ref:8.1.3]], the first execution given is fair, because no \(receive\) action is enabled in
        its final state. The second is not fair, because it is finite and a \(receive\) action is enabled in
        the final state. The third is not fair, because it is infinite, contains no \(receive\) events, and
        has \(receive\) actions enabled at every point after the first step.
        #+END_examplle

        #+ATTR_LATEX: :options []
        #+BEGIN_theorem
        [[label:8.4]]
        Let \(\{A_i\}_{i\in I}\) be a compatible collection of automata and let \(A=\prod_{i\in I}A_i\).
        1. If \(\alpha\in fairexecs(A)\), then \(\alpha|A_i\in fairexecs(A_i)\) for every \(i\in I\).
        2. If \(\beta\in fairtraces(A)\), then \(\beta|A_i\in fairtraces(A_i)\) for every \(i\in I\).
        #+END_theorem

        #+BEGIN_proof
        1. If \(\alpha\in fairexecs(A)\).
           * If \(\alpha\) is finite, then for each task \(C\), \(C\) is not enabled in the final state of
             \(\alpha\), therefore each \(C|A_i\) is not enabled in the final state of \(\alpha|A_i\) too.
           * If \(\alpha\) is infinite, then blabla
           Therefore \(\alpha|A_i\in fairexecs(A_i)\)
        2. same
        #+END_proof

        #+ATTR_LATEX: :options []
        #+BEGIN_theorem
        [[label:8.5]]
        Let \(\{A_i\}_{i\in I}\) be a compatible collection of automata and let \(A=\prod_{i\in I}A_i\).
        Suppose \(\alpha_i\) is a fair execution of \(A_i\) for every \(i\in I\), and suppose \(\beta\) is a
        sequence of actions in \(ext(A)\) s.t. \(\beta|A_i=trace(\alpha_i)\) for every \(i\in I\). Then there
        is a fair execution \(\alpha\) of \(A\) s.t. \(\beta=trace(\alpha)\) and \(\alpha_i=\alpha|A_i\) for
        every \(i\in I\).
        #+END_theorem

        #+ATTR_LATEX: :options []
        #+BEGIN_theorem
        [[label:8.6]]
        Let \(\{A_i\}_{i\in I}\) be a compatible collection of automata and let \(A=\prod_{i\in I}A_i\).
        Suppose \(\beta\) is a sequence of actions in \(ext(A)\). If \(\beta|A_i\in fairexecs(A_i)\)  for
        every \(i\in I\), then \(\beta\in fairexecs(A)\).
        #+END_theorem

        #+ATTR_LATEX: :options [Fairness]
        #+BEGIN_examplle
        Consider the fair executions of the system of three processes and three channels in Example ref:8.2.1.
        In every fair execution, every message that is sent is eventually received.

        In every fair execution containing least one \(init_i\) event for each \(i\), each process sends
        infinitely many messages to each other processes and each process performs infinitely many \(decide\) steps

        In every fair execution that does not contain at least one \(init\) event for each process, no process
        ever performs a \(decide\) step.
        #+END_examplle

        #+ATTR_LATEX: :options []
        #+BEGIN_theorem
        Let \(A\) be any I/O automaton.
        1. If \(\alpha\) is a finite execution of \(A\), then there is a fair execution of \(A\) that starts
           with \(\alpha\).
        2. If \(\beta\) is a finite trace of \(A\), then there is a fair trace of \(A\) that starts with \(\beta\).
        3. If \(\alpha\) is a finite execution of \(A\) and \(\beta\) is any sequence of input actions of
           \(A\), then there is a fair execution \(\alpha\cdot\alpha'\) of \(A\) s.t. the sequence of input
           actions in \(\alpha'\) is exactly \(\beta\)
        4. If \(\beta\) is a finite trace of \(A\) and \(\beta'\) is any sequence of input actions of \(A\),
           then there is a fair execution \(\alpha\cdot\alpha'\) of \(A\) s.t. \(trace(\alpha)=\beta\) and
           s.t. the sequence of input actions in \(\alpha'\) is exactly \(\beta'\)
        #+END_theorem
** Inputs and Outputs for Problems
** Properties and Proof Methods
*** Invariant Assertions
*** Trace Properties
        A *trace property* \(P\) consists of the following:
        * \(sig(P)\), a signature containing no internal actions
        * \(traces(P)\), a set of (finite or infinite) sequences of actions in \(acts(sig(P))\)

        That is, a trace property specifies both an external interface and a set (in other words, a property)
        of sequences observed at that interface. We write \(acts(P)\) as shorthand for \(acts(sig(P))\), and
        similarly \(in(P)\), and so on.

        The statement that an I/O automaton \(A\) satisfies a trace property \(P\) can be mean either of two
        different things:
        1. \(extsig(A)=sig(P)\) and \(traces(A)\subseteq traces(P)\)
        2. \(extsig(A)=sig(P)\) and \(fairtraces(A)\subseteq traces(P)\)
        The fact that \(A\) is input-enabled ensures that \(fairtraces(A)\) contains a response by \(A\) to
        each possible sequence of input actions. If \(fairtraces(A)\subseteq traces(P)\), then all of the
        resulting sequences must be included in the property \(P\).

        #+ATTR_LATEX: :options [Automata and trace properties]
        #+BEGIN_examplle
        Consider automata and trace properties with input set \(\{0\}\) and output set \(\{1,2\}\). First
        suppose that \(traces(P)\) is the set of sequences over \(\{0,1,2\}\) that include at least 1. Then
        \(fairtraces(A)\subseteq traces(P)\) means that in every fair execution, \(A\) must output at least
        one.

        It is easy to design an I/O automaton for which this is the case - for example, it can include a task
        whose entire job is to output 1. The fairness condition is used to ensure that this task actually does
        get a change to output 1. On the other hand, there does not exist any automaton \(A\) for which
        \(traces(A)\subseteq traces(P)\), because \(traces(A)\) always includes the empty string \(\lambda\),
        which does not contain a 1.

        Now suppose that \(traces(P)\) is the set of sequences over \(\{0,1,2\}\) that include at least one 0.
        In this case, there is no I/O automaton \(A\) for which \(fairtraces(A)\subseteq traces(P)\), because
        \(fairtraces(A)\) must contain some sequence that includes no inputs.
        #+END_examplle

        A countable collection \(\{P_i\}_{i\in I}\) of trace properties is *compatible* if their signatures are
        compatible. Then the *composition* \(P=\prod_{i\in I}P_i\) is the trace property s.t.
        * \(sig(P)=\prod_{i\in I}sig(P_i)\).
        * \(traces(P)\) is the set of sequences \(\beta\) of external actions of \(P\) s..t
          \(\beta|acts(P_i)\in traces(P_i)\) for all \(i\in I\).
*** Safety and Liveness Properties
        #+ATTR_LATEX: :options []
        #+BEGIN_definition
        A trace property \(P\) is a *trace safety property*, or a *safety property* for short, provided that \(P\)
        satisfies the following conditions:
        1. \(traces(P)\) is nonempty
        2. \(traces(P)\) is *prefix-closed*, that is, if \(\beta\in traces(P)\) and \(\beta'\) is a finite
           prefix of \(\beta\), then \(\beta'\in traces(P)\)
        3. \(traces(P)\) is *limit-closed*, that is, if \(\beta_1,\beta_2,\dots\) is an infinite sequence of
           finite sequences in \(traces(P)\), and for each \(i\), \(\beta_i\) is a prefix of \(\beta_{i+1}\),
           then \(\beta=\bigcup_{i\in\omega}\beta_i\in traces(P)\).
        #+END_definition

        #+ATTR_LATEX: :options [Trace safety property]
        #+BEGIN_examplle
        Suppose \(sig(P)\) consists of inputs \(init(v)\), \(v\in V\) and outputs \(decide(v)\), \(v\in V\).
        Suppose \(traces(P)\) is the set of sequences of \(init\) and \(decide\) actions in which no
        \(decide(v)\) occurs without a preceding \(init(v)\) (for the same \(v\)). Then \(P\) is a safety property.
        #+END_examplle

        #+ATTR_LATEX: :options []
        #+BEGIN_proposition
        If \(P\) is a safe property, TFAE:
        1. \(traces(A)\subseteq traces(P)\)
        2. \(fairtraces(A)\subseteq traces(P)\)
        3. finite traces of \(A\) are all in traces \(P\).
        #+END_proposition

        #+BEGIN_proof
        \((2\Rightarrow(3)\): For any finite trace \(\beta\in traces(A)\), there is
        \(\beta'\in fairtraces(A)\)  that starts in \(\beta\). Thus \(\beta\in traces(P)\) because of
        prefix-closedness.

        \((3)\Rightarrow(1)\): For any infinite trace \(\beta\in traces(A)\), we can have such a infinite
        sequence of traces \(\beta_1,\beta_2,\dots\) of \(A\), where \(\beta_i\) is a prefix of
        \(\beta_{i+1}\) for any \(i\), and \(\beta=\bigcup_{i\in\omega}\beta_i\). Therefore
        \(\beta\in traces(P)\) because of limit-closedness.
        #+END_proof

        #+ATTR_LATEX: :options []
        #+BEGIN_definition
        A trace property \(P\) is a *trace liveness property*, or a *liveness property* for short, provided that
        every finite sequence over \(acts(P)\) has some extension in \(traces(P)\).
        #+END_definition

        #+ATTR_LATEX: :options []
        #+BEGIN_examplle
        Suppose \(sig(P)\) consists of input \(init(v)\), \(v\in V\) and outputs \(decide(v)\), \(v\in V\).
        Suppose \(traces(P)\) is the set of sequences \(\beta\) of \(init\) and \(decide\) actions in which,
        for every \(init\) event in \(\beta\), there is some \(decide\) event occuring later in \(\beta\).
        Then \(P\)  is a liveness property.
        #+END_examplle

        Often one wants to prove that \(fairtraces(A)\subseteq traces(P)\) for some automaton \(A\) and
        liveness property \(P\). Methods based on *temporal logic* work well in practice for proving such
        claims. Another method for proving liveness claims, which we call the *progress function method*, is
        specially designed for proving that some particular goal is eventually reached.

        #+ATTR_LATEX: :options []
        #+BEGIN_theorem
        If \(P\) is both a safety property and a liveness property, then \(P\) is the set of all (finite and
        infinite) sequence of actions in \(acts(P)\).
        #+END_theorem

        #+BEGIN_proof
        Suppose that \(P\) is both a safety and a liveness property and let \(\beta\) be an arbitrary sequence
        of elements of \(acts(P)\). If \(\beta\) is finite, then since \(P\) is a liveness property, \(\beta\)
        has some extension \(\beta'\) in \(traces(P)\). Then since \(P\) is a safety property, \(\beta\in
        traces(P)\).

        If \(\beta\) is infinite, then for each \(i\ge 1\), define \(\beta_i\) to be the length \(i\) prefix
        of \(\beta\). Then \(\beta\in traces(P)\).
        #+END_proof

        #+ATTR_LATEX: :options []
        #+BEGIN_theorem
        If \(P\) is an arbitrary trace property with \(traces(P)\neq\emptyset\), then there exist a safety
        property \(S\) and a liveness property \(L\) s.t.
        1. \(sig(S)=sig(L)=sig(P)\).
        2. \(traces(P)=traces(S)\cap traces(L)\)
        #+END_theorem

        #+BEGIN_proof
        Let \(traces(S)\) be the prefix- and limit-closure of \(traces(P)\). Let
        \begin{align*}
        traces(L)=&traces(P)\\
        &\cup\{\beta:\beta\text{ is a finite sequence and no extension of $\beta$ is in }traces(P)\}
        \end{align*}
        #+BEGIN_claim
        \(L\) is a liveness property
        #+END_claim
        Now \(traces(P)\subseteq traces(S)\cap traces(L)\). If there is \(\beta\in traces(S)\cap
        traces(L)\setminus traces(P)\),
        then \(\beta\) is a finite sequence and no extension of \(\beta\) is in \(traces(P)\). <<P2>>
        #+END_proof
*** Compositional Reasoning
        #+ATTR_LATEX: :options []
        #+BEGIN_theorem
        label:8.10
        Let \(\{A_i\}_{i\in I}\) be a compatible collection of automata and let \(A=\prod_{i\in I}A_i\). Let
        \(\{P_i\}_{i\in I}\) be a (compatible) collection of trace properties and let \(P=\prod_{i\in I}P_i\)
        1. If \(extsig(A_i)=sig(P_i)\) and \(traces(A_i)\subseteq traces(P_i)\) for every \(i\), then
           \(extsig(A)=sig(P)\) and \(traces(A)\subseteq traces(P)\).
        2. If \(extsig(A_i)=sig(P_i)\) and \(fairtraces(A_i)\subseteq traces(P_i)\) for every \(i\), then
           \(extsig(A)=sig(P)\) and \(fairtraces(A)\subseteq traces(P)\).
        #+END_theorem

        #+BEGIN_proof
        1. If \(\beta\in traces(A)\), then by Theorem ref:8.1,
           \(\beta|A_i\in traces(A_i)\subseteq traces(P_i)\) for every \(i\in I\). Then by Theorem ref:8.3,
           \(\beta\in traces(P)\).
        2.
           
        #+END_proof

        #+ATTR_LATEX: :options [Satisfying a product trace property]
        #+BEGIN_examplle
        Consider the composed system of Example ref:8.2.1. Each process automaton \(P_i\) satisfies a trace
        safety property that asserts that any \(decide_i\) event has a preceding \(init_i\) event. Also, each
        channel automaton \(C_{i,j}\)  satisfies a trace safety property that asserts taht the sequence of
        messages in \(receive_{i,j}\) events is a prefix of athe sequence of messages in \(send_{i,j}\)
        events.

        Then it follows from Theorem ref:8.10 that the composed system satisfies the product trace safety
        property. This means that in an trace of the combined system, the following hold:
        1. For every \(i\), any \(decide_i\) event has a preceding \(init_i\) event
        2. For every \(i\) and \(j\), \(i\neq j\), the sequence of messages in \(receive_{i,j}\) events is a
           prefix of the sequence of messages in \(send_{i,j}\) events.
        #+END_examplle

        Second, suppose that we want to show that a particular sequence of actions is a trace of a composed
        system \(A=\prod_{i\in I}A_i\).  Theorem ref:8.3 shows that it is enough to show taht the projection
        of the sequence on each of the system components is a trace of that component. Theorem ref:8.6 implies
        an analogous result for fair traces.

        Third, consider the compositional proof of safety properties. Suppose we want to show that a composed
        system \(A=\prod_{i\in I}A_i\) satisfies a safety property \(P\). One strategy is to show that none of
        the components \(A_i\) is the first to violate \(P\).

        Let \(A\) be an I/O automaton and let \(P\) be a safety property with \(acts(P)\cap int(A)=\emptyset\)
        and \(in(P)\cap out(A)=\emptyset\). We say that \(A\) *preserves* \(P\) if for every finite sequence
        \(\beta\) of actions that does not include any internal actions of \(A\), and every \(\pi\in out(A)\),
        the following holds: If \(\beta|acts(P)\in traces(P)\) and \(\beta\pi|A\in traces(A)\), then
        \(\beta\pi|acts(P)\in traces(P)\). This says that \(A\) is not the first to violate \(P\), as long as
        \(A\)'s environment only provides inputs to \(A\) in such a way that the cumulative behaviour
        satisfies \(P\), then \(A\) will only perform outputs s.t. the cumulative behaviour satisfies \(P\).

        The key fact about preservation of safety properties is that if all the components in a composed
        system preserve a safety property, then so does the entire system. Moreover, if the composed system is
        closed, then it actually satisfies the safety property.

        #+ATTR_LATEX: :options []
        #+BEGIN_theorem
        [[label:8.11]]
        Let \(\{A_i\}_{i\in I}\) be a compatible collection of automata and let \(A=\prod_{i\in I}A_i\). Let
        \(P\) be a safety property with \(acts(P)\cap int(A)=\emptyset\) and \(in(P)\cap out(A)=\emptyset\).
        1. If \(A_i\) preserves \(P\) for every \(i\in I\), then \(A\) preserves \(P\)
        2. If \(A\) is a closed automaton, \(A\) preserves \(P\), and \(acts(P)\subseteq ext(A)\), then
           \(traces(A)|acts(P)\subseteq traces(P)\)
        3. If \(A\) is a closed automaton, \(A\) preserves \(P\), and \(acts(P)=ext(A)\), then
           \(traces(A)\subseteq traces(P)\).
        #+END_theorem
*** Hierarchical Proofs
** Complexity Measures
* Modelling \rom{3}: Asynchronous Shared Memory Model
** Shared Memory Systems
        We mode lthe entire system as one big I/O automaton \(A\).

        As in the synchronous network model, we assume that the processes in the system are indexed by
        \(1,\dots,n\). Suppose that each process \(i\) has an associated set of *states*, \(states_i\), among
        which some are designated as *start states*, \(start_i\). Also suppose that each shared variable \(x\)
        in the system has an associated set of *values*, \(values_x\), among which some are designated as the
        *initial values*, \(initial_x\). Then each state in \(states(A)\) (the set of states of the system
        automaton \(A\)) consists of a state in \(states_i\) for each process \(i\), plus a value in
        \(values_x\) for each shared variable \(x\). Each state in \(start(A)\) consists of a state in
        \(start_i\) for each process \(i\), plus a value in \(initial_x\) for each shared variable \(x\).

        We assume that each action in \(acts(A)\) is associated with one of the processes. In addition, some
        of the internal actions in \(int(A)\) may be associated with a shared variable. The input actions and
        output actions associated with process \(i\) are used for interaction between process \(i\) and the
        outside world; we say they occur on *port* \(i\). The internal actions of process \(i\) that do not have
        an associated shared variable are used for local computation, while the internal actions of \(i\) that
        are associated with shared variable \(x\) are used for performing operations on \(x\).

        The set \(trans(A)\) of transitions has some locality restrictions, which model the process and shared
        variable structure of the system.
        1. Consider an action \(\pi\) that is associated with process \(i\) but with no variable; as we noted
           above, \(\pi\) is used for local computation. Then only the state of \(i\) can be involved in any
           \(\pi\) step. That is, the set of \(\pi\) transitions can be generated from some set of triples of
           the form \((s,\pi,s')\), where \(s,s'\in states_i\), by attaching any combination of states for the
           other processes and values for the shared variables to both \(s\) and \(s'\) 
        2. Consider an action \(\pi\) that is associated with both a process \(i\) and a variable \(x\);
           \(\pi\) is used by \(i\) to perform an operation on \(x\). The set of \(\pi\) transitions can be
           generated from some set of triples of the form \((s,v),\pi,(s',v')\), where \(s,s'\in states_i\)
           and \(v,v'\in values_x\), by attaching any combination of states for the other processes and values
           for the other shared variables. There is a _technicality_: if \(\pi\) is associated with process
           \(i\) and variable \(x\), then whether or not \(\pi\) is enabled should depend only on the state of
           process \(i\)

        The task partitioon \(tasks(A)\) must be consistent with the process structure: that is, each
        equivalence class (task) should include locally controlled actions of only one process.

        #+ATTR_LATEX: :options [Shared memory system]
        #+BEGIN_examplle
        Let \(V\) be a fixed value set. Consider a shared memory system \(A\) consisting of \(n\) processes,
        numbered \(1,\dots,n\), and a single shared variable \(x\) with values in \(V\cup\{unknown\}\),
        initially \(unknown\). The inputs are of the form \(init(v)_i\), where \(v\in V\) and \(i\) is a
        process index. The outputs are of the form \(decide(v)_i\), The internal actions are of the form
        \(access_i\). All the actions with subscript \(i\) are associated with process \(i\), and in addition,
        the \(access\) actions are associated with variable \(x\).

        After process \(i\) receives an \(init(v)_i\) input, it accesses \(x\). If it finds \(x=unknown\),
        then it writes its value \(v\) into \(x\) and decides \(v\). If it finds \(x=w\), where \(w\in V\),
        then it does not write anything into \(x\), but decides \(w\).

        Formally:

        *States of \(i\)*:
        \begin{align*}
        &status\in\{idle,access,decide,done\}, \text{ initially } idle\\
        &input\in V\cup\{unknown\},  \text{ initially } unknown\\
        &output\in V\cup\{unknown\}, \text{ initially } unknown
        \end{align*}
        *Transitions of \(i\)*:
        \begin{alignat*}{2}
        &init(v)_i\hspace{3.5cm}&&decide(v)_i\\
        &\quad\text{Effect:}&&\quad\text{Precondition:}\\
        &\quad\quad input:=v&&\quad\quad status=decide\\
        &\quad\quad\text{if }status=idle\text{ then}&&\quad\quad output=v\\
        &\quad\quad\quad status:=access&&\quad\text{Effect:}\\
        &&&\quad\quad status:=done\\
        &access_i\\
        &\quad\text{Precondition:}\\
        &\quad\quad status=access\\
        &\quad\text{Effect:}\\
        &\quad\quad\text{if }x=unknown\text{ then }x:=input\\
        &\quad\quad output:=x\\
        &\quad\quad status:=decide
        \end{alignat*}

        There is one task per process, which contains all the \(access\) and \(decide\) actions for that
        process.

        It is not hard to see that in every fair execution \(\alpha\) of \(A\), any process that receives an
        \(init\) input eventually performs a \(decide\) output. Moreover, every execution satisfies the
        "agreement property" that no two processes decide on different values, and the "validity property"
        that every decision value is the initial value of some process.
        #+END_examplle
* Mutual Exclusion
** Asynchronous Shared Memory Model
        The system is modelled as a collection of processes and shared variables,
        with interactions. Each process \(i\) is a kind of state machine, with a set statesi of states and a subset \(start\) of \(states_i\) indicating the
        start states, just as in the synchronous setting. However, now process \(i\) also has labelled
        \(actions\), describing the activities in which it participates. These are classified as either
        \(input\), \(output\), or \(internal\) actions. We further distinguish between two different kinds of
        internal actions: those that involve the shared memory and those that involve strictly local
        computation. If an action involves the shared memory, we assumethat it only involves one shared
        variable.

        There is a transition relation \(trans\) for the entire system, which is a set of \((s,\pi,s')\)
        triples, where \(s\) and \(s'\) are *automaton states*, that is, combinations of states for all the
        processes and values for all the shared variables, and where \(\pi\)  is the label of an input,
        output, or internal action. We call these combinations of process states and variable values
        "automaton states" because  the entire system is modelled as a single automaton. The statement that
        \((s,\pi,s')\in trans\) says that from automaton state \(s\) it is possible to go to automaton state
        \(s'\) as a result of performing action \(\pi\).

        We assume that input actions can always happen, that is, that the system is input-enabled. Formally,
        this means that for every automaton state \(s\) and input action \(\pi\), there exists \(s'\) such
        that \((s,\pi,s')\in trans\). In contrast, output and internal steps might be enabled only in a subset
        of the states. The intuition behind the input-enabling property is that the input actions are
        controlled by an arbitrary external user, while the internal and output actions are controlled by the
        system itself.


** The Problem
        The mutual exclusion problem involves the allocation of a single, indivisible, nonshareable resource
        among \(n\) *users*, \(U_1,\dots,U_n\).

        A user with access to the resource is modelled as being in a *critical region*, which is simply a
        designated subset of its states. When a user is not involved in any way with the resource, it is said
        to be in the *remainder region*. In order to gain admittance to its critical region, a user executes a
        *trying protocol*, and after it is done with the resource, it executes an (often trivial) *exit protocol*.
        This procedure can be repeated, so that each user follows a cycle, moving from its
        /remainder region/ (R) to its /trying region/ (T), then to its /critical region/ (C), then to its /exit
        region/ (E), and then back again to its remainder region.  

        #+ATTR_LATEX: :width .2\textwidth :float nil
        #+NAME: 10.2
        #+CAPTION: The cycle of regions of a single user
        [[../images/DistributedAlgorithms/1.png]]

        The inputs to process \(i\) are the \(try_i\) action, which models a request by user \(U_i\) for
        access to the resource, and the \(exit_i\) action, which models an annoucement by user \(U_i\) that it
        is done with the resource. The outputs of process \(i\) are \(crit_i\), which models the granting of
        the resource to \(U_i\) and \(rem_i\), which tells \(U_i\) that it can continue with the reset of its
        work. The \(try\), \(crit\), \(exit\), and \(rem\) actions are the only external actions of the shared
        memory system. The processes are responsible for performing the trying and exit protocols. Each
        process \(i\) acts as an "agent" on behalf of user \(U_i\).

        Each of the users \(U_i\), \(1\le i\le n\), is modelled as a state machine (formally, an *I/O
        automaton*) that communicates with its agent process using the \(try_i\), \(crit_i\), \(exit_i\) and
        \(rem_i\) actions:
        #+ATTR_LATEX: :width .2\textwidth :float nil
        #+NAME: 10.3
        #+CAPTION: External interface of user \(U_i\)
        [[../images/DistributedAlgorithms/2.png]]
        The only thing that we assume about \(U_i\) is that it obeys the cyclic region protocol.
        We define a sequence of \(try_i\), \(crit_i\), \(exit_i\) and \(rem_i\) actions to be *well-formed* for
        user \(i\) if it is a prefix of the cyclically ordered sequence
        \(try_i,crit_i,exit_i,rem_i,try_i,\dots\). Then we require that \(U_i\) *preserve* the *trace property*
        defined by the set of sequences that are well-ordered for user \(i\).

        In executions of \(U_i\) that do observe the cyclic order of actions, we say that \(U_i\) is
        * in its *remainder region* initially and in between any \(rem_i\) event and the following \(try_i\) event
        * in its *trying region* in between \(try_i\) event and the following \(crit_i\) event
        * in its *critical region* in between any \(crit_i\) event and the following \(exit_i\) event. During
          the time, \(U_i\) should be thought of as being free to use the resource
        * in its *exit region* in between any \(exit_i\) event and the following \(rem_i\) event


        #+ATTR_LATEX: :width .9\textwidth :float nil
        #+NAME: 10.4
        #+CAPTION: Interactions between components for the mutual exclusion problem
        [[../images/DistributedAlgorithms/4.png]]

        [[index:Well-formedesness]]
        [[index:Progress]]
        [[index:Mutual exclusion]]
        The combination of \(A\) and the users must satisfy the following conditions:
        * *Well-formedness*: In any execution, and for any \(i\), the subsequence describing the interactions
          between \(U_i\) and \(A\) is well-formed for \(i\).
        * *Mutual exclusion*: There is no reachable system state where more than one user is in the critical
          region \(C\)
        * *Progress*: At any point in a /fair execution/
          1. (Progress for the trying region) If at least one user is in \(T\) and no user is in \(C\), then
             at some later point some user enters \(C\)
          2. (Progress for the exit region) If at least one user is in \(E\), then at some later point some
             user enters \(R\).

        We say that a shared memory system \(A\) *solves the mutual exclusion problem* provided that it solves
        it for every collection of users.


        #+ATTR_LATEX: :options []
        #+BEGIN_lemma
        [[label:10.1]]
        Let \(A\) be an algorithm that solves the mutual exclusion problem. Let \(U_1,\dots,U_n\) be any
        particular collection of users, and let \(B\) be the combination of \(A\) and the given collection of
        users. Let \(s\) be a reachable state of \(B\).

        If process \(i\) is in its trying or exit region in state \(s\), then some locally controlled action
        of process \(i\) is enabled in \(s\).
        #+END_lemma

        #+BEGIN_proof
        WLOG, we may assume that each of the users always returns the resource.

        Let \(\alpha\) be a finite execution of \(B\) ending in \(s\), and assume that process \(i\) is in
        either its trying or exit region in state \(s\), and no locally controlled action of process \(i\) is
        enabled in \(s\). Then we claim that no events involving \(i\) occur in any execution of \(B\) that
        extends \(\alpha\), after the prefix \(\alpha\). This follows from the fact that enabling of locally
        controlled actions is determined only by the local process state, plus the fact that well-formedness
        prevents inputs to process \(i\) while process \(i\) is in \(T\) or \(E\).

        Now let \(\alpha'\) be a fair execution of \(B\) that extends \(\alpha\), in which no \(try\) events
        occur after the prefix \(\alpha\). Repeated use of the progress assumption, plus the fact that the
        users always return the resource, imply that process \(i\) must eventually perform either a \(crit_i\)
        or a \(rem_i\) action. But this contradicts the fact that \(\alpha'\) contains no further actions of \(i\).
        #+END_proof

** Dijkstra's Mutual Exclusion Algorithm
*** The Algorithm
        \begin{algorithm}[H]
        \caption{DijkstraME algorithm}
        \label{DijME}
        \KwShared{\\\quad\(turn\in\{1,\dots,n\}\), initally arbitrary, writable and readable by all processes\\
                for every \(i\), \(1\le i\le n\):\\
                \quad\(flag(i)\in\{0,1,2\}\), initially 0, writable by process \(i\) and readable by all processes}\;
        \KwProcess
        \KwRem
        \(try_i\)\;
        \nlset{L}\label{zzzL}\(flag(i):=1\)\;
        \While{\(turn\neq i\)}{
                \uIf{\(flag(turn)=0\)}{\(turn:=i\)\;}
        }
        \(flag(i):=2\)\;
        \For{\(j\neq i\)}{
                \uIf{\(flag(j)=2\)}{\KwGoTo \ref{zzzL}\;}
        }
        \(crit_i\)\;
        \KwCrit
        \(exit_i\)\;
        \(flag(i):=0\)\;
        \(rem_i\)\;
        \end{algorithm}

        The \(turn\) variable is a \(multi\text{-}writer\)/\(multi\text{-}reader\) register. Each \(flag(i)\) is a
        \(single\text{-}writer\)/\(multi\text{-}reader\) register.


        The state of each process should consist of the values of its local variables plus some other
        information that is not represented explicitly in the code, including
        * temporary variables needed to remember values just read from shared variables
        * a program counter
        * temporary variables introduced by the flow of control of the program
        * a region designation, \(R\), \(T\), \(C\), or \(E\)


        The unique start state of each process should consist of specified initial values for local variables,
        arbitrary values for temporary variables, and the program counter and the region designation
        indicating the remainder region.

        There are some ambiguities in the code that need to be resolved in the automaton.
        1. Although the code describes the changes to the local and shared variables, it does not say
           explicitly what happens to the implicit variables
        2. The code also does not specify exactly which portions of the code comprise indivisible steps.


        #+ATTR_LATEX: :options {\textit{DijkstraME} algorithm (rewritten)}
        #+BEGIN_Block
        *Shared variables*:\\
        \(turn\in\{1,\dots,n\}\), initially arbitrary\\
        for every \(i\), \(1\le i\le n\):\\
        \indent\(flag(i)\in\{0,1,2\}\), initially 0

        \noindent *Actions of \(i\)*:\\
        #+ATTR_LATEX: :mode table :center nil
        | Input:\hspace{3cm} | Internal:                                          |
        | \(​\qw try_i\)     | \(​\qw set\text{-}flag\text{-}1_i\)                |
        | \(\qw exit_i\)     | \(\qw test\mhyphen turn_i\)                        |
        | Output:            | \(\qw test\mhyphen flag(j)_i,1\le j\le n,j\neq i\) |
        | \(\qw crit_i\)     | \(\qw set\mhyphen turn_i\)                         |
        | \(\qw rem_i\)      | \(\qw set\mhyphen flag\mhyphen 2_i\)               |
        |                    | \(\qw check(j)_i,1\le j\le n,j\neq i\)             |
        |                    | \(\qw reset_i\)                                    |


        \noindent *States of \(i\)*:\\
        \(pc\in\{\rem,\setflagi,\testturn,\testflag(j),\setturn,\allowbreak \setflagii,check,\\\leavetry,crit,reset,\leaveexit\}\),
        initially \(rem\).

        \(S\), a set of process indices, initially \(\emptyset\).

        \noindent *Transitions of \(i\)*:

        #+LATEX: \resizebox{0.9\linewidth}{!}{
        \begin{tabular}{l|l}
\(try_i\) & \(\setturn_i\)\\
\qw Effect: & \qw Precondition:\\
\(\qw\qw pc:=\setflagi\) & \(\qw\qw pc=\setturn\)\\
 & \qw Effect:\\
\(\setflagi_1\) & \(\qw\qw turn:=i\)\\
\qw Precondition: & \(\qw\qw pc:=\setflagii\)\\
\(\qw\qw pc=\setflagi\) & \\
\qw Effect: & \(\setflagii_i\)\\
\(\qw\qw flag(i):=1\) & \qw Precondition:\\
\(\qw\qw pc:=\testturn\) & \(\qw\qw pc=\setflagii\)\\
 & \qw Effect:\\
\(\testturn_i\) & \(\qw\qw flag(i):=2\)\\
\qw Precondition: & \(\qw\qw S:=\{i\}\)\\
\(\qw\qw pc=\testturn\) & \(\qw\qw pc:=check\)\\
\qw Effect: & \\
\qw\qw if \(turn=i\) then \(pc:=\setflagii\) & \(check(j)_i\)\\
\qw\qw else \(pc:=\testflag(turn)\) & \qw Precondition:\\
 & \(\qw\qw pc=check\)\\
\(\testflag(j)_i\) & \(\qw\qw j\notin S\)\\
\qw Precondition: & \qw Effect:\\
\(\qw\qw pc=\testflag(j)\) & \qw\qw if \(flag(j)=2\) then\\
\qw Effect: & \(\qw\qw\qw S:=\emptyset\)\\
\qw\qw if \(flag(j)=0\) then \(pc:=\setturn\) & \(\qw\qw\qw pc:=\setflagi\)\\
\qw\qw else \(pc:=\testturn\) & \qw\qw else\\
 & \(\qw\qw\qw S:=S\cup\{j\}\)\\
\(crit_i\) & \qw\qw\qw\qw if \(\abs{S}=n\) then \(pc:=\leavetry\)\\
\qw Precondition: & \\
\(\qw\qw pc=\leavetry\) & \(reset_i\)\\
\qw Effect: & \qw Precondition:\\
\(\qw\qw pc:=crit\) & \qw\qw\(pc=reset\)\\
 & \qw Effect:\\
\(exit_i\) & \qw\qw \(flag(i):=0\)\\
\qw Effect: & \qw\qw \(S:=\emptyset\)\\
\qw\qw\(pc:=reset\) & \qw\qw \(pc:=\leaveexit\)\\
 & \\
 & \(rem_i\)\\
 & \qw Precondition:\\
 & \qw\qw \(pc=\leaveexit\)\\
 & \qw Effect:\\
 & \qw\qw \(pc:=rem\)\\
        \end{tabular}
        #+LATEX: }
        #+END_Block
*** A Correctness Argument
        #+ATTR_LATEX: :options []
        #+BEGIN_lemma
        DijkstraME guarantees well-formedness for each user.
        #+END_lemma

        #+BEGIN_proof
        By inspection of the code, it is easy to check that DijkstraME preserves well-formedness for each
        user. Since, by assumption, the users also preserve well-formedness, Theorem ref:8.11 implies that the
        system produces only well-formed sequences.
        #+END_proof

        #+ATTR_LATEX: :options []
        #+BEGIN_lemma
        [[label:10.3]]
        DijkstraME satisfies mutual exclusion
        #+END_lemma

        #+BEGIN_proof
        By contradiction. Assume that \(U_i\) and \(U_j\), \(i\neq j\), are simultaneouly in region \(C\) in
        some reachable state. Consider the execution that leads to this state. By the code, both \(i\) and
        \(j\) perfrom \(\setflagii\) steps before entering their critical area. Consider the last such step
        for each process and assume, without loss of generality, that \(\setflagii_i\) comes first. Then
        \(flag(i)\) is 2 from that point until \(i\) leaves \(C\), contradicting the fact that \(j\) enters \(C\).

        #+ATTR_LATEX: :width .8\textwidth :float nil
        #+NAME: 105
        #+CAPTION: Order of events in the proof of Lemma \ref{10.3}
        [[../images/DistributedAlgorithms/6.png]]

        #+END_proof

        #+ATTR_LATEX: :options []
        #+BEGIN_lemma
        DijkstraME guarantees progress.
        #+END_lemma

        #+BEGIN_proof
        Progress of exit region is easy.

        We consider the progress condition for the trying region. Suppose for the sake of contradiction that \(\alpha\)
        is a fair execution that reaches a point where there is at least one user in \(T\) and no user in \(C\), and
        suppose that after this point, no user ever enters \(C\).

        Any process in \(E\) keeps taking steps, so after at most two steps, it must reach \(R\). So after
        some point in \(\alpha\), every process must be in \(T\) or \(R\). Second, since there are only
        finitely many processes in the system, after some point in \(\alpha\), no new processes enter \(T\).
        Thus, after some point in \(\alpha\), every process is in \(T\) or \(R\), and no process every again
        changes region. This implies that \(\alpha\) has a suffix \(\alpha_1\) in which there is a fixed
        nonempty set of processes in \(T\), continuing to take steps forever, and no region changes occur.
        Call these processes *contenders*.

        Note that after at most a single step in \(\alpha_1\), each contender \(i\) ensures that
        \(flag(i)\ge1\)  and it remains \(\ge 1\) for the rest of \(\alpha_1\). So we can assume, WLOG, that
        \(flag(i)\ge 1\) for all contenders throughout \(\alpha_1\).

        #+BEGIN_claim
        In \(\alpha_1\), turn eventually acquires a contender's index.
        #+END_claim

        #+BEGIN_proof
        Suppose not, that is, suppose the value of \(turn\) remains equal to the index of a non-contender
        throughout \(\alpha_1\). Consider any contender \(i\).

        If \(pc_i\) reaches \(\testturn\), which is happened since \(i\) fails to enter \(C\), then
        \(\testturn_i\) finds that \(turn\) equal to some \(j\neq i\).
        Then it performs a \(\testturn_i\) and finds \(flag(j)=0\). Process \(i\) therefore performs
        \(\setturn_i\), setting \(turn\) to \(i\).

        #+END_proof
        Once \(turn\) is set to a contender's index, it is always thereafter equal to /some/ contender's index.
        Then any later \(\testturn\) and subsequent \(\testflag\) yield \(flag(turn)\ge 1\). Thus, \(turn\)
        will not changed as a result of these tests. Therefore, eventually \(turn\) stabilizes to a final
        indx. Let \(\alpha_2\) be a suffix of \(\alpha_1\) in which the value of \(turn\) is stablized at some
        contender's index, say \(i\).

        Next, we claim that in \(\alpha_2\), any contender \(j\neq i\) eventually ends up with its program
        counter looping forever between \(\testturn\) and \(\testflag\). So let \(\alpha_3\) be a suffix of
        \(\alpha_2\) where all contenders other than \(i\)  loop forever between \(\testturn\) and
        \(\testflag\). Note that this means that all contenders other than \(i\) have their flag variables equal
        to 1 throughout \(\alpha_3\).

        We conclude the argument by claiming that in \(\alpha_3\), process \(i\) (the one whose index is in
        turn) has nothing to stand in the way of its reaching \(C\).
        #+END_proof

        #+ATTR_LATEX: :options []
        #+BEGIN_theorem
        DijkstraME solves the mutual exclusion problem.
        #+END_theorem
*** An Assertion Proof of the Mutual Exclusion Condition
        #+ATTR_LATEX: :options [another proof of Lemma \ref{10.3}]
        #+BEGIN_proof
        #+BEGIN_assertion
        [[label:10.3.1]]
        In any reachable system state, \(\abs{\{i:pc_i=crit\}}\le 1\)
        #+END_assertion

        #+BEGIN_assertion
        [[label:10.3.2]]
        In any reachable system state, if \(pc_i\in\{\leavetry,crit,reset\}\), then \(\abs{S_i}=n\)
        #+END_assertion

        #+BEGIN_assertion
        [[label:10.3.3]]
        In any reachable system state, there do not exist \(i\) and \(j\), \(i\neq j\), s.t. \(i\in S_j\) and
        \(j\in S_i\).
        #+END_assertion

        If both Assertions ref:10.3.2 and ref:10.3.3 are true, then Assertion ref:10.3.1 follows.

        Assertion ref:10.3.2 is easy.

        #+BEGIN_assertion
        [[label:10.3.4]]
        In any reachable system state, if \(S_i\neq\emptyset\), then \(pc_i\in\{check,\leavetry,crit,reset\}\).
        #+END_assertion

        #+BEGIN_assertion
        [[label:10.3.5]]
        In any reachable system state, if \(pc_i\in\{check,\leavetry,crit,reset\}\), then \(flag(i)=2\)
        #+END_assertion

        Putting these together, we see that:
        #+BEGIN_assertion
        [[label:10.3.6]]
        In any reachable system state, if \(S_i\neq\emptyset\), then \(flag(i)=2\).
        #+END_assertion

        Now we can prove Assertion ref:10.3.3, again by induction on the length of an execution. For the
        inductive step, the only event that could cause a violation is one that adds an element \(j\) to
        \(S_i\) for some \(i\) and \(j\), \(i\neq j\), that is, a \(check(j)_i\). Then it must be that
        \(flag(j)\neq 2\) when this event occurs. But then \(S_j=\emptyset\), so \(i\notin S_j\).
        #+END_proof
*** Running Time
        We impose:
        * an upper bound of \(l\) on the time between successive steps of each process (when these steps are
          enabled);
        * all the precondition-effect code for one action is assumed to comprise a single step.
        * an upper bound of \(c\) on the maximum time that any user spends in the critical region.

        In terms of these assumed bounds, we can deduce upper bounds for the time required for interesting
        activity to occur. 

        #+ATTR_LATEX: :options []
        #+BEGIN_theorem
        [[label:10.7]]
        In DijkstraME, suppose that at a particular time some user is in \(T\) and no user is in \(C\). Then
        within \(O(ln)\), some user enters \(C\)
        #+END_theorem

        #+BEGIN_proof
        Suppose the lemma is false and consider an execution in which, at some point, process \(i\) is in
        \(T\) and no process is in \(C\), and in which no process enters \(C\) for time at  least \(kln\), for
        some particular large constant \(k\).

        First, it is easy to see that the time elapsed from the starting point of the analysis until there is
        no process either in \(C\) or \(E\) is at most \(O(l)\).

        Second, we claim that the additional time until process \(i\) performs a \(\testturn_i\) is at most
        \(O(ln)\).  This is because \(i\) can at worst spend this much time checking flags in the second stage
        before returning to \(\setflagi\).

        Third, we claim that the additional time from when process i does \(\testturn_i\) until the value of
        turn is a contender index is at most \(O(l)\).

        Fourth, after an additional time \(O(l)\), a point is reached at which the value of \(turn\) has
        stablized to the index of some particular contender, say \(j\).

        Fifth, we claim that by an additional time \(O(ln)\), all contenders other than \(j\) will have their
        program counters in \(\testturn, \testflag\).

        Sixth and finally, within an additional time \(O(ln)\), \(j\) must succeed in entering \(C\)

        #+ATTR_LATEX: :width .99\textwidth :float nil
        #+NAME:
        #+CAPTION: Order of events and time bounds in proof of Theorem \ref{10.7}
        [[../images/DistributedAlgorithms/7.png]]
        #+END_proof
** Stronger Conditions for Mutual Exclusion Algorithms
        In order to distinguish these two types of fairness, we will call the fair execution of process steps
        and user automata steps *low-level fairness*, and the fair granting of the resource *high-level fairness*.

        Another not-so-attractive property of Dijkstra's algorithm is that it uses a shared
        /multi-writer/multi-reader/ register (turn). Such a variable is difficult and expensive to implement in
        many kinds of multiprocessor systems (as well as in nearly all message-passing systems). It would be
        better to design algorithms that use only /single-writer/multi-reader/ registers, or even better,
        /single-writer/single-reader/ registers.

        Each of these properties is stated for a particular mutual exclusion algorithm \(A\) composed with a
        particular collection \(U_1,\dots,U_n\) of users.

        *Lockout-freedom*: In any low-level-fair execution, the following hold:
        1. (Lockout-freedom for the trying region) If all users always return the resource, then any user that
           reaches \(T\) eventually enters \(C\).
        2. (Lockout-freedom for the exit region) Any user that reaches \(E\) eventually enters \(R\).

        *Time bound \(b\)*: In any low-level-fair execution with associated times, the following hold:
        1. (Time bound \(b\) for the trying region) If each user always returns the resource within time \(c\)
           of when it is granted, and the time between successive steps of each process in \(T\) or \(E\) is
           at most \(l\), then any user that reaches \(T\) enters \(C\) within time \(b\).
        2. (Time bound \(b\) for the exit region) If the time between successive steps of each process in
           \(T\) or \(E\) is at most \(g\), then any user that reaches \(E\) enters \(R\) within time \(b\).

        *Number of bypasses \(a\)*: Consider any interval of an execution starting when a process \(i\) has
        performed a locally controlled step in \(T\), and throughout which it remains in \(T\). During this
        interval, any other user \(j\), \(j\neq i\), can only enter \(C\) at most \(a\) times.

        #+ATTR_LATEX: :options []
        #+BEGIN_theorem
        Let \(A\) be a mutual exclusion algorithm, let \(U_1,\dots,U_n\) be a collecion of users, and let
        \(B\) be the composition of \(A\) with \(U_1,\dots,U_n\). If \(B\) has any finite bypass round and is
        lockout-free for the exit region, then \(B\) is lockout-free.
        #+END_theorem

        #+BEGIN_proof
        Consider a low-level-fair execution of \(B\) in which all users always return the resource, and
        suppose that at some point in the execution, \(i\) is in \(T\). Assume for the sake of contradiction
        that \(i\) never enters \(C\). Lemma ref:10.1 implies that eventually \(i\) must perform a locally
        controlled action in that trying region, if it has not already done so. Repeated use of the progress
        condition and of the assumption that users always return the resource together imply that infinitely
        many total region changes occur. But then some process other than \(i\) enters \(C\) an infinite
        number of times while \(i\) remains in \(T\), which violates the bypass bound.
        #+END_proof

        #+ATTR_LATEX: :options []
        #+BEGIN_theorem
        Let \(A\) be a mutual exclusion algorithm, let \(U_1,\dots,U_n\) be a collection of users, and let
        \(B\) be the composition of \(A\) with \(U_1,\dots,U_n\). If \(B\) has any time bound \(b\), then
        \(B\) is lockout-free.
        #+END_theorem
** Lockout-Free Mutual Exclusion Algorithms
*** A Two-Process Algorithm.
        If \(i\in\{0,1\}\), we write \(\bari\) to indicate \(1-i\).
        
        #+ATTR_LATEX: :options {\textit{Peterson2P} algorithm}
        #+BEGIN_Block
        *Shared variables*:\\
        \(turn\in\{0,1\}\), initially arbitrary, writable and readable by all processes

        For every \(i\in\{0,1\}\):
        \qw\(flag(i)\in\{0,1\}\), initially 0, writable by \(i\) and readable by \(\bari\)

        *Process \(i\)*:\\
        \begin{algorithm}[H]
        \caption{}
        \KwRem
        \(try_i\)\;
        \(flag(i):=1\)\;
        \(turn:=i\)\;
        wait for \(flag(\bari)=0\) or \(turn\neq i\)\;
        \(crit_i\)
        \KwCrit
        \(exit_i\)\;
        \(flag(i):=0\)\;
        \(rem_i\)\;
        \end{algorithm}
        #+END_Block

        #+ATTR_LATEX: :options {\textit{Peterson2P} algorithm (rewritten)}
        #+BEGIN_Block
        *Shared variables*:\\
        \(turn\in\{0,1\}\), initially arbitrary

        \noindent for every \(i\in\{0,1\}\):\\
        \indent\(flag(i)\in\{0,1\}\), initially 0

        \noindent *Actions of \(i\)*:\\
        \begin{tabular}{l|l}
        Input:&Internal:\\
        \qw\(try_i\)&\qw\(\setflag_i\)\\
        \qw\(exit_i\)&\qw\(\setturn_i\)\\
        Output:&\qw\(\checkflag_i\)\\
        \qw\(crit_i\)&\qw\(\checkturn_i\)\\
        \qw\(rem_i\)&\qw\(reset_i\)
        \end{tabular}

        \noindent *States of \(i\)*:\\
        \(pc\in\{rem,\setflag,\setturn,\checkflag,\checkturn,\leavetry,crit,reset,\\\leaveexit\}\), initially
        \(rem\)

        \noindent *Transitions of \(i\)*:\\

        \begin{center}\begin{tikzpicture}[scale=0.6,transform shape,
        every node/.style={rectangle,draw,rounded corners,drop shadow,fill=blue!5},
        arr/.style = {-{Stealth[length=1mm, width=1mm]},shorten >=1pt,rounded corners=10pt},]
        \node (try)
        {$\begin{aligned}
        &try_i\\
        &\qw\text{Effect:}\\
        &\qw\qw pc:=\setflag
        \end{aligned}$};
        \node (setflag) [below=of try]
        {$\begin{aligned}
        &\setflag_i\\
        &\qw\text{Precondition}:\\
        &\qw\qw pc=\setflag\\
        &\qw\text{Effect}:\\
        &\qw\qw flag(i):=1\\
        &\qw\qw pc:=\setturn
         \end{aligned}$};
        \node (setturn) [below=of setflag]
        {$\begin{aligned}
        &\setturn_i\\
        &\qw\text{Precondition:}\\
        &\qw\qw pc=\setturn\\
        &\qw\text{Effect:}\\
        &\qw\qw turn:=i\\
        &\qw\qw pc:=\checkflag
         \end{aligned}$};
        \node (checkflag) [below=of setturn]
        {$\begin{aligned}
        &\checkflag_i\\
        &\qw\text{Precondition:}\\
        &\qw\qw pc=\checkflag\\
        &\qw\text{Effect:}\\
        &\qw\qw \text{ if }flag(\bari)=0\text{ then}\\
        &\qw\qw\qw pc:=\leavetry\\
        &\qw\qw\text{else}\\
        &\qw\qw\qw pc:=\checkturn
         \end{aligned}$};
        \node (crit) [below=of checkflag]
        {$\begin{aligned}
        &crit_i\\
        &\qw\text{Precondition:}\\
        &\qw\qw pc=\leavetry\\
        &\qw\text{Effect:}\\
        &\qw\qw pc:=crit
         \end{aligned}$};
        \node[right=of checkflag] (checkturn)
        {$\begin{aligned}
        &\checkturn_i\\
        &\qw\text{Precondition:}\\
        &\qw\qw pc=\checkturn\\
        &\qw\text{Effect:}\\
        &\qw\qw\text{ if }turn\neq i\text{ then}\\
        &\qw\qw\qw pc:=\leavetry\\
        &\qw\qw\text{else}\\
        &\qw\qw\qw pc:=\checkflag
         \end{aligned}$};
        \node[right =5cm of try] (exit)
        {$\begin{aligned}
        &exit_i\\
        &\qw\text{Effect:}\\
        &\qw\qw pc:=reset\\
         \end{aligned}$};
        \node[below=of exit] (reset)
        {$\begin{aligned}
        &reset_i\\
        &\Precondition\\
        &\qw\qw pc=reset\\
        &\Effect\\
        &\qw\qw flag(i):=0\\
        &\qw\qw pc:=\leaveexit
         \end{aligned}$};
        \node[below=of reset] (rem)
        {$\begin{aligned}
        &rem_i\\
        &\Precondition\\
        &\qw\qw pc=\leaveexit\\
        &\Effect\\
        &\qw\qw pc:=rem
         \end{aligned}$};
        \path[->,arr] (try) edge (setflag)
                                 (setflag) edge (setturn)
                                 (setturn) edge (checkflag)
                                 (checkflag) edge (crit)
                                (checkflag)  edge (checkturn)
                                 (exit) edge (reset)
                                 (reset) edge (rem)
                                (checkturn) edge (checkflag)
                                (checkturn.south) edge (crit.east);
        \end{tikzpicture}\end{center}
        #+END_Block

        #+ATTR_LATEX: :options []
        #+BEGIN_lemma
        Peterson2P satisfies mutual exclusion
        #+END_lemma

        #+BEGIN_proof
        #+BEGIN_assertion
        In any reachable system state, if \(flag(i)=0\), then \(pc_i\in\{\leaveexit,rem,\setflag\}\)
        #+END_assertion

        #+BEGIN_assertion
        [[label:10.5.2]]
        In any reachable system state, if \(pc_i\in\{\leavetry,crit,reset\}\), and
        \(pc_{\bari}\in\{\checkflag,\checkturn,\leavetry,crit,reset\}\), then \(turn\neq i\).
        #+END_assertion
        That is, if \(i\) has won the competition, and if \(\bari\) is a competitor, then the \(turn\)
        variable is set favorably for \(i\).

        Suppose both \(i\) and \(\bari\) are in \(C\), then Assertion ref:10.5.2, applied twice for \(i\) and
        \(\bari\), implies that both \(turn\neq i\) and \(turn\neq\bari\).
        #+END_proof

        #+ATTR_LATEX: :options []
        #+BEGIN_lemma
        Peterson2P guarantees progress.
        #+END_lemma

        #+BEGIN_proof
        Suppose \(\alpha\) is a low-level-fair execution that reaches a point where at least one of the
        processes, say \(i\), is in \(T\) and neither process is in \(C\), and suppose that after this point,
        neither process ever enters \(C\).
        1. If \(\bari\) is in \(T\) sometime after the given point in \(\alpha\), then both processes must get
           stuck in their \(check\) loops, which is impossible
        2. If \(\bari\) is never in \(T\) after the given point in \(\alpha\), we can show that
           \(flag(\bari)\) eventually becomes and stays equal to 0.
        #+END_proof

        #+ATTR_LATEX: :options []
        #+BEGIN_lemma
        Peterson2P is lockout-free
        #+END_lemma

        #+BEGIN_proof
        Consider the lockout-freedom for trying region.

        Suppose the contrary, that is, that at some point in execution \(\alpha\), process \(i\) is in \(T\)
        after having performed \(\setflag_i\), and thereafter, while \(i\) remains in \(T\), process \(\bari\)
        enters \(C\) three times.

        Note that in each of the second and third times, it must be that \(\bari\) first sets \(turn:=\bari\)
        and then sees \(turn=i\); it cannot see \(flag(i)=0\). This means that there are at least two
        occurrences of \(\setturn_i\) after the given point in \(\alpha\). But \(\setturn_i\) is only
        performed once.
        #+END_proof

        Let \(l\) and \(c\) be upper bounds on process step time and critical section time, respectively.

        #+ATTR_LATEX: :options []
        #+BEGIN_theorem
        In Peterson2P, the time from when a particular process \(i\) enters \(T\) until it enters \(C\) is
        most \(c+O(l)\).
        #+END_theorem
*** An \texorpdfstring{\(n\)}{n}-Process Algorithm
        For \(n\) processes, we can use the idea of the /Peterson2P/ algorithm iteratively, in a series of
        \(n-1\) competitions at levels \(1,2,\dots,n-1\). At each successive competition, the algorithm
        ensures that there is at least one *loser*. Thus, all \(n\) processes may compete in the level 1
        competition, but at most \(n-1\) processes can win.

        #+ATTR_LATEX: :options {}
        #+BEGIN_Block
        \noindent *Shared variables*:\\
        \noindent for every \(k\in\{1,\dots,n-1\}\):
        \indent\(turn(k)\in\{1,\dots,k\}\), initially arbitrary
        \noindent for every \(i\), \(1\le i\le n\):
        \indent\(flag(i)\in\{0,\dots,n-1\}\), initially 0

        \noindent *Process \(i\)*:\\
        \begin{algorithm}[H]
        \caption{}
        \KwRem
        \(try_i\)\;
        \For{\(k\in\{1,\dots,n-1\}\)}{
                \(flag(i):=k\)\;
                \(turn(k):=i\)\\
                wait for \([\forall j\neq i:flag(j)<k]\) or \([turn(k)\neq i]\)\;
        }
        \KwCrit
        \(exit_i\)\;
        \(flag(i):=0\)\;
        \(rem_i\)\;
        \end{algorithm}
        #+END_Block

        Ambiguities:
        * one of the conditions in the waitfor statement involves the flag variables for all the other processes.
        * we need to specify some conditions on the order in which process i checks the various \(flag\) variables and the \(turn(k)\) variable,

        #+ATTR_LATEX: :options {}
        #+BEGIN_Block
        \noindent *Shared variables*:\\
        \noindent for every \(k\in\{1,\dots,n-1\}\):
        \indent\(turn(k)\in\{1,\dots,k\}\), initially arbitrary
        \noindent for every \(i\), \(1\le i\le n\):
        \indent\(flag(i)\in\{0,\dots,n-1\}\), initially 0

        \noindent *Actions of \(i\)*:\\
        \begin{tabular}{ll}
        Input:&Internal:\\
        \qw\(try_i\)&\qw\(\setflag_i\)\\
        \qw\(exit_i\)&\qw\(\setturn_i\)\\
        Output:&\qw\(\checkflag(j)_i\), \(1\le j\le n\), \(j\neq i\)\\
        \qw\(crit_i\)&\qw\(\checkturn_i\)\\
        \qw\(rem_i\)&\qw\(reset_i\)
        \end{tabular}

        \noindent *States of \(i\)*:\\
        \(pc\in\{rem,\setflag,\setturn,\checkflag,\checkturn,\leavetry,crit,reset,\leaveexit\}\), initially
        \(rem\)\\
        \(level\in\{1,\dots,n-1\}\), initially 1\\
        \(S\), a set of process indices, initially \(\emptyset\)

        \noindent *Transitions of \(i\)*:\\
        \begin{center}\begin{tikzpicture}[scale=0.6,transform shape,
                every node/.style={rectangle,draw,rounded corners,drop shadow,fill=blue!5},
                arr/.style = {-{Stealth[length=1mm, width=1mm]},shorten >=1pt,rounded corners=10pt},]
        \node (try)
        {$\begin{aligned}
        &try_i\\
        &\Effect\\
        &\qw\qw pc:=\setflag
         \end{aligned}$};
        \node[below=of try] (setflag)
        {$\begin{aligned}
        &\setflag_i\\
        &\Precondition\\
        &\qw\qw pc=\setflag\\
        &\Effect\\
        &\qw\qw flag(i):=level\\
        &\qw\qw pc:=\setturn
         \end{aligned}$};
        \node[below=of setflag] (setturn)
        {$\begin{aligned}
        &\setturn_i\\
        &\Precondition\\
        &\qw\qw pc=\setturn\\
        &\Effect\\
        &\qw\qw turn(level):=i\\
        &\qw\qw S:=\{i\}\\
        &\qw\qw pc:=\checkflag
         \end{aligned}$};
        \node[below=of setturn] (checkflag)
        {$\begin{aligned}
        &\checkflag_i\\
        &\Precondition\\
        &\qw\qw pc=\checkflag\\
        &\qw\qw j\notin S\\
        &\Effect\\
        &\qw\qw \text{if }flag(j)<level\text{ then}\\
        &\qw\qw\qw S:=S\cup\{j\}\\
        &\qw\qw\qw \text{if }\abs{S}=n\text{ then}\\
        &\qw\qw\qw\qw S:=\emptyset\\
        &\qw\qw\qw\qw \text{if }level<n-1\text{ then}\\
        &\qw\qw\qw\qw\qw level:=level+1\\
        &\qw\qw\qw\qw\qw pc:=\setflag\\
        &\qw\qw\qw\qw \text{else}\\
        &\qw\qw\qw\qw\qw pc:=\leavetry\\
        &\qw\qw\text{else}\\
        &\qw\qw\qw S:=\emptyset\\
        &\qw\qw\qw pc:=\checkturn
         \end{aligned}$};
        \node[right=of checkflag] (checkturn)
        {$\begin{aligned}
        &\checkturn_i\\
        &\Precondition\\
        &\qw\qw pc=\checkturn\\
        &\Effect\\
        &\qw\qw\text{if }turn(level)\neq i\text{ then}\\
        &\qw\qw\qw\text{if }level<n-1\text{ then}\\
        &\qw\qw\qw\qw level:=level+1\\
        &\qw\qw\qw\qw pc:=\setflag\\
        &\qw\qw\qw\text{else}\\
        &\qw\qw\qw\qw pc:=\leavetry\\
        &\qw\qw\text{else}\\
        &\qw\qw\qw S:=\{i\}\\
        &\qw\qw\qw pc:=\checkflag
         \end{aligned}$};
        \node[below=of checkflag] (crit)
        {$\begin{aligned}
        &crit_i\\
        &\Precondition\\
        &\qw\qw pc=\leavetry\\
        &\Effect\\
        &\qw\qw pc:=crit
         \end{aligned}$};
        \draw[->,arr]
        (try) edge (setflag)
        (setflag) edge (setturn)
        (setturn) edge (checkflag)
        (checkflag) edge (checkturn) edge (crit);
        \node[right=9cm of try] (exit)
        {$\begin{aligned}
        &exit_i\\
        &\Effect\\
        &\qw\qw pc=reset
         \end{aligned}$};
        \node[below=of exit] (reset)
        {$\begin{aligned}
        &reset_i\\
        &\Precondition\\
        &\qw\qw pc=reset\\
        &\Effect\\
        &\qw\qw flag(i):=0\\
        &\qw\qw level:=1\\
        &\qw\qw pc:=\leaveexit
         \end{aligned}$};
        \node[below=of reset] (rem)
        {$\begin{aligned}
        &rem_i\\
        &\Precondition\\
        &\qw\qw pc=\leaveexit\\
        &\Effect\\
        &\qw\qw pc:=rem
         \end{aligned}$};
        \draw[->,arr] (exit) edge (reset) (reset) edge (rem);
        \draw[->,arr]
        (checkturn) |- (crit);
        \draw[->,arr] (checkturn) |- (setflag);
        \draw[->,arr] (checkturn) -- (checkflag);
        \draw[->,arr] (checkflag.west) -| ++(-15mm,10mm) |- (setflag);
        %\draw[->,arr] (checkflag) -|- (setflag);
        \end{tikzpicture}\end{center}
        #+END_Block

        In any system state of /PetersonNP/, we say that a process \(i\) is a *winner* at level \(k\) provided
        that either \(level_i>k\) or else \(level_i=k\) and \(pc_i\in\{\leavetry,crit,reset\}\). (The latter
        condition only arise for \(k=n-1\).) We also say that process \(i\) is a *competitor* at level \(k\),
        provided that it is either a winner at level \(k\) or else \(level_i=k\) and
        \(pc_i\in\{\checkflag,\checkturn\}\).


        #+ATTR_LATEX: :options []
        #+BEGIN_lemma
        PetersonNP satisfies mutual exclusion.
        #+END_lemma

        #+BEGIN_proof
        #+BEGIN_assertion
        [[label:10.5.3]]
        In any reachable system state of PetersonNP, the following are true:
        1. If process \(i\) is a competitor at level \(k\), if \(pc_i=\checkflag\), and if any process
           \(j\neq i\) in \(S_i\) is a competitor at level \(k\), then \(turn(k)\neq i\)
        2. If process \(i\) is a winner at level \(k\), and if any other process is a competitor at level
           \(k\), then \(turn(k)\neq i\).
        #+END_assertion

        \begin{proof}
        \begin{enumerate}
        \item If \(j\) is a winner, \(j\notin S\). So \(level_j=k\) and \(pc_j\in\{\checkflag,\checkturn\}\). But \(j\in S\) implies
        that \(i\) first set \(S\) to \(S\cup\{j\}\) and then \(j\) set its flag. So \(turn(k)\neq i\).
        \item Suppose \(turn(k)=i\), then we have \(\setflag_j\to\setturn_j\to\setturn_i\). But then as \(turn(k)=i\), \(i\) won't become a winner.
        \end{enumerate}
        \end{proof}
        #+BEGIN_assertion
        [[label:10.5.4]]
        In any reachable system state of PetersonNP, if there is a competitor at level \(k\), then the value
        of \(turn(k)\) is the index of some competitor at level \(k\).
        #+END_assertion

        #+BEGIN_assertion
        [[label:10.5.5]]
        In any reachable system state of PetersonNP, and for any \(k\), \(1\le k\le n-1\), there are at most
        \(n-k\) winners at level \(k\).
        #+END_assertion

        Induction on the value of \(k\).\\
        /Basis/: \(k=1\). If all \(n\) processes are winners at level 1. Then Assertion ref:10.5.3 implies a
        contradiction.

        /Inductive step/: We assume the statement for \(k\), \(1\le k\le n-2\), and show it for \(k+1\). Suppose
        for the sake of contradiction that the statement is false for \(k+1\), that is, that there are
        strictly more than \(n-(k+1)\) winners at level \(k+1\); let \(W\) be the set of such winners. Every
        winner at level \(k+1\) is also a winner at level \(k\), and by IH, the number of winners at level
        \(k\) is at most \(n-k\). It follows that \(W\) is also the set of winners at level \(k\), and that
        \(\abs{W}=n-k\ge 2\).

        Then Assertion ref:10.5.3 implies that the value of \(turn(k+1)\) cannot be the index of any of the
        processes in \(W\). And Assertion ref:10.5.4 implies that the value of \(turn(k+1)\) is the index of
        some competitor at level \(k+1\). But every competitor at level \(k+1\) is a winner at level \(k\),
        and so is in \(W\). This is a contradiction.
        #+END_proof

        #+ATTR_LATEX: :options []
        #+BEGIN_theorem
        In PetersonNP, the time from when a particular process \(i\) enters \(T\) until it enters \(C\) is at
        most \(2^{n-1}c+O(2^nnl)\).
        #+END_theorem

        #+BEGIN_proof
        We prove the bound using a recurrence. Define \(T(0)\) to be the maximum time from when a process
        enters \(T\) until it enters \(C\). For \(k\), \(1\le k\le n-1\), define \(T(k)\) to be the maximum
        time from when a process becomes a winner at level \(k\) until it enters \(C\). We want to bound
        \(T(0)\).

        By the code, we know that \(T(n-1)\le l\).

        Suppose process \(i\) has just won at level \(k\) if \(k\ge 1\), or has just entered \(T\) if \(k=0\).
        Then within time \(2l\), process \(i\) performs \(\setturn_i\), setting \(turn(k+1):=i\). Let \(\pi\)
        denote this \(\setturn_i\) event. We consider two cases.

        First, if \(turn(k+1)\) gets set to some value other than \(i\) within time \(T(k+1)+c+(2n+2)l\)
        (previous winner needs such time to enter \(C\)) after
        \(\pi\), then \(i\) wins at level \(k+1\) within an additional time \(nl\). Then within additional
        time \(T(k+1)\), \(i\) enters \(C\). In this case, the total time from \(\pi\) until \(i\)'s entrance
        to \(C\) is at most \(2T(k+1)+c+(3n+2)l\).

        On the other hand, assume that \(turn(k+1)\) does not get set to any value other than \(i\) within
        time \(T(k+1)+c+(2n+2)l\) after \(\pi\). Then no process can set its \(flag\) to \(k+1\) within time
        \(T(k+1)+c+(2n+1)l\) after \(\pi\). Let \(I\) be the set of processes \(j\neq i\) for which
        \(flag(j)\ge k+1\) when \(\pi\) occurs. Then each process in \(I\) wins at level \(k+1\) within time
        at most \(nl\) after \(\pi\) since it finds \(turn(k+1)=i\), then enters \(C\) within an additional
        time \(T(k+1)\), then leaves \(C\) within additional time \(c\) and performs \(reset\) within
        additional time \(l\). That is, within time \(nl+T(k+1)+c+l=T(k+1)+c+(n+1)l\) after \(\pi\), all
        processes in \(I\) set their \(flags\) to 0.

        For an additional time \(nl\) after that, no process sets its \(flag\) to \(k+1\). That is sufficient
        time for proces \(i\) to detect that all the \(flag\) variables are less than \(k+1\) and so to win at
        level \(k+1\). That is, in this case, process \(i\) wins at level \(k+1\) within time
        \(T(k+1)+c+(2n+1)l\) after \(\pi\). Within another \(T(k+1)\), \(i\) enters \(C\).

        Thus
        \begin{align*}
        T(k)&\le 2T(k+1)+c+(3n+4)l,0\le k\le n-2\\
        T(n-1)&\le l
        \end{align*}
        #+END_proof
*** Tournament Algorithm
        Assume \(n\), the number of progresses, is a power of 2. Each process engages in a series of
        \(\log n\) competitions in order to obtain the resource.

        For \(0\le i\le n-1\) and \(1\le k\le\log n\), define
        * \(comp(i,k)\), the *level \(k\) competition* of process \(i\), is the string consisting of the
          high-order \(\log n-k\) bits of the binary representation of \(i\).
        * \(role(i,k)\), the *role* of process \(i\) in the level \(k\) competition of process \(i\), is the
          \(\log n-k+1\)st bit of the binary representation of \(i\). In terms of the tournament tree,
          \(role(i,k)\) indicates whether \(i\)'s leaf is a descendant of the left of right child of the node
          for competition \(comp(i,k)\).
        * \(opponents(i,k)\), the *opponents* of process \(i\) in the level \(k\) competition of process \(i\),
          is the set of process indices with the same high-order \(\log n-k\) bits as \(i\) and the opposite
          \((\log n-k+1)\)st bit. In terms of the tournament tree, the processes in \(opponents(i,k)\) are
          those whose leaves are descendants of the opposite child of node \(comp(i,k)\)

        #+ATTR_LATEX: :options []
        #+BEGIN_examplle
        Figure ref:fig:10.9 shows the tournament tree for \(n=8\). \(comp(5,2)=1\), \(role(5,2)=0\) and \(opponents(5,2)=\{6,7\}\).
        #+END_examplle

        \begin{figure}[H]
        \label{fig:10.9}
        \begin{center}\begin{forest}
        for tree={align=center},
        before drawing tree={
                tikz+={\coordinate (a) at (current bounding box.east);},
                for nodewalk={fake=r, L, ancestors}{
                        tikz+/.process={Ow+Pw}{level}{int(3-#1)}{\node [anchor=base west] at (.base -| a) {Level #1};}
                }
        }
        [\(\lambda\),
                [0
                        [00
                                [{0\\(000)}]
                                [{1\\(001)}]]
                        [01
                                [{2\\(010)}]
                                [{3\\ (011)}]]]
                [1
                        [10
                                [{4\\ (100)}]
                                [{5\\ (101)}]]
                        [11
                                [{6\\ (110)}]
                                [{7\\ (111)}]]]]
        \end{forest}\end{center}
        \caption{Names of competitions in the \textit{Tournament} algorithm}
        \end{figure}

        We call the algorithm the *Tournament algorithm*.

        #+ATTR_LATEX: :options {\textit{Tournament} algorithm}
        #+BEGIN_Block
        \noindent *Shared variables*:\\
        \noindent for every binary string \(x\) of length at most \(\log n-1\):
        \indent \(turn(x)\in\{0,1\}\), initially arbitrary, writable and readable by exactly those processes
        \(i\) for which \(x\) is a prefix of the binary representation of \(i\).

        \noindent for every \(i\), \(0\le i\le n-1\):
        \indent \(flag(i)\in\{0,\dots,\log n\}\), initially 0, writable by \(i\) and readable by all \(j\neq
        i\).

        \noindent *Process \(i\)*:\\
        \begin{algorithm}[H]
        \KwRem
        \(try_i\)\;
        \For{\(k=1,\dots,\log n\)}{
                \(flag(i):=k\)\;
                \(turn(comp(i,k)):=role(i,k)\)\;
                wait for \([\forall j\in opponents(i,k):flag(j)<k]\) or \([turn(comp(i,k))\neq role(i,k)]\)\;
        }
        \(crit_i\)\;
        \KwCrit
        \(exit_i\)\;
        \(flag(i):=0\)\;
        \(rem_i\)\;
        \end{algorithm}
        #+END_Block

        #+ATTR_LATEX: :options []
        #+BEGIN_lemma
        The Tournament algorithm satisfies mutual exclusion
        #+END_lemma

        #+BEGIN_proof
        #+BEGIN_assertion
        [[label:10.5.6]]
        In any reachable system state of the Tournament algorithm, and for any \(k\), \(1\le k\le\log n\), at
        most one process from any subtree rooted at level \(k\) is a winner at level \(k\).
        #+END_assertion

        #+BEGIN_assertion
        [[label:10.5.7]]
        If process \(i\) is a winner at level \(k\) and if any level-\(k\) opponent of \(i\) is a competitor
        at level \(k\), then \(turn(comp(i,k))\neq role(i,k)\).
        #+END_assertion

        Similar to ref:10.5.3

        #+END_proof

        #+ATTR_LATEX: :options []
        #+BEGIN_theorem
        In the Tournament algorithm, the time from when a particular process \(i\) enters \(T\) until it
        enters \(C\) is at most \((n-1)c+O(n^2l)\).
        #+END_theorem

        #+ATTR_LATEX: :options []
        #+BEGIN_theorem
        The Tournament algorithm solves the mutual exclusion problem and is lockout-free.
        #+END_theorem
** An Algorithm Using Single-Writer Shared Registers
        #+ATTR_LATEX: :options {\textit{BurnsME} algorithm}
        #+BEGIN_Block
        \noindent *Shared variables*:\\
        \noindent for every \(i\), \(1\le i\le n\):\\
        \indent \(flag(i)\in\{0,1\}\), initially 0, writable by \(i\) and readable by all \(j\neq i\)

        \noindent *Process \(i\)*:\\
        \begin{algorithm}[H]
        \KwRem
        \(try_i\)\;
        \nlset{L}\label{LLL}\(flag(i):=0\)\;
        \For{\(1\le j\le i-1\)}{
                \uIf{\(flag(j)=1\)}{\KwGoTo \ref{LLL}}
        }
        \(flag(i):=1\)\;
        \For{\(1\le j\le i-1\)}{
                \uIf{\(flag(j)=1\)}{\KwGoTo \ref{LLL}}
        }
        \nlset{M}\label{MMM}
        \For{\(i+1\le j\le n\)}{
                \uIf{\(flag(i)=1\)}{\KwGoTo \ref{MMM}}
        }
        \(crit_i\)\;
        \KwCrit
        \(exit_i\)\;
        \(flag(i):=0\)\;
        \(rem_i\)\;
        \end{algorithm}
        #+END_Block

        #+ATTR_LATEX: :options []
        #+BEGIN_lemma
        The /BurnsME/ algorithm satisfies mutual exclusion.
        #+END_lemma

        #+BEGIN_proof
        If process \(i\) and \(j\) are simultaneously in \(C\), then assume that \(i\) sets its \(flag\) to 1
        first. 
        #+END_proof

        #+ATTR_LATEX: :options []
        #+BEGIN_lemma
        /BurnsME/ guarantees progress.
        #+END_lemma

        #+BEGIN_proof
        For the trying region, assume that \(\alpha\) is a low-level-fair execution that reaches a point where
        there is at least one process in \(T\) and no process in \(C\), and that after this point, no process
        ever enters \(C\). W.L.O.G., we can assume that every process is in \(T\) or \(R\) and that no process
        changes region, in \(\alpha\). Let the *contenders* be the processes in \(T\).

        Now we partition the contenders into two sets: those that ever reach label \(M\) and those that never
        do. Call the first set \(P\) and the second set \(Q\). There must be some point in \(\alpha\) by which
        all the processes in \(P\) have already reached label \(M\); note that they never thereafter drop
        back to any point in the code prior to label \(M\). Let \(\alpha_1\) be a suffix of \(\alpha\) in
        which all processes in \(P\) are in the final for loop, after label \(M\).

        We claim that there is at least one process in \(P\). Specifically, the process with the smallest
        index among all the contenders is not blocked from reaching label \(M\).

        Let \(i\) be the largest index of a process in \(P\). We claim that eventually in \(\alpha_1\), any
        process \(j\in Q\) s.t. \(j>i\) has \(flag(j)\) set permanently to 0. So let \(\alpha_2\) be a suffix
        of \(\alpha_1\) in which all processes in \(Q\) with indices \(>i\) always have their \(flags\) equal
        to 0.

        Now in \(\alpha_2\), there is nothing to stop process \(i\) from reaching \(C\).
        #+END_proof

        #+ATTR_LATEX: :options []
        #+BEGIN_theorem
        /BurnsME/ solves the mutual exclusion problem.
        #+END_theorem
** The Bakery Algorithm
        The /Bakery/ algorithm only uses single-writer/multi-reader shared registers. In fact, it also works
        using a weaker form of register known as a *safe register*, in which the registers are allowed to
        provide arbitrary responses to reads that are performed concurrently with writes.

        The Bakery algorithm guarantees lockout-freedom and a good time bound. It guarantees bounded bypass
        and also a related condition - it is "FIFO after a wait-free doorway" (to be defined below). An
        unattractive property of the Bakery algorithm is that it uses unbounded size registers.

        #+ATTR_LATEX: :options {\textit{Bakery} algorithm}
        #+BEGIN_Block
        \noindent *Shared variables*:\\
        \noindent for every \(i\), \(1\le i\le n\):\\
        \indent \(choosing(i)\in\{0,1\}\), initially 0, writable by \(i\) and readable by all \(j\neq i\)\\
        \indent \(number(i)\in\N\), initially 0, writable by \(i\) and readable by all \(j\neq i\)

        \noindent *Process \(i\)*:
        \begin{algorithm}[H]
        \KwRem
        \(try_i\)\;
        \(choosing(i):=1\)\;
        \(number(i):=1+\max_{j\neq i}number(j)\)\;
        \(choosing(i):=0\)\;
        \For{\(j\neq i\)}{
                \Waitfor{\(choosing(j)=0\)}\;
                \Waitfor{\(number(j)=0\) or \((number(i),i)<(number(j),j)\)}\;
        }
        \(crit_i\)\;
        \KwCrit
        \(exit_i\)\;
        \(number(i):=0\)\;
        \(rem_i\)\;
        \end{algorithm}
        #+END_Block

        The first part of the trying region, until the point where process \(i\) sets \(choosing(i):=0\), is
        designated as the *doorway*. Note that it is possible for two processes to be in the doorway at the same
        time, which can cause them to choose the same number. To break such ties, processes compare not just
        their numbers, but their \((number, index)\) pairs. This comparison is done lexicographically, thus
        breaking ties in favor of the process with the smaller index.

        Let \(D\) denote the doorway.

        #+ATTR_LATEX: :options []
        #+BEGIN_lemma
        In any reachable system state of the Bakery algorithm, and for any process \(i\) and \(j\),
        \(i\neq j\), the following is true: If \(i\) is in \(C\) and \(j\) is in \((T-D)\cup C\), then
        \((number(i),i)<(number(j),j)\) 
        #+END_lemma

        #+BEGIN_proof
        Fix some point \(s\) in an execution in which \(i\) is in \(C\) and \(j\) is in \((T-D)\cup C\). Call
        the values of \(number(i)\) and \(number(j)\) at point \(s\) the *correct* values of these values.

        Process \(i\) must read \(choosing(j)=0\) in its first \(waitfor\) loop. Let \(\pi\) denote this
        reading event, thus \(\pi\) precedes \(s\). When \(\pi\) occurs, \(j\) is not in the "choosing region"
        (i.e., the portion of the doorway after setting \(choosing(j):=1\)). There are two cases:
        1. \(j\) enters the choosing region after \(\pi\). Then the correct \(number(i)\) is chosen before
           \(j\) starts.
        2. \(j\) leaves the choosing region before \(\pi\). Then whenever \(i\) reads \(j\)'s number in its
           second \(waitfor\) loop, it get the correct \(number(j)\). Therefore \((number(i),i)<(number(j),j)\).
        #+END_proof

        #+ATTR_LATEX: :options []
        #+BEGIN_lemma
        The Bakery algorithm satisfies mutual exclusion.
        #+END_lemma

        #+ATTR_LATEX: :options []
        #+BEGIN_lemma
        [[label:10.26]]
        The Bakery algorithm guarantees progress.
        #+END_lemma

        #+ATTR_LATEX: :options []
        #+BEGIN_lemma
        The Bakery algorithm guarantees lockout-freedom.
        #+END_lemma

        #+BEGIN_proof
        Consider a particular process \(i\) in \(T\) and suppose it never reaches \(C\). Process \(i\)
        eventually completes the doorway and reaches \(T-D\). Thereafter, any new process that enters the
        doorway sees \(i\)'s latest \(number\) and so chooses a higher number. Thus, since \(i\) doesn't reach
        \(C\), none of these new processes reach \(C\) either.

        But Lemma ref:10.26 implies that there must be continuing progress.
        #+END_proof

        #+ATTR_LATEX: :options []
        #+BEGIN_theorem
        The Bakery algorithm solves the mutual exclusion problem and is lockout-free
        #+END_theorem

        *Complexity analysis*: An upper bound for the time from when a process \(i\) enters the trying region
        until it enters the critical region is \((n-1)c+O(n^2l)\).

        *FIFO after a wait-free doorway*
** Lower Bound on the Number of Registers
        Two system states, \(s\) and \(s'\), are *indistinguishable* to process \(i\), written as \(s\sim_is'\),
        if the state of process \(i\), the state of \(U_i\), and the values of all the shared variables are
        the same in \(s\) and \(s'\). A system state \(s\) is *idle* if all processes are in their remainder
        regions in \(s\).

        We consider a fixed collection of user automata.
*** Basic Facts
        #+ATTR_LATEX: :options []
        #+BEGIN_lemma
        [[label:10.29]]
        Suppose that an algorithm \(A\) solves the mutual exclusion problem (that is, guarantees
        well-formedness, mutual exclusion, and progress) for \(n\ge 2\) processes, using only read/write
        shared variables. Suppose that \(s\) is a reachable idle system state and let \(i\) be any process.

        Then there is an execution fragment starting from state \(s\) and involving steps of process \(i\)
        only, in which process \(i\) reaches \(C\).
        #+END_lemma

        #+BEGIN_proof
        Progress condition.

        The progress condition is applied to a low-level-fair execution containing \(s\) in which \(i\) enters
        \(T\) after the occurrence of \(s\).
        #+END_proof

        #+ATTR_LATEX: :options []
        #+BEGIN_lemma
        [[label:10.30]]
        Suppose \(A\) solves the mutual exclusion problem for \(n\ge 2\) processes, using only read/write
        shared variables. Let \(s\) and \(s'\) be reachable system states that are indistinguishable to
        process \(i\) and suppose that \(s'\) is an idle state.

        Then there is an execution fragment starting from state \(s\) and involving steps of process \(i\)
        only, in which process \(i\) reaches \(C\).
        #+END_lemma

        #+ATTR_LATEX: :options []
        #+BEGIN_lemma
        [[label:10.31]]
        Suppose \(A\) solves the mutual exclusion problem for \(n\ge 2\) processes, using only read/write
        shared variables. Suppose that \(s\) is a reachable system state where process \(i\) is in the
        remainder region. Suppose that process \(i\) reaches \(C\) in an execution fragment starting from
        \(s\) that involves steps of \(i\) only. Then, along the way, \(i\) must write some shared variable.
        #+END_lemma

        #+BEGIN_proof
        Let \(\alpha_1\) be any finite execution fragment that starts from state \(s\), involves steps of
        \(i\) only, and ends with process \(i\) in \(C\). Suppose for the sake of contradiction that
        \(\alpha_1\) does not include any write to a shared variable. Let \(s'\) denote the state at the end
        of \(\alpha_1\). Since process \(i\) does not write any shared variable, the only differences between
        \(s\) and \(s'\) are in the states of process \(i\) and user \(U_i\). So \(s\sim_js'\) for every
        \(j\neq i\).

        Repeated use of the progress condition implies that there is an execution fragment starting from \(s\)
        and not including any steps of process \(i\), in which some process reaches \(C\). Since \(s'\sim_js\)
        for every \(j\neq i\), there is also such an execution fragment starting from \(s'\).

        But this easily yields a counterexample execution \(\alpha\). Execution \(\alpha\) begins with a
        finite execution fragment leading to reachable state \(s\), then continues with \(\alpha_1\), thus
        letting \(i\) into \(C\) with no shared variable writes. It finishes by letting another process go to
        \(C\) without any steps of \(i\), starting from \(s'\). This violates the mutual exclusion condition,
        because two processes are in \(C\) at the end of \(\alpha\).
        #+END_proof
*** Single-Writer Shared Variables
        If the shared variables are constrained to be single-writer/multi-reader read/write registers, then
        Lemmas ref:10.29 and ref:10.31 imply:
        #+ATTR_LATEX: :options []
        #+BEGIN_theorem
        If algorithm \(A\) solves the mutual exclusion problem for \(n\ge 2\) processes, using only
        single-write/multi-reader read/write shared variables, then \(A\) must use at least \(n\) shared variables
        #+END_theorem

        #+BEGIN_proof
        Consider any process \(i\). By Lemma ref:10.29, \(i\) can reach \(C\) on its own, starting from an
        initial system state of \(A\). Then Lemma ref:10.31 implies that \(i\) must write some shared variable
        along the way.
        #+END_proof
*** Multi-Writer Shared Variables
        #+ATTR_LATEX: :options []
        #+BEGIN_theorem
        [[label:10.33]]
        If algorithm \(A\) solves the mutual exclusion problem for \(n\ge 2\) processes, using only read/write
        shared variables, then \(A\) must use at least \(n\) shared variables.
        #+END_theorem

        To give the intuition for the proof, we start by proving two special cases.

        *Two processes and one variable*. We say that process \(i\) *covers* shared variable \(x\) in system state
        \(s\) provided that in state \(s\), process \(i\) is enabled to write to \(x\).
        
        #+ATTR_LATEX: :options []
        #+BEGIN_theorem
        There is no algorithm that solves the mutual exclusion problem for two processes using only one
        read/write shared variables.
        #+END_theorem

        #+BEGIN_proof
        Suppose for the sake of contradiction that there is such an algorithm, \(A\), using a single shared
        register \(x\). Let \(s\) be an initial system state. We construct an execution of \(A\) that violates
        mutual exclusion.

        Lemmas ref:10.29 and ref:10.31 imply that there is an execution involving process 1 only, starting
        from state \(s\), that causes process 1 to enter \(C\) and to write the single shared variable \(x\)
        before doing so. Just before process 1 writes \(x\), it covers \(x\). Let \(\alpha_1\) be the prefix
        of this execution up to the first point where process 1 covers x and let \(s'\) denote the final state
        of \(\alpha_1\). Note that \(s\sim_2s'\), since process 1 does not write anything to shared memory
        during \(\alpha_1\). Then Lemma ref:10.30 implies that process 2 can reach \(C\) on its own, starting
        from state \(s'\).

        The counterexample execution \(\alpha\) begins with \(\alpha_1\), thus bringing process 1 to state
        \(s'\), where it covers \(x\). It then continues by letting process 2 reach \(C\), running on its own
        from \(s'\). Next, we resume process 1, allowing it to write \(x\), _thereby overwriting anything_
        _process 2 might have written on its way to \(C\)_ (\wu{this is a consequence}). This eliminates all
        traces of process 2's execution.  So process 1 can continue to run just as it does in its solo
        execution and reach \(C\). But this puts both processes in \(C\), which contradicts the mutual
        exclusion requirement. 

        #+ATTR_LATEX: :width .88\textwidth :float nil
        #+NAME:
        #+CAPTION:
        [[../images/DistributedAlgorithms/8.png]]

        #+END_proof

        *Three processes and two variables*.
        #+ATTR_LATEX: :options []
        #+BEGIN_theorem
        There is no algorithm that solves the mutual exclusion problem for three processes using only two
        read/write shared variables.
        #+END_theorem

        #+BEGIN_proof
        Suppose there is such an algorithm \(A\), using shared registers \(x\) and \(y\). Let \(s\) be an
        initial system state.

        Starting from \(s\),we will maneuver processes 1 and 2 only, to a point where each covers one of the
        two variables \(x\) and \(y\); moreover, the resulting state, \(s'\) will be indistinguishable to
        process 3 from a reachable idle state. Then we run process 3 on its own until it reaches \(C\).

        Next we let each of processes 1 and 2 take one step, which can eliminate all traces of process 3's
        execution. Then we let processes 1 and 2 continue to take steps. Thus, by the progress condition,
        either 1 or 2 will eventually reach \(C\).

        It remains to show how to maneuver processes 1 and 2 to cover the two shared variables while appearing
        to process 3 to still be in \(R\) (\wu{What we have is the three lemmas only}).

        First, we construct execution \(\alpha_1\) by running process 1 alone from \(s\) until it first covers
        a shared variable. Then we extend \(\alpha_1\) to \(\alpha_2\) by continuing to run process 1 alone
        until it enters \(C\), then \(E\), then \(R\), then \(T\) once again, and again covers some shared
        variable. We extend \(\alpha_2\) to \(\alpha_3\) in the same way. Let the final states of
        \(\alpha_1\), \(\alpha_2\) and \(\alpha_3\) be \(s_1\), \(s_2\) and \(s_3\), respectively.

        Since there are only two shared variables, in two of the three states \(s_1\), \(s_2\) and \(s_3\),
        process 1 must cover the /same variable/. Suppose that in \(s_2\) and \(s_3\), process 1 covers variable
        \(x\).

        Now consider what happens if we run process 2 alone, starting from state \(s_2\). Process 2 can enter
        \(C\) because \(s_2\) is indistinguishable to process 2 from the last preceding state in \(\alpha\) in
        which process 1 is in \(R\). Moreover, we claim that along the way process 2 must write the other
        shared variable \(y\) (\wu{2 could still writes \(x\)}). For otherwise, process 2 could reach \(C\), then process 1 could take one step,
        overwriting whatever process 2 wrote to variable \(x\) and thus eliminating all traces of 2, and then
        process 1 could continue and violate mutual exclusion.

        Now we construct a counterexample \(\alpha\):
        #+ATTR_LATEX: :width .88\textwidth :float nil
        #+NAME: 10.12
        #+CAPTION: Construction of \(\alpha\)
        [[../images/DistributedAlgorithms/9.png]]

        Execution \(\alpha\) begins with \(\alpha_2\), thus bringing process 1 to a point where it covers
        \(x\).  It then continues by letting process 2 run until the first point where it covers \(y\). (In
        this situation we have so far, process 2 might have written \(x\) since it last left \(R\), which
        could be detectable by process 3.)

        From the point where process 2 covers \(y\), we resume process 1. It can first write \(x\), thereby
        eliminating all traces of process 2. Then process 1 can continue to run and reach a point that looks
        to it like the point after \(\alpha_3\), where it again covers \(x\). Let \(s'\) be the final state of
        \(\alpha\).

        Let \(s''\) be the last idle state occurring in \(\alpha_3\). \(s''\sim_3 s_3\sim_3 s'\).
        #+END_proof

        *The general case*.
        #+ATTR_LATEX: :options []
        #+BEGIN_lemma
        Suppose \(A\) solves the mutual exclusion problem for \(n\ge 2\) processes, using only read/write
        variables. Suppose that \(s\) is a reachable system state in which process \(i\) is in the remainder
        region. Suppose that process \(i\) reaches \(C\) in an execution fragment starting from \(s\) that
        involves steps of \(i\) only. Then, along the way, \(i\) must write some shared variable that is not
        covered by any other process in \(s\).
        #+END_lemma

        #+BEGIN_proof
        The proof is similar to that of Lemma ref:10.31. The main difference is that now we must ensure that
        the execution fragment involving the other processes begins with a single step of each process that
        covers a shared variable, thus overwriting that variable. This allows the other processes to eliminate
        all traces of \(i\)'s computation.
        #+END_proof

        For any \(k\), \(1\le k\le n\), we say that one system state is *\(k\)-reachable* from another if it is
        reachable using steps of processes \(1,\dots,k\) only.

        #+ATTR_LATEX: :options []
        #+BEGIN_lemma
        Suppose \(A\) solves the mutual exclusion problem for \(n\ge 2\) processes, using only read/write
        shared variables. Assume that there are exactly \(n-1\) shared variables. Let \(s\) be any reachable
        idle system state. Suppose \(1\le k\le n-1\). Then there are two system states, \(s'\) and \(s''\),
        each \(k\)-reachable from \(s\), satisfying the following properties:
        1. \(k\) distinct variables are covered by processes \(1,\dots,k\) in \(s'\)
        2. \(s''\) is an idle state
        3. \(s'\sim_is''\) for all \(i\), \(k+1\le i\le n\)
        #+END_lemma

        #+BEGIN_proof
        Induction on \(k\).

        /Basis/: \(k=1\). We run process 1 alone from \(s\) until it first covers a shared variable. Defining
        \(s'\) to be the resulting state and \(s''=s\) gives the needed properties.

        /Inductive step/: Suppose the lemma holds for \(k\), where \(1\le k\le n-2\); we prove it for \(k+1\).
        Using IH, we obtain a state \(t_1\) that is \(k\)-reachable from \(s\) and in which processes
        \(1,\dots,k\) cover \(k\) distinct variables; however, \(t_1\) is indistinguishable to processes
        \(k+1,\dots,n\) from some idle state that is also \(k\)-reachable from \(s\). Next, we let each of
        processes \(1,\dots,k\) take one step from \(t_1\), thereby writing the variable that it covers. Then
        we let all of \(1,\dots,k\) proceed to \(R\), resulting in a new reachable idle state \(u_1\).
        #+END_proof
* Q&A
        1. [[P1]]. Need think.
        2. [[P2]]
