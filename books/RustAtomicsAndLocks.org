#+title: Rust Atomics And Locks

#+AUTHOR: Mara Bos

#+EXPORT_FILE_NAME: ../latex/RustAtomicsAndLocks/RustAtomicsAndLocks.tex
#+LATEX_HEADER: \graphicspath{{../../books/}}
#+LATEX_HEADER: \input{../preamble.tex}
#+LATEX_HEADER: \usepackage{minted}
#+LATEX_HEADER: \makeindex

* Basics of Rust Concurrency
** Threads in Rust
    Rust std assigns every thread a unique identifier.

    #+ATTR_LATEX: :options [Output Locking]
    #+BEGIN_remark
    The ~println~ macro uses ~std::io::Stdout::lock()~ to make sure its output does not get interrupted.
    A ~println!()~ expression will wait until any concurrently running one is finished before writing
    any output.
    #+END_remark

    Since a thread might run until the every end of the program's execution, the ~spawn~ function has
    a ~'static~ lifetime bound on its argument type. In other words, it only accepts functions that
    may kept around forever.

    #+ATTR_LATEX: :options [Thread Builder]
    #+BEGIN_remark
    The ~std::thread::spawn~ function is a convenient shorthand for
    ~std::thread::Builder::new().spawn().unwrap()~.

    A ~std::thread::Builder~ allows you to set some settings for the new thread before spawning it.
    You can use it to configure the stack size for the new thread and to give the new thread a name.
    The name of a thread is available through ~std::thread::current().name()~, will be used in panic
    messages, and will be visible in monitoring and debugging tools on most platforms.

    Additionally, Builder’s spawn function returns an ~std::io::Result~, allowing you
    to handle situations where spawning a new thread fails. This might happen if the operating
    system runs out of memory, or if resource limits have been applied to your program. The
    ~std::thread::spawn~ function simply panics if it is unable to spawn a new thread.
    #+END_remark
** Scoped Threads
    If we know for sure that a spawned thread will definitely not outlive a certain scope, that
    thread could safely borrow things that do not live forever, such as local variables, as long as
    they outlive that scope.
** Shared Overship and Reference Counting
*** Statics
    ~static~ is "owned" by the entire program.
    #+begin_src rust
static X: [i32; 3] = [1, 2, 3];
thread::spawn(|| dbg!(&X));
thread::spawn(|| dbg!(&X));
    #+end_src
    Every thread can borrow it, since it's guaranteed to always exist.
*** Leaking
    Using ~Box::leak~, one can release ownership of a ~Box~, promising to never drop it.
    #+begin_src rust
let x: &'static [i32; 3] = Box::leak(Box::new([1, 2, 3]));
thread::spawn(move || dbg!(x));
thread::spawn(move || dbg!(x));
    #+end_src
*** Reference Counting
    To make sure that shared data gets dropped and deallocated, we can’t completely give up its
    ownership. Instead, we can share ownership. By keeping track of the number of owners, we can
    make sure the value is dropped only when there are no owners left.

    ~std::rc::Rc~ is short for "reference count". Cloning it will not allocate anything new, but
    instead increment a counter stored next to the contained value.

    ~Rc~ is not *thread-safe*. Instead we can use ~std::sync::Arc~, which stands for "atomically
    reference counted"
*** Borrowing and Data Races
*** Interior Mutability
    A ~std::cell::Cell<T>~ simply wraps a ~T~, but allows mutations through a shared reference. To avoid
    undefined behavior, it only allows you to copy the value out (if ~T~ is ~Copy~) or replace it with
    another value as a whole. In addition, it can only be used within a single thread.
    #+begin_src rust
use std::cell::Cell;
fn f(a: &Cell<i32>, b: &Cell<i32>) {
    let before = a.get();
    b.set(b.get() + 1);
    let after = a.get();
    if before != after {
        x(); // might happen
    }
}
    #+end_src

    #+begin_src rust
fn f(v: &Cell<Vec<i32>>) {
    let mut v2 = v.take(); // Replaces the contents of the Cell with an empty Vec
    v2.push(1);
    v.set(v2); // Put the modified Vec back
}
    #+end_src

    A ~std::cell::RefCell~ does allow you to borrow its content, at a small runtime cost. A
    ~RefCell<T>~ does not only hold a ~T~, but also holds a counter that keep track of any outstanding
    borrows. If you try to borrow it while it is already mutably borrowed (or vice-versa), it will
    panic, which avoids undefined behavior. A ~RefCell~ can only be used within a single thread.

    Borrowing the contents is done by calling ~borrow~ or ~borrow_mut~.
*** Mutex and RwLock
    An ~RwLock~ or *reader-writer lock* is the concurrent version of a ~RefCell~. An ~RwLock<T>~ holds a ~T~
    and tracks any outstanding borrows. However, unlike a ~RefCell~, it does not panic on conflicting
    borrows. Instead, it blocks the current thread—putting it to sleep—while waiting for conflicting
    borrows to disappear.
*** Atomics
    Unlike a ~Cell~, though, they cannot be of arbitrary size. Because of this, there is no generic
    ~Atomic<T>~ type for any ~T~, but there are only specific atomic types such as ~AtomicU32~ and
    ~AtomicPtr<T>~.
*** UnsafeCell
    ~UnsafeCell~ is the primitive building block for interior mutability.

    An ~UnsafeCell<T>~ wraps a ~T~, but does not come with any conditions or restrictions to avoid
    undefined behavior. Instead, its ~get()~ method just gives a raw pointer to the value it wraps,
    which can only be meaningfully used in unsafe blocks.
** Locking: Mutexes and RwLocks
*** Rust's Mutex
    ~std::sync::Mutex<T>~

    To ensure a locked mutex can only be unlocked by the thread that locked it, it does not have an
    ~unlock()~ method. Instead, its ~lock()~ method returns a special type called a ~MutexGuard~. This
    guard represents the guarantee that we have locked the mutex. It behaves like an exclusive
    reference through the ~DerefMut~ trait, giving us exclusive access to the data the mutex protects.
    Unlocking the mutex is done by dropping the guard. When we drop the guard, we give up our
    ability to access the data, and the Drop implementation of the guard will unlock the mutex.

    #+begin_src rust
use std::sync::Mutex;
fn main() {
    let n = Mutex::new(0);
    thread::scope(|s| {
        for _ in 0..10 {
            s.spawn(|| {
                let mut guard = n.lock().unwrap();
                for _ in 0..100 {
                    ,*guard += 1;
                }
            });
        }
    });
    assert_eq!(n.into_inner().unwrap(), 1000);
}
    #+end_src

    The ~into_inner~ method takes ownership of the mutex, which guarantees that nothing else can have a
    reference to the mutex anymore, making locking unnecessary.
*** Lock Poisoning
    The ~unwrap()~ calls in the examples above relate to lock poisoning.

    A Mutex in Rust gets marked as /poisoned/ when a thread panics while holding the lock. When that
    happens, the ~Mutex~ will no longer be locked, but calling its lock method will result in an Err
    to indicate it has been poisoned.

    This is a mechanism to protect against leaving the data that’s protected by a mutex in an
    inconsistent state. In our example above, if a thread would panic after incrementing the integer
    fewer than 100 times, the mutex would unlock and the integer would be left in an unexpected
    state where it is no longer a multiple of 100, possibly breaking assumptions made by other
    threads. Automatically marking the mutex as poisoned in that case forces the user to handle this
    possibility.
*** Reader-Writer Lock
    A mutex is only concerned with exclusive access. The ~MutexGuard~ will provide us an exclusive
    reference (~&mut T~) to the protected data, even if we only wanted to look at the data and a
    shared reference (~&T~) would have sufficed. It has ~read()~ and ~write()~ method for locking as
    either a reader or a writer.

    Both ~Mutex<T>~ and ~RwLock<T>~ require ~T~ to be ~Send~, because they can be used to send a ~T~ to
    another thread. An ~RwLock<T>~ additionally requires ~T~ to also implement ~Sync~, because it allows
    multiple threads to hold a shared reference (~&T~) to the protected data.
*** Waiting: Parking and Condition Variables
    One way to wait for a notification from another thread is called *thread parking*.

    Thread parking is available through the ~std::thread::park()~ function. For unparking, you call
    the ~unpark()~ method on a ~Thread~ object representing the thread that you want to unpark. Such an
    object can be obtained from the join handle returned by ~spawn~, or by the thread itself through
    ~std::thread::current()~.

    #+begin_src rust
use std::collections::VecDeque;
fn main() {
    let queue = Mutex::new(VecDeque::new());
    thread::scope(|s| {
        // Consuming thread
        let t = s.spawn(|| loop {
            let item = queue.lock().unwrap().pop_front();
            if let Some(item) = item {
                dbg!(item);
            } else {
                thread::park();
            }
        });
        // Producing thread
        for i in 0.. {
            queue.lock().unwrap().push_back(i);
            t.thread().unpark();
            thread::sleep(Duration::from_secs(1));
        }
    });
}
    #+end_src

    An important property of thread parking is that a call to ~unpark()~ before the thread parks
    itself does not get lost. The request to unpark is still recorded, and the next time
    the thread tries to park itself, it clears that request and directly continues without
    actually going to sleep.

    However, unpark requests don't stack up.

    The Rust standard library provides a condition variable as ~std::sync::Condvar~. Its
    wait method takes a ~MutexGuard~ that proves we’ve locked the mutex. It first unlocks the mutex
    and goes to sleep. Later, when woken up, it relocks the mutex and returns a new ~MutexGuard~.

    It has two notify functions: ~notify_one~ to wake up just one waiting thread (if any),
    and ~notify_all~ to wake them all up.

    #+begin_src rust
use std::sync::Condvar;
let queue = Mutex::new(VecDeque::new());
let not_empty = Condvar::new();
thread::scope(|s| {
    s.spawn(|| {
        loop {
            let mut q = queue.lock().unwrap();
            let item = loop {
                if let Some(item) = q.pop_front() {
                    break item;
                } else {
                    q = not_empty.wait(q).unwrap();
                }
            };
            drop(q);
            dbg!(item);
        }
    });
    for i in 0.. {
        queue.lock().unwrap().push_back(i);
        not_empty.notify_one();
        thread::sleep(Duration::from_secs(1));
    }
});
    #+end_src
*  Atomics
** Atomic Load and Store Operations
    Take ~AtomicI32~ as an example:
    #+begin_src rust
impl AtomicI32 {
    pub fn load(&self, ordering: Ordering) -> i32;
    pub fn store(&self, value: i32, ordering: Ordering);
}   
    #+end_src

    Note how the store method takes a shared reference (~&T~) rather than an exclusive reference
    (~&mut T~), even though it modifies the value.
*** Example: Stop Flag
    #+begin_src rust
use std::sync::atomic::AtomicBool;
use std::sync::atomic::Ordering::Relaxed;
fn main() {
    static STOP: AtomicBool = AtomicBool::new(false);
    // Spawn a thread to do the work.
    let background_thread = thread::spawn(|| {
        while !STOP.load(Relaxed) {
            some_work();
        }
    });
    // Use the main thread to listen for user input.
    for line in std::io::stdin().lines() {
        match line.unwrap().as_str() {
            "help" => println!("commands: help, stop"),
            "stop" => break,
            cmd => println!("unknown command: {cmd:?}"),
        }
    }
    // Inform the background thread it needs to stop.
    STOP.store(true, Relaxed);
    // Wait until the background thread finishes.
    background_thread.join().unwrap();
}
    #+end_src
*** Fetch-and-Modify Operations
    The most commonly used ones are ~fetch_add~ and ~fetch_sub~, which perform addition and subtraction,
    respectively. Some of the other available operations are ~fetch_or~ and ~fetch_and~ for bitwise
    operations, and ~fetch_max~ and ~fetch_min~ which can be used to keep a running maximum or minimum.
    #+begin_src rust
impl AtomicI32 {
    pub fn fetch_add(&self, v: i32, ordering: Ordering) -> i32;
    pub fn fetch_sub(&self, v: i32, ordering: Ordering) -> i32;
    pub fn fetch_or(&self, v: i32, ordering: Ordering) -> i32;
    pub fn fetch_and(&self, v: i32, ordering: Ordering) -> i32;
    pub fn fetch_nand(&self, v: i32, ordering: Ordering) -> i32;
    pub fn fetch_xor(&self, v: i32, ordering: Ordering) -> i32;
    pub fn fetch_max(&self, v: i32, ordering: Ordering) -> i32;
    pub fn fetch_min(&self, v: i32, ordering: Ordering) -> i32;
    pub fn swap(&self, v: i32, ordering: Ordering) -> i32; // "fetch_store"
}   
    #+end_src

    #+begin_src rust
use std::sync::atomic::AtomicI32;

let a = AtomicI32::new(100);
let b = a.fetch_add(23, Relaxed);
let c = a.load(Relaxed);

assert_eq!(b, 100);
assert_eq!(c, 123);
    #+end_src

    An important thing to keep in mind is that ~fetch_add~ and ~fetch_sub~ implement wrapping behavior
    for overflows. Incrementing a value past the maximum representable value will wrap around and
    result in the minimum representable value. This is different than the behavior of the plus and
    minus operators on regular integers, which will panic in debug mode on overflow.
*** Compare-and-Exchange Operations
    #+begin_src rust
impl AtomicI32 {
    pub fn compare_exchange(
        &self,
        expected: i32,
        new: i32,
        success_order: Ordering,
        failure_order: Ordering
    ) -> Result<i32, i32>;
}
    #+end_src

    Ignoring the order, it is basically identical to
    #+begin_src rust
impl AtomicI32 {
    pub fn compare_exchange(&self, expected: i32, new: i32) -> Result<i32, i32> {
        // In reality, the load, comparison and store,
        // all happen as a single atomic operation.
        let v = self.load();
        if v == expected {
            // Value is as expected.
            // Replace it and report success.
            self.store(new);
            Ok(v)
        } else {
            // The value was not as expected.
            // Leave it untouched and report failure.
            Err(v)
        }
    }
}
    #+end_src

    An example:
    #+begin_src rust
fn increment(a: &AtomicU32) {
    let mut current = a.load(Relaxed);
    loop {
        let new = current + 1;
        match a.compare_exchange(current, new, Relaxed, Relaxed) {
            Ok(_) => return,
            Err(v) => current = v,
        }
    }
}   
    #+end_src

    Or we would use ~fetch_update~
    #+begin_src rust
a.fetch_update(Relaxed, Relaxed,
    |n| n.add(1));
    #+end_src
* Memory Ordering
** Reordering and Optimizations
    A processor might determine that two particular consecutive instructions in your program will
    not affect each other, and execute them /out of order/, if that is faster, for example. While one
    instruction is briefly blocked on fetching some data from main memory, several of the following
    instructions might be executed and finished before the first instruction finishes, as long as
    that wouldn’t change the behavior of your program.
** The Memory Model
*** Happens-Before Relationship
    ~Relaxed~ memory ordering is the most basic (and most performant) memory ordering that, by itself,
    never results in any cross-thread happens-before relationships.

    #+begin_src rust
static X: AtomicI32 = AtomicI32::new(0);
static Y: AtomicI32 = AtomicI32::new(0);
fn a() {
    X.store(10, Relaxed);    // 1
    Y.store(20, Relaxed);    // 2
}
fn b() {
    let y = Y.load(Relaxed); // 3
    let x = X.load(Relaxed); // 4
    println!("{x} {y}");
}
    #+end_src
    If either of ~a~ or ~b~ completes before the other starts, the output will be ~0 0~ or ~10 20~. If ~a~ and
    ~b~ cun concurrently, it's easy to see how the output can be ~10 0~.
*** Spawning and Joining
    Spawning a thread creates a happens-before relationship between what happened before the ~spawn()~
    call, and the new thread. Similarly, joining a thread creates a happens-before relationship
    between the joined thread and what happens after the ~join()~ call.

    For example, the following assertion cannot fail:
    #+begin_src rust
static X: AtomicI32 = AtomicI32::new(0);
fn main() {
    X.store(1, Relaxed);
    let t = thread::spawn(f);
    X.store(2, Relaxed);
    t.join().unwrap();
    X.store(3, Relaxed);
}
fn f() {
    let x = X.load(Relaxed);
    assert!(x == 1 || x == 2);
}
    #+end_src
*** Relaxed Ordering
    While atomic operations using relaxed memory ordering do not provide any happens-before
    relationship, they do guarantee a *total modification order* of each individual atomic variable. This
    means that all modifications *of the same atomic variable* happen in an order that is the same
    from the perspective of every single thread.

    Consider
    #+begin_src rust
static X: AtomicI32 = AtomicI32::new(0);
fn a() {
    X.fetch_add(5, Relaxed);
    X.fetch_add(10, Relaxed);
}
fn b() {
    let a = X.load(Relaxed);
    let b = X.load(Relaxed);
    let c = X.load(Relaxed);
    let d = X.load(Relaxed);
    println!("{a} {b} {c} {d}");
}
    #+end_src
*** Release and Acquire Ordering
    *Release* and *acquire* memory ordering are used in a pair to form a happens-before relationship
    between threads. ~Release~ memory ordering applies to store operations, while ~Acquire~ memory
    ordering applies to load operations.

    A happens-before relationship is formed when an acquire-load operation observes
    the result of a release-store operation. In this case, the store and everything before it,
    happened before the load and everything after it.

    When using ~Acquire~ for a fetch-and-modify or compare-and-exchange operation, it applies only to
    the part of the operation that loads the value. Similarly, ~Release~ applies only to the store
    part of an operation. ~AcqRel~ is used to represent the combination of ~Acquire~ and ~Release~, which
    causes both the load to use acquire ordering, and the store to use release ordering.

    Consider
    #+begin_src rust
use std::sync::atomic::Ordering::{Acquire, Release};
static DATA: AtomicU64 = AtomicU64::new(0);
static READY: AtomicBool = AtomicBool::new(false);
fn main() {
    thread::spawn(|| {
        DATA.store(123, Relaxed);
        READY.store(true, Release); // Everything from before this store ..
    });
    while !READY.load(Acquire) { // .. is visible after this loads `true`.
        thread::sleep(Duration::from_millis(100));
        println!("waiting...");
    }
    println!("{}", DATA.load(Relaxed));
}
    #+end_src
    The only possible outcome of this program is 123.

    #+ATTR_LATEX: :options [Locking]
    #+BEGIN_examplle
    #+begin_src rust
static mut DATA: String = String::new();
static LOCKED: AtomicBool = AtomicBool::new(false);
fn f() {
    if LOCKED.compare_exchange(false, true, Acquire, Relaxed).is_ok() {
        // Safety: We hold the exclusive lock, so nothing else is accessing DATA.
        unsafe { DATA.push('!') };
        LOCKED.store(false, Release);
    }
}
fn main() {
    thread::scope(|s| {
        for _ in 0..100 {
            s.spawn(f);
        }
    });
}
    #+end_src
    #+END_examplle
*** Consume Ordering
*** Sequentially Consistent Ordering
    Every single operation using ~SeqCst~ ordering within a program is part of a single total order
    that all threads agree on. This total order is consistent with the total modification order of
    each individual variable.
    #+begin_src rust
use std::sync::atomic::Ordering::SeqCst;
static A: AtomicBool = AtomicBool::new(false);
static B: AtomicBool = AtomicBool::new(false);
static mut S: String = String::new();
fn main() {
    let a = thread::spawn(|| {
        A.store(true, SeqCst);
        if !B.load(SeqCst) {
            unsafe { S.push('!') };
        }
    });
    let b = thread::spawn(|| {
        B.store(true, SeqCst);
        if !A.load(SeqCst) {
            unsafe { S.push('!') };
        }
    });
    a.join().unwrap();
    b.join().unwrap();
}
    #+end_src

    If both store operations happen before either of the load operations, it’s possible that neither
    thread ends up accessing ~S~. However, it’s impossible for both threads to access ~S~ and cause
    undefined behavior, since the sequentially consistent ordering guarantees only one of them can
    win the race.
*** Fences
